## Physically Protecting Sensitive Data

### Five Dimensions of Physical Security

We propose using five dimensions of physical data security to serve as a framework to evaluate the different defining features of various data access mechanisms. The five dimensions include the location of the data, the access that researchers have to the analysis computers, the location of the access computers, the level of security of the access room, and the range of analysis methods available to researchers. When proposing and negotiating a potential use sharing agreement, evaluating the physical security arrangements along these five dimensions can help researchers and their data providers craft robust mechanisms to protect data when transferring and using data for research.

#### Data Location

The researcher-accessible administrative data can be stored at one of three types of locations. The data can exist at the data provider, the data provider can transfer the data directly to the researcher, or the data provider can transfer the data to a trusted third party. Each possible data location comes with its own requirements, advantages, disadvantages, and special considerations for the researcher and data provider.

When the researcher-accessible administrative data remains under the custody of the data provider, the primary advantage is that the data provider has direct physical control over the access it provides to the data. With properly configured software and hardware access mechanisms, only approved devices belonging to safe people will be able to connect to the data. Access mechanisms in this scenario are limited to having the researcher travel directly to the data provider, or providing a remote access system for the researcher to connect to the data provider’s data system. Both the New Brunswick Institute for Research, Data and Training (NB-IRDT) and the German Institute of Employment Research (IAB) maintain direct control over their data, with researchers having to travel to the NB-IRDT to access the data in a secure setting, while the IAB allows researchers to remotely access the data.

If the data provider transfers the data to the researcher, the researcher has physical control over the data. This can be a cost-saving measure for the data provider, as it no longer has to maintain the infrastructure to support data storage and analysis. However, the data provider is mostly dependent on legal agreements, audits, and other second-hand mechanisms to maintain de jure control over what the researcher can and cannot do with the data. The data provider can mandate the usage of monitoring software, specific storage setups, access requirements, and other technical methods of assuring that the researcher only uses the data for approved purposes and shares with approved people. The Ohio Longitudinal data Archive (OLDA) is an example of transferring the data to researchers, where researchers are responsible for providing secure desktop to store OLDA data. 

The third alternative is for the data provider to entrust a third party to hold the data on its behalf. The third party can either be a secure data service researcher’s institution or a neutral third party. The third party has its own agreement with the data provider to maintain and transfer the data as requested, separate from the agreements that govern the researchers’ usage of the data. The advantages of this arrangement include having an organization that is more familiar with and responsive to the needs of the researchers handling the data as well as reducing the burden on staff and resources at the data provider. The San Francisco Unified School District (SFUSD) Stanford Partnership is an example where the data provider entrusts the data to a third party at Stanford University, which ultimately makes it available to approved researchers.

#### Analysis Computers

The level of access that researchers have to the analysis computers is another dimension on which data providers and researchers setting up data sharing systems must consider. Analysis computers are the computers on which researchers perform their analysis on and are by definition at in the same location as the data, and are potentially distinct from the computers which researchers use to access the data. The level of access that researchers have refers to the restrictions, or lack thereof, on what researchers can do on the computer; the most relevant aspect of this tends to be what software that researchers can utilize.

In the least restrictive arrangement, researchers can have full administrative access to the analysis computers, meaning that there is no restriction on the types of software that researchers can use to perform their analysis. This can be through the researcher having ownership over the analysis computer, such as in the instance when the data is transferred to the researcher, or when the researcher has agreements with the data provider allowing them to utilize their choice of software on the analysis computers. This allows researchers to perform more types of analysis than they might otherwise be able to. One example of this is the way that NCES restricted-use data licenses operate. The researcher must set up a secure data room in accordance with NCES requirements, but is otherwise free to utilize whatever software they want to analyze the data.

In other instances, researchers only have partial access to the analysis computers. This usually occurs in cases where researchers only have remote access to the data and analysis computers. There is a large spectrum of the limits that partial access can place on researchers. On one end of the spectrum, partial access can be relatively open, with researchers being allowed to utilize most if not all commonly available software packages without having administrative access to the computers. Researchers may have a mechanism to request new software or packages for the analysis computers that requires the computer owner to implement. Functionally, this allows researchers nearly the same level of flexibility as having full access, without allowing researchers to have administrative privileges to the computers.

On the other end of the spectrum, researchers may be restricted to very specific sets of software that are pre-approved by the analysis computer owner. This may be due to technical requirements related to computer and network security, as a mechanism for disclosure control, or the expense of acquiring or maintaining multiple sets of software. These restrictions affect not only the base software itself, such Stata or R, but also third party packages for those software; while the base software itself may be unrestricted, additional packages not signed by the original developer may not be allowed. For example, the Federal Statistical Research Data Center network has a specific set of software that they make available to researchers, who must use one of the programs that the FSRDC has on their secure computing network. 

#### Access Computers

The location of the access computers is another dimension of physical security. Access computers are the computers researchers utilize to access the analysis computers. The access computers can be the same as the analysis computers, in instances that the analysis computer is also the access computer. Access computers can also be distinct from analysis computers, such as in remote login or remote execution setups. Access computers can be located at the data provider, at the researcher, or at a third party institution.

If the access computer is located at the data provider, the researcher must travel to the data provider. This does not necessarily mean that the access computer is the same computer as the analysis computer, merely that the access computer is under the physical control of the data provider. This allows the data provider maximum control over the access computer and its security arrangements, including physical monitoring, removing USB access ports, controlling user access to specific files and folders, and other measures. One example of this setup is the NB-IRDT, which only maintains access computers at sites that it controls.

Access computers located at the researcher can take a variety of forms. This can involve direct data transfers to the researcher, where the access and analysis computer both belong to the researcher. This requires the researchers to properly configure and secure the access computer under their control, which the data provider can exercise some control over with the usage of monitoring software. The other option is for a remote access system, whether it is software installed on a computer owned by the researcher, such as remote desktop or remote submission systems, or the data provider issuing the researcher a thin client, a specialized computer that has specific hardware and software configurations. The SFUSD-Stanford partnership allows researchers to utilize their own computers, subject to security requirements, as the access computer. The IAB remote execution access route has researchers using a software remote submission system to access the data.

The final option is for the access computer to be located at a third party. This usually takes the form of research data centers that have agreements to host access computers in a secure environment on behalf of the data provider. This allows more flexible access options for researchers, who can avoid having to travel to the data provider itself. It also saves the data provider itself from having to maintain the entirety of the access infrastructure by itself. In the example of the US Census Bureau FSRDC, there are many research universities and other host institutions that house access computers in secure settings to enable easier access for researchers located around the country. A lower cost, smaller scale implementation of this system is the Safepod network in the United Kingdom, which functions similarly to an RDC but in a much smaller, prefabricated space.

#### Access Rooms

The location of the access computer, the access rooms, can have varying levels of security. We classify the levels of security into four levels, ranging from open access (no security) to low, medium, and high security arrangements. Unlike the other dimensions outlined above, these are not concrete distinctions between different mechanisms but rather broad classifications of the overall rigor of physical security regimes.

An open access arrangement is one where there are no mandated controls on the physical location of the access computer. The access computer is protected only by hardware and software configuration of the device itself. This is usually only seen in remote access or submission systems, such as the IAB JoSuA interface where there are no explicit restrictions on where the researcher can use the interface [do you know if this is true, Lars? I can’t find anything on IAB website saying that there is a restriction].

A low security arrangement has a mandated location for the access room or other basic security precautions, but otherwise has no access controls outside of the control of the researcher. Frequently this takes the form of provisions in the data use agreement between the data provider and researcher mandating certain steps such as storing the data in a locked room, but the security arrangements are maintained by the researcher. For instance, the SFUSD-Stanford data use agreement template mandates that Stanford researchers take “reasonable and appropriate efforts” to keep the data “in a space otherwise physically and electronically secure from unauthorized access”. However, the district does not exercise physical control over the researchers’ access room security.

An access room with a medium security setup has mandated security features. Access is restricted to approved researchers, with a minimum of a physically secured facility such as a locked room where only approved researchers have key or keycard access.  Frequently, medium security room setups will be under the control of a third party or the data provider itself. This enables the room administrator to directly monitor who has access to the room and the physical security of the access computers within the room.

In some circumstances, access rooms can still remain under the control of the researcher; however the data provider would need to approve the security arrangements, conduct audits, or otherwise directly verify that the researcher is in compliance with the security requirements or the access room. The requirements for the data location outlined in the NCES restricted-use data license is an example of a medium security arrangement under the control of the researcher. The data must be kept in a locked room with access restricted only to licensed researchers, with the security arrangements subject to random audits by NCES.

A high security access room builds on the medium security room, but has strong specifications for physical security. This can include mandating that the room have secured walls that fully extend from the floor to ceiling with no gaps, electronic shielding for the room, video monitoring of the room, identity or biometric verification for people entering the room, and other security arrangements that extend beyond simple access controls for people entering the room. The NB-IRDT data centers, with their stringent access controls and additional physical safeguards such as bolting the server to the floor in a separate locked cage, falls into the high security category.

#### Analysis Methods

The final dimension of physical security is the range of analysis methods available to the researchers. There are either unrestricted analysis methods, subject to software availability, or a limited range of methods that limits the sorts of analysis and tabulations that researchers can perform.

Environments with unrestricted analysis methods allow researchers to utilize the full range of methods available in the set of software that is available on the analysis computer, subject to other restrictions on the analysis computer as discussed in the previous section. Limited analysis methods place restrictions on what researchers can do, such as limiting the language set available to researchers to a whitelisted set of commands.

[lars - can you fill this section out more? This sort of restriction isn’t mentioned in any of our case studies, and publicly available information seems really thin as well]

### Technical features, infrastructure, implementations

#### Thin Clients
One of the common implementations of access computers, whether with the researcher or at data centers, is the usage of thin clients. Thin clients are computers that have been optimized for connecting with remote servers that store the data and do the actual analysis. Thin clients can either be provided directly to researchers or be housed within a research data center. [incomplete]

#### Biometrics

#### Secure Rooms

#### Etc

### Typical access mechanisms

#### Remote Execution

Under a remote execution model, data is stored remotely in a location such that a researcher does not have direct access to the data. In this scenario, a researcher needs to submit a request to have the data provider run the analysis on behalf of the researcher and share only the summary output, with the researcher never having access to the actual data.

Remote execution requires that a data provider maintain dedicated staff with the technical expertise to interface with researchers, run the researchers’ analysis, and check the output for data anonymity before sending it back to the researchers. The systems to perform the analysis and disclosure checks can be manual or automatic, which both require technical experts to maintain.

The data provider also needs to create and maintain the systems to facilitate the transfer of the necessary files (researchers need to receive the synthetic data, submit analysis files, and receive the output) as well as to allow the data provider to run the necessary analysis on behalf of the researcher.

A key requirement for such a system is the provision of accurate codebooks and documentation from data providers to researchers such that they can prepare the appropriate data request and analysis files for the data provider. While important for all data exchanges, this is especially important for remote execution since researchers cannot personally examine the data. One common method is for the data provider to give researchers synthetic data files that have the same variables and table structures as the real data, but have fictitious values for the variables.

By maintaining full control of the data as well as having the opportunity to check the researchers’ request and check the output before handing it back to the researcher, remote execution gives the data provider the highest level of data security. The primary tradeoff is the additional resources required on the part of the data provider to perform these tasks and the additional time it will take for a government to receive relevant results from their research partner.

One example of a national statistical agency that uses remote a remote execution model is Statistics Canada, which allows researchers to submit analysis code after testing it on synthetic data for a select number of their databases. The Statistics Canada implementation follows the standard remote execution model. Similarly, the German IAB has a remote execution portal where researchers can test their code on test data data and upload their code for execution, and only access approved results when their job is complete.

A variant on the remote execution model is the United States National Center for Health Statistics Research Data Centers, which requires researchers to first submit their analysis code for manual approval before arriving at the research data center itself to run the analysis.

#### Physical Data Enclave

In a physical data enclave, researchers must physically enter the data enclave to access the data and run their analysis code. The data provider can choose to store the data either on site at the data enclave itself, or store the data on a remote server that can only be accessed by specifically configured computers located within the data enclave. In either case researchers only have access to the data in a secure and physically controlled environment.

To run a physical data enclave, a data provider needs to have an access-controlled space for researchers to work in with the requisite servers, computers, and software packages. The data provider must also have staff or automated systems to ensure that researchers are not running proscribed analyses and checking the outputs before being removed from the physical data enclave.

The data provider gets most of the security benefits of remote execution by maintaining full control over the data in the entire research process. It removes the potential bottleneck and additional expense of requiring dedicated staff on the part of the data provider to actually run the analysis on behalf of the researcher. The ability of researchers to personally examine the data in controlled settings enables them to potentially work with data providers on improving data quality in such a setting.

However, physical data enclaves still impose restrictions on the flexibility of researchers and the speed at which governments can receive research findings; instead of waiting for someone to run the remote execution for them, researchers have to schedule visits to a physical location. It also requires the data provider to provide the physical and technical infrastructure for researchers to conduct their research in a secure location.

Different models of physical data enclaves exist. The traditional model in the United States is the Federal Statistical Research Data Center (FSRDC) network, where federal statistical agencies partner with research institutions to provide secure data access facilities managed by the US Census Bureau. Research institutions maintain the data enclave itself and the client computers within the data enclaves, which are connected to servers maintained by statistical agencies. Researchers must be approved by the Census Bureau and pass background checks before gaining access to the facility and data, and the output is subject to disclosure-avoidance review by FSRDC staff. FSRDC type facilities represent the highest level of security for protecting sensitive data, but are also more expensive than other methods which rely more on trust and less on physical security. Initial startup costs could reach hundreds of thousands to millions of dollars, and ongoing operating costs, while much lower, must cover full time staff and maintenance on the equipment.

An innovation on the physical data enclave is the SafePod network in the United Kingdom, which scales down a full-scale research data center. The SafePod has much lower installation costs than a full data center, around £25,000. It is a standardized, prefabricated unit that can be placed in any partner institution, and the pod itself serves as the physically controlled space. Like a FSRDC, a SafePod facilitates researcher access to data stored on statistical agency servers; in this case, with access to the data approved by the actual data providers while the partner institution handles local support and physical access controls. While the SafePod is still a physical location that requires installation and ongoing staff and maintenance, it is an example of innovation in physical data enclaves that makes this highest level of data security less costly.

#### Virtual Data Enclave

A virtual data enclave is conceptually similar to physical data enclaves, except there is no physically controlled space that the researcher must visit in order to access the data. Rather, researchers utilize different technical means to remotely access servers that store data and perform their analysis on the remote server. Software access controls perform automated scans of the output and prevent the researcher from removing data from the remote server.

Data providers using a virtual data enclave model maintain the servers that house the data and enable researchers to run their analysis, the connections with the thin clients and the remote desktops used to connect with the server. A virtual data enclave includes trained staff, who help process data and assist researchers. There are two basic approaches to the remote access mechanism: either using remote desktop software that the researcher can install on their own computer, or a dedicated computer (referred to as thin clients) that the data provider loans the researcher to connect to the server. To address physical security concerns, data providers can impose storage and safety requirements on researchers as part of the agreement that allows them access to the virtual data enclave or have dedicated staff conduct periodic audits.

The virtual data enclave model has a major advantage for researchers in that they no longer have to travel to specific facilities to perform their research. Furthermore, instead of the cost of maintaining an entire physical data enclave and the associated staff at each enclave, the data provider only needs to provide researchers with the necessary thin clients or remote desktop systems and can centralize their data staff.

The primary tradeoff is the slightly lower level of data security when the researcher accesses the data, as the data provider relies on only software level controls without the ability to physically check the researcher and their output as in a physical data enclave. However, with the proper implementation this level of security is still quite robust and less costly.

Statistics Denmark is one major statistical agency that uses a virtual data enclave model for access to their data. Researchers approved by Statistics Denmark can utilize specific client software for remote access to servers that house research data and perform their analysis through the client software. Researchers must sign agreements with Statistics Denmark with specific requirements to protect the physical security of the terminal that they use to access the server, consent to having their transactions on the server logged to prevent unauthorized copying of data, and ensure that they do not identify individual persons or enterprises in their output.

#### Researcher-Provided Infrastructure

In some data sharing arrangements, the data provider has the researcher provide the data storage, access, and analysis infrastructure. The data provider will provide the data to the researcher, who has custodianship over the data.

Data providers must ensure that they properly remove variables containing personally identifying information from data that they transfer to researchers in order to protect the privacy of study participants. In the instance that researchers have access to potentially identifiable data, the data provider must take care to ensure that the results produced for publication do not contain personally identifiable information. The data provider and researcher must have the technical means to securely transfer the data. Many such tools exist, including commercial enterprise level cloud services such as Google Drive, Box, and Dropbox that can be configured for secure data storage and transfer.

This process allows researchers significantly more flexibility and rapid turnarounds on research findings of importance to their government partners. Allowing researchers to store the data on their own devices may reduce the burden on data providers, who only have to provide the data itself and the staff necessary to transfer it to the researchers. On the other hand, data providers may also choose to conduct random on site inspections or have researchers submit their output for approval, which requires staff time. In instances where researchers can work very closely with the data providers’ technical staff with direct access to their data, they can also help the government learn more about their data and improve processes and systems at the government.

Many research projects and data providers utilize data transfers to researchers, particularly among smaller scale data providers for whom a more expensive data enclave model is less feasible. For example, San Francisco Unified School District has a long-standing partnership with Stanford University, where the Center for Education Policy Analysis (CEPA) at Stanford acts as a data warehouse for individual-level administrative data on behalf of the district. While many of the researchers who use the data are affiliated with CEPA, the CEPA has dedicated staff with no ties to specific research projects to manage the warehouse. The district approves researchers and projects to have access to the data, while the warehouse performs data cleaning, anonymization, and ultimately provides data files to the researcher.

Large scale implementations of the data transfer model for sensitive, individual-level data also exist. The U.S. National Center for Education Statistics maintains a restricted-use data license model that requires researchers to set up their own version of a physical enclave, at their home location, as a requirement for becoming a license holder. The researcher must maintain an access-controlled secure data room with specific physical and electronic protection requirements and must undergo random NCES audits to ensure compliance with these procedures. The data is transferred to the researcher via encrypted disks with the passwords sent separately, such that the data is protected in transit and only the researcher with both the data disk and password can access the data. Combining the efficiency of data transfer with the increased security of physical and electronic protection shows how data access can be tailored for individual circumstances based on sensitivity and cost needs.


### Examples from the handbook along the five metrics
#### SFUSD-Stanford
Data location: initially transferred to third party, limited set transferred to researcher
Analysis Computer: owned by researcher
Access Computer: owned by researcher
Acces Room: low security
Analysis method: unrestricted

#### New Brunswick

#### IAB

#### OLDA

#### Aurora

#### Cape Town
