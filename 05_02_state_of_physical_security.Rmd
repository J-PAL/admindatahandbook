```{r, echo=FALSE}
source("programs/_plot_physical.R") 
}

```

## Physically Protecting Sensitive Data

The physical protection of sensitive data is one of the key parameters that data custodians can and do influence. Within the Five Safes Framework, "safe settings" are heavily influenced by how data are physically protected. However, it is also the parameter that is most dependent on current technology. While sending around floppy disks to researchers who inserted them into desktop computers in a locked room, isolated from computer networks, was common in the 1980s, it has been superseded by technologies that provide similar or stronger security, combined with greater ease of access.

Possibly because technological advances happen faster than legal or cultural habits change, we have found that  data custodians and policy makers may not always be aware of the most current technological possibilities when crafting the legal and contractual framework for data access. This chapter sets out to describe the currently available spectrum of physical protection methods. We use a framework that defines five dimensions with which we can characterise a particular access mechanism. We then describe several actual examples, both from the case studies in this handbook as well as others that we are aware of. Finally, we caution readers that by the time that this chapter is being read, the range of possibilities may yet again have expanded (rarely does it contract). Technological obsolescence is intrinsic to a chapter relying so heavily on technology.

### Five Dimensions of Physical Security

In any data sharing setup, the fundamental setup always involves the original holder of the data, and access by a new entity. In the context of this Handbook, the original holder is the data custodian, and the new accessor is the researcher. Technology determines how the physical exchange and access may happen.

Here, we propose  five dimensions of physical data security to serve as a framework to evaluate the different defining features of various data access mechanisms. These are:

- the physical **location of analysis computers and the data**,
- the **control over analysis computers** that researchers are allowed,
- the **location and type of access computers**,
- the **level of security of  access locations**, and
- the **range of analysis methods available** to researchers.

When proposing and negotiating a potential use sharing agreement, evaluating the physical security arrangements along these five dimensions can help researchers and their data providers craft robust mechanisms to protect data when transferring and using data for research. Importantly, these physical access mechanisms in turn interact with the other four safes. We highlight such interactions in the examples provided.

For each dimension, classifications range from **1** to **3**, except for security, which has a range of **4**.

####  Location of Analysis Computers and Data

The researcher-accessible administrative data can be stored at one of three types of locations. The data can remain with  the data provider, the data provider can transfer the data directly to the researcher, or the data provider can transfer the data to a trusted third party. Each possible data location comes with its own requirements, advantages, disadvantages, and special considerations for the researcher and data provider.

| 1 | 2 | 3 |
|---|---|---|
| Data provider | Third-party | Researcher |

Key consideration for the choice of location is the level of trust that the data provider has in the entity controlling the new location. The enforcement of DUA or MOU is key. Transferring control to another entity might be desirable when support for many researchers is a burden for the regular business of the data provider. For instance, by transferring the data to the researcher, a data provider may no longer be responsible for the cost of providing computational infrastructure for data storage and analysis. On the other hand, costs of enforcing access restrictions, such as site visits, may be higher once physical custody of the data has been transferred.

In certain cases, the transfer to a third party or the researcher unlocks the possibility of combining data from multiple data providers. For instance, government departments responsible for immigration and taxes may not be legally allowed to share data, but they may each be able to transfer the data to a national statistical office. Similarly, multiple companies may not be willing (or legally allowed) to share data with one another, but may be able to transfer the data to trusted third parties. In other situations, one branch within a government department, responsible for enforcement, may transfer the data to another branch, whose business it becomes to make the data accessible. The advantages of this arrangement include having an organization that is more familiar with and responsive to the needs of the researchers handling the data as well as reducing the burden on staff and resources at the data provider.

Note that the location of the data on its own in no way defines how researchers access the data, or the type of analysis a researcher can conduct.

#### Researcher Control over Analysis Computers

Analysis computers are the computers on which researchers perform their analysis on and are by definition in the same location as the data. They need not coincide with the  computers which researchers use to access the data. The level of control that researchers are allowed over these computers may differ widely. In some cases, the researcher may have physical control over the analysis computer, in others, even software control is minimal. Of key interest to many researchers is the  software that researchers can utilize.

| 1 | 2 | 3 |
|---|---|---|
| Low | Medium | High |

In the least restrictive arrangement, researchers can have full  access to the analysis computers, with no restriction on the software that researchers can use to perform their analysis. The researcher may own and physically control the analysis computer, such as  when the data is transferred to the researcher. Even when administrative control over the analysis computer is retained by the data provider or a third party, the researcher may be able to request and utilize their choice of software on the analysis computers without much restriction.

>  One example of this is the way that NCES restricted-use data licenses operate. The researcher must set up a secure data room in accordance with NCES requirements, but is otherwise free to utilize whatever software they want to analyze the data.

In other instances, researchers only have limited control over the analysis computers. This may occur in cases where researchers only have remote access to the analysis computers. Limitations can range from a white (allowed) list of software, with no restrictions on packages that can be installed to augment that software (e.g., Stata, R, Python), to a pre-approved list of software, which can only be modified via an approval and security vetting process. This may be due to technical requirements related to computer and network security, as a mechanism for disclosure control, or the expense of acquiring or maintaining multiple sets of software. These restrictions affect not only the base software itself, such Stata or R, but also third party packages for those software; while the base software itself may be unrestricted, additional packages not signed by the original developer may not be allowed.

> The Federal Statistical Research Data Center network has a specific set of software that they make available to researchers, who must use one of the programs that the FSRDC has on their secure computing network. Additions must be approved by program managers and security analysts.

> The Norwegian data access mechanism runs only a limited set of Python modules, with no additions allowed.

> The Canadian Remote Access Mechanism runs only a limited subset of SAS commands, with no exceptions allowed.


#### Location and Type of Access Computers

Access computers (end points) are the computers researchers utilize to access the data. In some cases, access computers are co-incidental with analysis computers. However, when data is not in the same location, access computers are distinct from analysis computers. Access computers can be located at and be owned by the data provider,  the researcher, or a third party institution. However, ownership is not necessarily aligned with location. For instance, a researcher may be assigned a computer that serves both as an access and analysis computer, but which is owned by the data provider.

| 1 | 2 | 3 |
|---|---|---|
| Data provider | Third-party | Researcher |

If the access computer is located at the data provider or the third party (the *data access providers*), the researcher must travel to their location. This allows the data access providers maximum control over the access computer and its security arrangements, including physical monitoring, removing USB access ports, controlling user access to specific files and folders, and other measures.

> Example: Bureau of Labor Statistics Research Data Center in Washington DC. (maybe some of the examples in Handbook)

Note that when the access computer is located with the third party, travel may still be required, but typically over shorter distances.

> Example: NB. FSRDC (note that strictly speaking, FSRDC sites are under control of the US Census Bureau, but are located on university campuses or within other research institutions)

Access computers can be of several types. In some cases, the agreement may prescribe certain types of access computers, in others, they may remain undefined. When not further defined, a researcher may be able to use any computer for access, for instance, when access is via a secure website. VDI access, defined below, may be allowed from any computer capable of running the necessary software, including tablets. On the other hand, secure laptops with dedicated VPN setups and encrypted hard-drives may be deployed. In certain cases, dedicated thin clients, including zero-footprint thin clients, provide similar functionality as such dedicated laptops, without the computational capability that such laptops may have. As the enumeration of possibilities also makes clear: physical configuration control for such access computers may also differ widely. We discuss software configuration control below.

#### Security of Access Locations

The location of  access can have varying levels of security. We classify the levels of security into four levels, ranging from **open access** (no security) to **low, medium, and high** security arrangements. Unlike the other dimensions outlined above, these are not concrete distinctions between different mechanisms but rather broad classifications of the overall rigor of physical security regimes. Note that in some instances, specific rooms may be mandated, whereas the open access regime might not specify any specific location.

| 1 | 2 | 3 | 4 |
|---|---|---|---|
| High| Medium | Low | Open |

An **open access** arrangement is one where there are no mandated controls on the physical location of the access computer. The access computer is protected only by hardware and software configuration of the device itself. This is typically seen in remote submission systems, such as the IAB JoSuA interface where there are no explicit restrictions on where the researcher can use the interface. Trivially, this may be true when access and analysis computer are coincident with the researcher's laptop.

> Example: Access to IAB's Joshua can be from any internet connected computer, regardless of location.

A **low security** arrangement has a mandated location for the access room or other basic security precautions, but otherwise has no access controls outside of the control of the researcher. Frequently this takes the form of provisions in the data use agreement between the data provider and researcher mandating certain steps such as storing the data in a locked room, but the security arrangements are maintained by the researcher. In some cases, the data provider explicitly reserves the right to approve the security arrangements, conduct audits, or otherwise directly verify that the researcher is in compliance with the security requirements or the access room.

> French CASD mandates that thin clients be deployed in university offices, although relaxations were allowed during the 2020 COVID-19 worldwide health crisis. (CITATION)

> The SFUSD-Stanford data use agreement template mandates that Stanford researchers take “reasonable and appropriate efforts” to keep the data “in a space otherwise physically and electronically secure from unauthorized access”. However, the district does not exercise physical control over the researchers’ access room security.

> The requirements for the data location outlined in the NCES restricted-use data license is an example of a medium security arrangement under the control of the researcher. The data must be kept in a locked room with access restricted only to licensed researchers, with the security arrangements subject to random audits by NCES.


An access room with a **medium security** setup has mandated security features. Access is restricted to approved researchers, with a minimum of a physically secured facility such as a locked room where only approved researchers have key or keycard access.  Frequently, medium security room setups will be under the control of a third party or the data provider itself. This enables the room administrator to directly monitor who has access to the room and the physical security of the access computers within the room.

> Example are the IAB thin clients in various locations, including in North America. These are in a room under the control of the research institution hosting the thin client, and are not freely accessible to the researcher.

A **high security** access room has stronger specifications for physical security. This can include mandating that the room have secured walls that fully extend from the floor to ceiling with no gaps, electronic shielding for the room, video monitoring of the room, identity or biometric verification for people entering the room, and other security arrangements that extend beyond simple access controls for people entering the room. The NB-IRDT data centers, with their stringent access controls and additional physical safeguards such as bolting the server to the floor in a separate locked cage, falls into the high security category.

#### Analysis Methods

The range of analysis methods allowed by access systems can vary widely. Researchers may be able to leverage a wide range of analysis methods, ranging from simple tabulations to complex machine learning tasks. In other cases, they may be limited to a small set of methods, defined by the data custodian for technical or security reasons. Note that this dimension is distinct from the control that researchers have over software installation. A system may allow for any analysis method, as long as it is implemented in SAS - a situation where the software choices may be limited (and limiting for researchers), but where the analysis methods are nearly unrestricted.

| 1 | 2 | 3 |
|---|---|---|
| Restrictive | Medium | Flexible |

Environments with unrestricted analysis methods allow researchers to utilize the full range of methods available in the set of software that is available on the analysis computer, subject to other restrictions on the analysis computer as discussed in the previous section. Limited analysis methods place restrictions on what researchers can do, such as limiting the language set available to researchers to a whitelisted set of commands or utilizing online tabulators that limit the researcher to using conditional tables.

> Norwegian system is limited both to Python, and within Python, to a limited set of analysis methods, a strict subset of the Pandas package.  

> The IAB system only allows for Stata in Josua, but within Stata, few restrictions are imposed.

### Technical features, infrastructure, implementations

#### Remote desktop

Remote desktop systems (also referred to as Virtual Desktop Infrastructure, VDI) are software packages that enable users on one computer to connect to another computer over a network. This allows a researcher to use an analysis computer remotely, with the desktop environment of the analysis computer displayed on the client device, the access computer. This enables the data holder to retain full physical control over the analysis computer, which can be configured to prevent file transfers to the researcher’s computer, prevent the researcher from installing software, and other controls. Analysis computers (typically servers) typically run Microsoft® or Linux operating systems; clients to access the remote desktop exist on a variety of platforms, including cell phones and Apple computers. Vendors of such systems include [Microsoft®](https://www.microsoft.com/en-us/p/microsoft-remote-desktop/), [Citrix®](https://www.citrix.com/), [VMware®](https://www.vmware.com/), and [NoMachine®](https://www.nomachine.com/).

#### Thin Clients

Thin clients are computers that have been optimized for utilizing remote desktop software to connect to a server. Very restrictive implementations of thin clients can prohibit any usage beyond displaying information from the server and accepting mouse and keyboard input from the user. One of the main advantages of dedicated hardware thin clients is that they are cheaper and simpler than regular computers. As of the time of writing, thin clients can cost as little as $100 for the hardware itself, in contrast with the cheapest entry level computers which are several hundred dollars. Note however that most thin clients require a server-side infrastructure to support both access and security updates. Thin clients typically operate without local storage, thus preventing users from saving data to the client.

For data providers and researchers setting up remote access to analysis computers via thin clients, the clients themselves do not need to be capable of running statistical software or intensive analysis; the analysis will occur on the server that hosts the data and software packages. Thin clients can either be provided directly to researchers or be housed within a research data center. Thin clients can be sourced from many manufacturers of enterprise hardware, both as standalone devices for the user to configure as well as full fledged hardware and software package solutions configured by the vendor. Thin clients can be purchased from most business PC vendors, including [Dell®](https://www.dell.com/en-us/work/shop/wyse-endpoints-and-software/sc/cloud-client/thin-clients), [HP®](https://www8.hp.com/us/en/cloud-computing/thin-clients.html), as well as some custom-produced solutions, such as the "[SD-Box](https://www.casd.eu/en/technologie/sd-box/)" developed by and produced for ||CASD||.

![IMAGE of CASD thin client SD-Box](assets/images/casd-sd-box.png)

![IMAGE of a commercial zero-footprint thin client Wyse Zero Clients for VMware 5020-P25](assets/images/Dell-Wyse-LargePNG.png)

#### Biometric authentication

Biometrics are physical and biological features unique to individuals. Biometric authentication is the use of biometric features to verify the identity of individual users, such as fingerprints or iris scans. By verifying the user’s identity based on stored information about authorized users, biometrics can be used to authenticate authorized access to access computers, analysis computers, and access rooms. The main components of such an access system includes the biometric sensor itself, which is connected to a database that contains the set of validated users, and controls either the physical or electronic lockouts for a given system (e.g. entering a room or logging into a computer).

> The aforementioned CASD SD-Box has an integrated biometric fingerprint sensor.

Most biometric authentication techniques rely on the physical characteristics of individuals. One of the most common biometric technologies in current use is fingerprint scanners for consumer electronics such as laptops and smartphones. Other commonly used technologies include facial recognition, retinal or iris recognition, and voice identification. Biometric authentication techniques can serve both as a primary form of identification as well as being layered in two or multiple factor authentication techniques, such as in conjunction with passwords or other devices. When applied to physical data security, biometrics authentication can be required  by data providers as part of an access agreement, collected from authorized users, and implemented by any of the parties with administrative control over access rooms, access computers, and analysis computers as required.

#### Physical access cards

Physical access cards are electronic cards that identify the card bearer for a physical access control system. Access to devices or rooms are secured by a card reader validates the user’s card with a central database that has a set of valid cards and subsequently disables the locks on the system or room that it is protecting. The cards themselves can use magnetic stripes, barcodes, electronic fields, or other systems for interfacing with the card reader. Physical access cards are commonly used in universities and have the advantage of likely having existing infrastructure to support the creation of secure access rooms for researchers receiving administrative data.

> The aforementioned CASD SD-Box has an reader for an access card.

> The FSRDC system uses physical access cards and a lock system under control of the data provider, not the hosting institution (data intermediary).

#### Secure Rooms

Beyond access control, rooms can have various specifications for securing it against unauthorized access. Secure rooms may be required to be fully enclosed by walls that extend from floor to ceiling, minimize the number of possible entryways, have doors, windows, air vents, and other possible entryways secured by bars, mesh, or other methods. Doors and walls may have minimum specifications in terms of materials, construction techniques, and thickness to increase protection against physical attacks. For instance, reinforced doors and walls offer increased protection compared to regular home and office construction materials. Door hinges, access panels, partitions, windows, and other possible ways of entering the room may be installed from the inside of the secure room to prevent their removal from the outside. Additional requirements may extend to physically securing devices within the room. Finally, computer infrastructure may be required to have  no outside network connections (a so-called "air-gapped network"), or no network connection at all. Secure rooms may be mandated for both analysis computers as well as access computers, though they may not be held to the same standards.

#### IP address restrictions

When any network is involved, network access controls may be implemented. One way to ensure that only an authorized system has access to the remote system is to restrict the ||IP|| address of the devices that are allowed to connect to the server. There are two types of restrictions, blacklisting and whitelisting. Blacklisting specific addresses is used to block known or potential bad actors but otherwise does not restrict connections to the server; whitelisting only authorized users is the primary use of IP restrictions in an access control mechanism. This is frequently an option built into the software for managing the server. For example, software used for managing ||secure file transfer protocols|| can restrict the IP addresses that it will accept connections from. For data providers and researchers, this can be restricted to specific devices that the researcher registers with the data provider as the access computer.

Other, more sophisticated network access controls may also be implemented, as dictated by any one of the involved parties' IT security staff.

#### VPN

Virtual private networks (VPN’s) are used to allow two computers to connect over public networks as if they were directly connected on a private network. VPNs utilize an encrypted channel established between the remote computer and the network to securely transfer data and gain access to resources on the network. As typically implemented, users must authenticate themselves, such as with usernames and passwords, to access the VPN. VPNs can be used both for data transfer and for securing remote desktop access. For data sharing arrangements that allow for open access locations, VPNs can be particularly useful, as they allow the encryption (and therefore security) of any data that the researcher can access from a public network. Many universities have VPN services that allow researchers to access university networks from a remote location. In instances where a data sharing parntership has to implement a VPN from scratch, such as setting up a VPN service at a data provider sharing data for the first time, there are VPN configuration settings built into the Windows Server operating system; open source options are also available.

#### On-site storage

The proper secure data storage is important for all parties physically in custody of the data, whether that is the data provider or the researcher. Reliability and security are two main considerations for on-site storage of data. 

Reliability of storage refers both to preventing data loss as well as system uptime. The risk of data loss can be mitigated by using one or more of the following techniques. Multiple disks can be organized in a redundant array (RAID) such that the failure of any one (or sometimes multiple) disks does not result in the loss of data. Robust automated backup strategies tailored to the risk tolerance as well as any legal or data use agreement requirements can be used. Backup strategies involving manual action -- plugging in a USB drive in combination with scheduled backup software -- are fallible, but may be considered as a last resort.

When using servers to store data, maximizing system uptime is important to allow for the uninterrupted use of data for research. Specialized storage servers allow for maintenance, including hot-swapping storage drives, while the server remains available for use. Similarly, having a  USB drive with a current backup available mitigates the downtime should data be lost.

Online storage services implement these techniques as a normal part of their business, and may be one way researchers may leverage such techniques, if compliant with data use agreements.

Security in the context of setting up data storage is the prevention of unauthorized access to the data. On top of [Data access controls] for users, the storage device itself needs to be properly configured. When using storage servers, operating systems need to be kept up to date with security patches. [Encryption at rest](https://en.wikipedia.org/wiki/Data_at_rest#Encryption), i.e., the data is fully encrypted when not in use, provides protection in the event that an adversary  gets access to the storage device. Full disk encryption (FDE) of the storage device is when the entire hard drive is encrypted and needs to be unlocked before being used, and can be implemented in hardware or software. The data files themselves can also be encrypted (file-level encryption), and only decrypted when used .adver

Encryption may decrease convenience (a password or a hardware key need to be used each time decryption occurs). Full disk encryption occurs once when systems (servers, laptops) are booted up, and can be combined with [biometric authentication]. Data encryption may require that a hardware token be present any time data is processed, but such a hardware token may be embedded in the computer, or attached as a USB device. File-level encryption can also be used when using online storage systems. 

> Hardware-based FDE is offered by most storage drive vendors as an option.

> Operating system-level FDE is built into all major operating systems: [FileVault](https://it.cornell.edu/filevault) on MacOS, [Bitlocker](https://it.cornell.edu/bitlocker) on modern Microsoft Windows operating systems, and various systems on Linux OS.^[https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019] 

IT staff, where available, will be well versed in these techniques. Individual researchers, if receiving data, may want to consult with IT staff on how to implement an appropriate strategy. All of these elements will carry some cost, and should be factored into the project budget.

#### Data access controls

Access control regulates what users can view or use in a computing environment, preventing unauthorized users from accessing confidential data. This is of particular relevance for systems where multiple researchers utilize the same computing resources for access or analysis to data, whether with a compute server or a laptop. Access controls can be implemented by setting user permissions on directories at the operating system level on the analysis computer. Another method is to use a virtual machine, i.e. a completely isolated computing environment running on a host computer. A host computer can run multiple virtual machines, with each researcher or research project having a specific virtual machine. Each virtual machine is configured to provide access only to a specific (limited) set of data files, as defined by the access permissions of the research team. In addition, software availability or network access can be customized on a per-project basis. Containers, popularly known under as `Docker`, or Linux techniques such as `chroot`, achieve similar goals, with varying degrees of isolation and performance penalties.

> CASD uses a small set of standardized virtual machines running Microsoft Windows for research projects.

> The FSRDC uses a variant of the `chroot` setup on Linux servers.

#### Transfer mechanisms

The transfer of data between data providers, third parties, and researchers occurs in many data sharing partnerships. Data can be transferred through various network protocols, cloud services, or a physical medium that is exchanged between the various parties. 

Often used for small-scale transfers, physically media (USB sticks, CDROMs, hard-drives) should be encrypted at rest. Similar to [on-site storage], encryption can be hardware-based or through software. Popular software such as [GnuPG](https://gnupg.org/index.html) are free and easy to use, and available for all major operating systems. Decryption keys (passwords) should always be separately transmitted.

There are many network protocols used for transferring data. Data may be transferred peer-to-peer, or may require the use of an intermediate party that typically is not signatory to the data use agreement. Some obsolete but commonly used transfer protocols do not use encryption, are therefore vulnerable to data being read in transfer, and should not be used. Any transfer protocols should use be encrypted in transit, while endpoints should have encrypted [on-site storage]. Secure peer-to-peer transfer can use the SSH File Transfer Protocol (SFTP), or authenticated transfer via HTTPS, the same protocol used by banks and most other modern websites. which encrypts the data sent between the client and server. Transfer over a [VPN] is also encrypted, regardless of transfer protocols, including for shared directory mounts (Windows shares, NFS).

The use of cloud storage services^[As of 2020, the following are vendors of cloud storage services: Google Drive, Dropbox, Box, Microsoft OneDrive. Cloud storage-like mechanisms can also be implemented by data providers or intermediaries, by using open source software such as [Nextcloud](https://en.wikipedia.org/wiki/Nextcloud).]  
also support the encrypted transfer of data. Encryption of data when stored at the vendor's servers may vary, and encryption of data at the endpoints (data provider, researcher) is determined by the setting for [on-site storage]. It should be noted that while data may be encrypted, the cloud storage service may be able (or even legally obligated) to be able to decrypt the data. Thus, utilizing cloud storage services requires placing the data under the control of a third party, which may be prohibited depending on the data sharing agreement. 

### Typical access mechanisms

In this section, we illustrate a few typical access mechanisms. The case studies in this handbook are all additional examples.

#### Remote Execution

Under a remote execution model, the researcher has no direct access to the analysis computer or the confidential data. In order to conduct an analysis, a researcher needs to submit a request to have the data provider run the analysis on behalf of the researcher and share only the summary output, with the researcher never having access to the actual data.

Remote execution requires that the data provider maintain a mechanism for executing researchers' code, rather than  researcher doing that themselves. Such a mechanism may be an automated service, or staff time. In the latter case, staff are required to have   the technical expertise to interface with researchers, run the researchers’ analysis. Staff or systems will also conduct disclosure avoidance checks on  the output before sending it back to the researchers. 

The data provider also needs to create and maintain the systems to facilitate the transfer of the necessary files. This may involve providing test files to researchers, receiving and tracking analysis files, and transmitting the output. The availability of accurate codebooks and data documentation greatly improves the process. Test files are data files that have the same variables and table structures as the real data, but have fictitious values for the variables.

Thus, data providers maintain full control over the data, and have the unique opportunity to check the researchers’ code prior to execution. Because researchers need to specify the analysis carefully, iterative or exploratory analysis may be inhibited or reduced. For some researchers, this may be perceived as an impediment; however, for researchers working under a pre-registration paradigm, the same restriction may be perceived as an advantage.

A downside for the data provider is the cost of providing the necessary resources (systems and staff time) to conduct the analysis. In some instances, cost is recovered by charging researchers. 

Metrics: remote execution setups will locate the analysis computers and data at the data provider or third party. Researchers will have have low control over the analysis computers, as they never interact directly with the analysis computers. Access computers can be at any location, although most remote execution models involve researchers submitting their analysis files from a location distinct from the location of the analysis computer. The security of the access location can also vary widely, as remote execution jobs can be submitted from a variety of locations. Analysis methods are typically restrictive in remote execution setups, as the researcher can only use methods approved by the data provider or third party that executes the job submission.


#### Physical Data Enclave

In a physical data enclave model, researchers must enter a secure room (the "data enclave") to access the data and run their analysis code. The data provider can choose to store the data either on site at the data enclave itself, or store the data on a remote server that can only be accessed by specifically configured computers located within the data enclave. 

To run a physical data enclave, a data provider needs to have an access-controlled space for researchers to work in. The secure room is provisioned with the requisite analysis computers (possibly servers), access computers, and software packages. The data provider typically has staff or automated systems to ensure that only authorized researchers enter the secure room. Systems or people, not necessarily the same, may also be responsible for ensuring that only "safe outputs" are removed from enclave.

The data provider gets most of the security benefits of remote execution by maintaining full control over the data in the entire research process. It removes the potential bottleneck and additional expense of requiring dedicated staff on the part of the data provider to actually run the analysis on behalf of the researcher. 

However, physical data enclaves still impose restrictions on the flexibility of researchers. Instead of waiting for someone to run the remote execution for them, researchers have to schedule visits to a physical location. Travel, with associated costs, is often required. It also requires the data provider to provide the physical and technical infrastructure for researchers to conduct their research in a secure location. Meeting safety requirements can impose a substantial initial start-up cost on new sites.

Along the five metrics, physical data enclaves will locate the data and analysis computers at the data provider or a third party, either on site at the data enclave or elsewhere. Researchers will generally have low or medium control over analysis computers, as those are in the custody of the data custodian. The data enclave itself houses the access computers, which can be the same as the analysis computer or a separate device that has a remote connection to the analysis computer. The security of the access location is typically medium or high security, as that is the defining feature of the physical data enclave. Physical data enclaves can allow for any level of flexibility of analysis methods.

We note that a variant of this model, typically not referred to as "enclave," is when the analysis computer is on university premises, but in a secure room under control of the researcher, such as a locked faculty office. In such a case, no separate staff or systems are needed to control exit or entry of people and results, since this is delegated to the researcher (typically by a contractual arrgangements specifying the nature of "safe outputs").


#### Virtual Data Enclave

A virtual data enclave is conceptually similar to physical data enclaves, except there is no physically controlled space that the researcher must visit in order to access the data. Rather, researchers utilize different technical means to remotely access servers that store data and perform their analysis on the remote server. Typically, researchers using virtual data enclaves use remote desktop software to connect. In most cases, the researcher is prevented from removing data from the remote server.

Data providers using a virtual data enclave model maintain the servers that house the data and enable researchers to run their analysis, and the computer connections allowing researchers to connect with the server. Alternatively, this may be outsourced to a cloud provider or specialized services. There are two basic approaches to the remote access mechanism: either using [remote desktop] software that the researcher can install on their own computer, or a dedicated computer (referred to as thin clients) that the data provider loans the researcher to connect to the server. 

The virtual data enclave model has a major advantage for researchers in that they no longer have to travel to specific facilities to perform their research, though some restrictions may still apply. Furthermore, instead of the cost of maintaining an entire physical data enclave and the associated staff at each enclave, the data provider only needs to provide researchers with the necessary thin clients or remote desktop systems and can centralize their data staff.

The primary tradeoff is the slightly lower level of data security because the data provider no longer controls the physical environment from which the researcher accesses the data.

Along the five metrics, virtual data enclaves are similar to remote execution setups. The location of the data and analysis computers is always at the data provider or a third party that acts as the data custodian. Researchers will generally have low or medium control over analysis computers; they will be able to access them remotely, subject to whatever restrictions the data custodian implements. Any level of security for access computers or analysis methods can be implemented with virtual data enclaves.

#### Researcher-Provided Infrastructure

In some data sharing arrangements, the data provider has the researcher provide the data storage, access, and analysis infrastructure. The data provider will provide the data to the researcher, who has custodianship over the data.

> STRIKE: THIS IS NOT ABOUT PHYSICAL SECURITY. Data providers must ensure that they properly remove variables containing personally identifying information from data that they transfer to researchers in order to protect the privacy of study participants. In the instance that researchers have access to potentially identifiable data, the data provider must take care to ensure that the results produced for publication do not contain personally identifiable information. The data provider and researcher must have the technical means to securely transfer the data. Many such tools exist, including commercial enterprise level cloud services such as Google Drive, Box, and Dropbox that can be configured for secure data storage and transfer.

This process allows researchers significantly more flexibility and rapid turnarounds on research findings of importance to their government partners. Allowing researchers to store the data on their own devices may reduce the burden on data providers, who only have to provide the data itself and the staff necessary to transfer it to the researchers. On the other hand, data providers may also choose to conduct random on site inspections or have researchers submit their output for approval, which requires staff time. In instances where researchers can work very closely with the data providers’ technical staff with direct access to their data, they can also help the government learn more about their data and improve processes and systems at the government.

In this arrangement, the location of the data, analysis computers, and access computers are at the researcher. They will have full control over the analysis computers and analysis methods. The security of the access location can also vary widely, but is dependent on the specific requirements that the data provider sets on the researcher.

### Examples from the handbook

In this section, we explore how the five dimensions map onto the case study chapters in the handbook. Each set of data providers and researchers utilizes a unique combination of the five metrics for their data sharing framework.

#### San Francisco Unified School District (SFUSD)-Stanford Partnership

```{r, echo=FALSE, fig.width=4, fig.height=2}
sfusd = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,3,3))
plot(sfusd)

```

In the SFUSD-Stanford Partnership, SFUSD uses the CEPA Data Warehouse as a trusted data service that ultimately transfers a restricted set of data to the researcher. The location of the analysis computers and the data are therefore at the researcher, and the access computer is the same as the analysis computer. Computers used to hold and analyze SFUSD data are subject to Stanford and SFUSD requirements for data security, including enterprise operating system management and whole disk encryption for any device that holds the data. The researchers otherwise have a high degree of control over the analysis computer. The access rooms are low security; researchers must take reasonable measures to physically protect the data but there are no specific requirements or checks on the location of the data itself. Typically this takes the form of storing the researcher’s computer in a locked office, although in the case of graduate student researchers the offices may be shared. The analysis methods are unrestricted, with researchers being able to use any set of statistical software that they can acquire for analysis.

#### NB Institute for Research, Data and Training (NB-IRDT)

```{r, echo=FALSE, fig.width=4, fig.height=2}
nbirdt = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(2,2,1,1,2))
plot(nbirdt)
```

The NB-IRDT serves as a third-party data center for the various data providers that supply it with data to make available to researchers. The data location, access computers, and analysis computers are all located on site at NB-IRDT facilities. Researchers use workstations to remotely access data from a central server, and store their data on a local server at the specific facility that the researcher is at. Researchers have partial access to analysis computers, without the ability to  Researchers have limited access to the access computer, with stringent security requirements placed upon their usage of the research workstation. The access room is under high security, with strong specifications of security such as restricting mobile devices and outside materials, physical controls on the servers and workstations, and having dedicated fiber optics cables to handle data connections between the central and satellite locations. [Missing information about access computer software and analysis methods from chapter]

#### Institute for Employment Research (IAB)

```{r, echo=FALSE, fig.width=4, fig.height=2}
iab1 = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(2,2,2,1,2))
plot(iab1)
```

The IAB uses three different access models, each with its unique implementation of the five metrics of data security. The most restrictive access method is the IAB on-site access method, where researchers must go to an affiliated research data center. In this model, the data location and analysis computers are both located at the IAB, which acts as a third party for the German Federal Employment Agency. Researchers have restricted access to the analysis computers, including not being allowed to install their own software. The access computers are located at RDC’s under the control of the IAB itself or third-party partner institutions, consisting of secured workstations at RDC-IAB and thin clients at its partner institutions. The analysis methods are limited to the statistical software packages available at the specific RDC. The room security depends on the specific RDC, although all RDC’s generally have strong physical specifications for security with additional restrictions beyond just access controls managed by the RDC administrator.

```{r, echo=FALSE, fig.width=4, fig.height=2}
iab2 = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(2,2,3,4,2))
plot(iab2)
```

For IAB remote execution, the data location and analysis computers are both still under the control of the IAB. Analysis methods are limited to preparing program code on test data to run on the analysis computers at the IAB. However, the access computer is the researcher’s own device utilizing the JoSuA portal to submit requests to the IAB. The access room is open with no security requirements, as the researchers are limited to the deidentified output from the JoSuA system.

```{r, echo=FALSE, fig.width=4, fig.height=2}
iab3 = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,2,3))
plot(iab3)
```

The IAB also makes anonymized data products available for direct download by researchers. In this instance, the data location, acces, and analysis computers are at the researcher’s institution, with researchers having full administrative control over the computer systems. As a result of that, they have the full range of analysis methods available as well. The IAB data use agreement for downloading the scientific use files specifics medium security requirements, with the building and room required to have some level of access control or monitoring against unauthorized access; options range from receptionists and security guards to admission simple key locks. There are additional requirements for electronic security such as encrypting the computers and servers with access to the data. Note also that scientific use data can only be accessed by European institutions, though this is not captured here ("safe people").

#### Ohio Longitudinal Data Archive (OLDA)

```{r, echo=FALSE, fig.width=4, fig.height=2}
olda = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,3,3))
plot(olda)
```

The Ohio Longitudinal Data Archive is a third party organization that provides data to researchers on behalf of the government. The data is initially located at the third party institution before ultimately being transferred to researchers via a secure FTP server. The researchers have full control over the analysis and access computer, which is required to be a desktop computer located in the researcher’s office space. This is a low specification of access room security, placing no additional requirements beyond utilizing a specific space. Researchers have full analysis methods available for them. Data can be provided in a variety of formats, including CSV files that enable the researcher to use any analysis software or method of their choosing.

#### Aurora Healthcare

```{r, echo=FALSE, fig.width=4, fig.height=2}
aurora = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,3,3))
plot(aurora)
```

The researchers for this project received data from the data provider via a secure file transfer protocol. The data location, acces computer, and analysis computers were all located at the researcher’s home institution. [need more info from Amy and Laura]

#### Cape Town

```{r, echo=FALSE, fig.width=4, fig.height=2}
data = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,3,3))
plot(data)
```

In the Cape Town partnership, the data was transferred from the data provider to the researcher. As such, the data location, access, and analysis computers are all with the researcher, with the researcher having a full range of analysis methods available. [need more information about access rooms, some more detail about how they did the transfer and storage etc]

### Other examples 

#### Statistics Canada's Real Time Remote Access

```{r, echo=FALSE, fig.width=4, fig.height=2}
data = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(1,1,3,4,1))
plot(data)
```

The **[Real Time Remote Access](https://www.statcan.gc.ca/eng/rtra/)** system provides access to a large number of surveys. Users can univariate statistics (histograms, quantiles, means) as well as ratios. SAS is the only allowed software, and a maximum number of procedure calls are allowed per day. Output is protected via controlled rounding, and can be downloaded by users after successful execution. No manual processing happens at any stage. A registration and contract are required for access, and researchers must be affiliated with a government department, non-profit organization, or an academic institution.

#### Statistics Norway's Remote Access System

```{r, echo=FALSE, fig.width=4, fig.height=2}
data = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(1,1,3,4,2))
plot(data)
```


The **[microdata.no](https://microdata.no)** system provides a facility to analyze Norwegian register data. The system allows for descriptive statistics as well as a small set of regression methods and  analysis of variance. Automated anonymization processes have been implemented, and microdata cannot be viewed. Researchers must be affiliated with (Norwegian) institutions having an agreement with Statistics Norway. A custom programming interface is used, based on Python augmented with four (commonly used) Python modules, but limited to certain functionality. 

> NOTE: We have coded the security of the Access Room as `open`, as researchers  affiliated with Norwegian institutions are allowed access from anywhere (`high`). The system is not accessible, however, to researchers from elsewhere - this is not reflected in these metrics, as it relates to "secure people" dimension of the Five Safes.



#### Federal Statistical Research Data Centers (FSRDC)

```{r, echo=FALSE, fig.width=4, fig.height=2}
data = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(1,2,2,1,3))
plot(data)
```

The Federal Statistical Research Data Center (FSRDC) network in the United States, where federal statistical agencies partner with research institutions to provide secure data access facilities managed by the US Census Bureau, is a variant of the physical enclave model. Until 1999, data was physically housed in secure rooms at university institutions. In the system as of 2020, research institutions maintain the secure room housing the client computers, but the analysis computers are housed in a computer center maintained by the U.S. Census Bureau in Suitland, Maryland. For Census Bureau data, the data custodian remains unchanged, but when data is provided by other statistical agencies, the Census Bureau acts as a trusted third-party. Researchers must be approved by the data providers, and must pass background checks by the Census Bureau before gaining access to the facility and data. Researchers cannot remove output from either the secure room, or the analysis computer. Access to the secure rooms is controlled by access systems under control of the Census Bureau, not the host institution, and for some data access, a Census Bureau employee must be present in the secure room when researchers access the data. Access is via [remote desktop]. While there is an (increasing) number of FSRDC locations throughout the country, for some researchers, travel is still required. A wide variety of analysis methods and software is available (SAS, Stata, Matlab, Python, R, and others), and there is a limited ability to request the installation of additional software.

FSRDC type facilities represent the highest level of security for protecting sensitive data, but are also more expensive than other methods which rely more on trust and less on physical security. Initial startup costs could reach hundreds of thousands dollars, and ongoing operating costs, while much lower, must cover full time staff and other cost recovery.


#### Safepod

[update this]
An innovation on the physical data enclave is the SafePod network in the United Kingdom, which scales down a full-scale research data center. The SafePod has much lower installation costs than a full data center, around £25,000. It is a standardized, prefabricated unit that can be placed in any partner institution, and the pod itself serves as the physically controlled space. Like a FSRDC, a SafePod facilitates researcher access to data stored on statistical agency servers; in this case, with access to the data approved by the actual data providers while the partner institution handles local support and physical access controls. While the SafePod is still a physical location that requires installation and ongoing staff and maintenance, it is an example of innovation in physical data enclaves that makes this highest level of data security less costly.

#### French

```{r, echo=FALSE, fig.width=4, fig.height=2}
data = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(1,2,2.5,3,3))
plot(data)
```


#### National Center for Education Statistics (NCES) Restricted Use Data License

```{r, echo=FALSE, fig.width=4, fig.height=2}
nces = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(3,3,3,2,3))
plot(nces)
```

The NCES, a part of the United States Department of Education, allows researchers to apply for a restricted use data license to store data on site at the researcher. The data location, access computer, and analysis computers are all under the control of the researcher, with specific security requirements for the computers, the storage mediums that researchers receive the data on, and any physical documentation. With full administrative control of the analysis computers, researchers also have no restrictions on the analysis methods that they are allowed to use. NCES mandates a medium level of security for the access room, requiring that it must be a locked room with access restricted to authorized users but without additional specifications for security. The security arrangements must be approved by NCES prior to the receipt of restricted use data and are subject to unannounced inspections.

#### Bureau of Labor Statistics (BLS) Onsite Access

```{r, echo=FALSE, fig.width=4, fig.height=2}
bls = data.frame(metrics=c("Data Location","Analysis Computer","Access Computer","Access Room","Analysis Method"),
                  rank=c(1,1,1,1,2))
plot(bls)
```

The BLS has two research data centers in its national office at Washington D.C. for access to particularly sensitive research files and surveys that are not available offsite or through the FSRDC network. The data location, access computers, and analysis computers are all located and controlled by BLS. As with other research data centers, there is a high specification of security for the access room, with access limited to approved researchers and all materials subject to search when entering or exiting the facility. Analysis methods are restricted to pre-installed versions of SAS, Stata, and SPSS, with limited use of approved statistical software and data files that can be installed by the BLS staff.

