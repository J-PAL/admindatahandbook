```{r, echo=FALSE}
source("programs/_plot_physical.R")
```

## Physically Protecting Sensitive Data

The physical protection of sensitive data is one of the key parameters of any data access mechanism that the various stakeholders must address. Within the Five Safes Framework, "safe settings" are heavily influenced by how data are physically protected. However, it is also the parameter that is most dependent on current technology. While sending around floppy disks to researchers who inserted them into desktop computers in a locked room, isolated from computer networks, was common in the 1980s, it has been superseded by technologies that provide similar or stronger security, combined with greater ease of access.

Possibly because technological advances happen faster than legal or cultural habits change, we have found that data custodians and policy makers may not always be aware of the most current technological possibilities when crafting the legal and contractual framework for data access. This chapter sets out to describe the currently available spectrum of physical protection methods. We use a framework that defines five dimensions with which we can characterise a particular access mechanism. We then describe several actual examples, both from the case studies in this handbook as well as others that we are aware of.

We caution readers that by the time that this chapter is being read, the range of possibilities may yet again have expanded (rarely does it contract). Technological obsolescence is intrinsic to a chapter relying so heavily on technology. Furthermore, the difficulty of implementing any given data access mechanism is contingent on the local conditions and available resources. Due to the many possible factors that go into the decision of where along each dimension a data access mechanism will reside or which technologies to include as part of the setup, we cannot make a comprehensive set of recommendations for data providers and researchers. What this chapter can provide are recommendations for a minimum baseline of security features that data access mechanisms should include and a framework for evaluating the tradeoffs between addressing likely threats while maintaining useful access and minimizing costs.

Readers must note that physical security is only one component of protecting individuals in data and safely using data for research, and cannot be considered on its own. The ethical usage of data for research is governed by institutional review boards (IRB’s), the legal framework is set by data use agreements (DUA’s), and additional security measures take the form of ||statistical privacy protection||. The physical security of data access mechanisms do not operate in a vacuum, and we direct readers to our other technical chapters for a more holistic view of data access, usage, and security.

Throughout the chapter, we refer to data providers, data custodians, access providers, third parties, and researchers. Data providers are entities that generate data used in the course of administering their organizations or programs, and are able to provide such data to others under certain circumstances. Data providers include government agencies, nonprofits, and private firms. Data custodians are the party that holds the administrative data for access by approved researchers, while access providers are the party that facilitates this access. Neither of these necessarily have to be the data provider. Third parties can serve as data custodians or access providers through legal mandates or agreements with data providers, including entities such as national statistical agencies or research data centers at universities. External researchers are the end user of interest for administrative data, who can receive administrative data directly from the custodian or have to access the data under controlled settings. While there are other end users, including researchers belonging to the data providers and other external parties, the physical security considerations for the provision of data for external research is the focus of this chapter.

### Types of Security Threats

There are a variety of security threats, each with different levels of likelihood, severity, and considerations that are unique to the specific context of each data sharing agreement and access mechanism. Depending on the context, actions taken to address any given threat may be absolutely necessary no matter the cost or how much impedes the ability to conduct research, or may be cost-inefficient for what it is intended to protect against. Data providers and researchers looking to set up new data access mechanisms should carefully judge the likely threats, their severity, and what cost-effective ways of addressing them are.

The archetypal threat to data security is the active, unauthorized access by adversarial actors. There are two main mechanisms in which this occurs. Adversarial actors can exploit technical vulnerabilities, such as improperly secured computer systems and networks, in the data access mechanism. They can also utilize social engineering, which is the use of deception to manipulate individuals into granting access to the data either directly or through by obtaining the  credentials of otherwise authorized users. There are many possible incentives for adversarial actors to compromise data: targeted attacks for the sake of exploiting specific data, targeting organizations to inflict financial or reputational harm, attacks of opportunity for financial or reputational gain, or functionally random targeting simply because they can. One cannot assume that any particular set of data is not of interest for adversarial actors merely due to the contents of the data or the organization that holds it.

> One of the most infamous examples of data breaches due to adversarial actors exploiting technical vulnerabilities is the Equifax data breach of 2017.^[https://epic.org/privacy/data-breach/equifax/] Equifax neglected to apply security patches on their servers, leading to adversarial actors compromising their computer systems and the private information of over 148 million people.

A related security threat is the unintentional breach where data is left unsecured by authorized users. In this scenario, the data is breached not by any deliberate attempt by unauthorized users to gain access but by behavior on the part of authorized users that leaves it exposed, such as by losing devices that contain or can access data. These breaches can still lead to data ending up in the hands of adversarial actors seeking to exploit the confidential data. Like with adversarial actors, these measures are aimed at preventing unauthorized users from gaining access to the data when they should not, and different measures may be appropriate depending on the setting and sensitivity of the data. Collectively, deliberate attacks by adversarial actors and unintentional breaches can both be categorized as unauthorized access.

> The 2008 theft of a Stanford University employee laptop^[https://news.stanford.edu/news/2008/june11/laprelease-061108.html] that was left unsecured and unencrypted is an example of the unintentional breach of the data. While there was no evidence that the laptop was targeted due to it containing sensitive data, the theft led to the possible breach of the personal information of up to 60,000 Stanford University employees whose data were on the laptop.

The third main category of security threats is where authorized users become bad actors and use the data in unauthorized ways. Unlike the other two threats, this is a situation where the threat comes from within the framework of the data access mechanism. This is an inherent risk in granting access to the data to outside users. Users may wish to conduct analyses that were unauthorized by the data provider, exploiting the data for personal gain unrelated to its analytical use, or simply forget their obligations to protect the data. Traditionally this is often addressed through non-technical means, including conducting background checks, laying out civil and criminal penalties for unauthorized use, and other methods. However, features of data access mechanisms can be crafted to address this threat as well.

> The Facebook-Cambridge Analytical data scandal is an example of the misuse of data by otherwise authorized users. While the technical details are complex, the chain of events started with an individual collecting Facebook user data by creating an app using a Facebook feature allowing users to log into the app using their Facebook credentials; this collection of Facebook user data by developers was within the bounds of Facebook’s terms of service. He subsequently provided the data to Cambridge Analytica in violation of Facebook’s terms of service for app developers, which was the actual misuse of the data.

### Technical features of data access mechanisms

There are a variety of technical tools that can be used to protect against these security threats and are important for the implementation of secure data access mechanisms. We provide a brief introduction to a list of important systems and concepts, which is by no means exhaustive. These tools broadly correspond to protecting three areas data access mechanisms - protecting the transfer and storage of data, facilitating and managing researcher access to the data, and providing secure locations for data access. Many computer security best practices, such as using strong passwords and anti-virus software, are deliberately left off this list as they are not unique or central to data access mechanisms. Data providers and researchers looking to implement new or review existing data access mechanisms should consult with their institutions’ IT and security staff.

#### Encryption

Encryption is a cornerstone of information security. Fundamentally, encryption is process of encoding information using a process that prevents other parties from reading it without the encryption key. Modern computer encryption methods rely on encryption keys that are so large, with a sufficient number of possibilities that they are functionally immune to brute force attacks from all but the most sophisticated state actors. However, encryption methods are in a state of constant evolution as attackers seek new ways of defeating existing methods or bypassing them all together while the other side patches existing vulnerabilities and creates new, more secure methods.

While using encryption may decrease convenience (a password or a hardware key needs to be used each time decryption occurs), utilizing encryption for data and devices should be mandated as a minimum security feature part of any data access mechanism. In almost all cases, there is zero added monetary expense for encrypting existing data and devices, in return for a substantial increase in protection against unauthorized access. IT staff, where available, should be well versed in these techniques. Individual researchers, if receiving data, should consult with IT staff on how to implement an appropriate strategy. All of these elements will carry some cost, and should be factored into the project budget. While utilizing encryption is a basic computer security best practice, it is of particular relevance for data access mechanisms due to the many methods of using encryption for storing and transferring data, with implementations described below.

#### Physical media

Physical media include devices such as USB sticks, CDROMs, and external hard-drives. These can be used as part of a data access mechanism that involves the transfer of data between parties, such as from a data provider to a researcher. Physical media are typically used for smaller scale or one time data transfers, as there are inherent inefficiencies with sending physical media back and forth. Physical media intended for data transfers should always be encrypted at rest. The encryption of these devices can be hardware-based, through protections built into the device itself, or through external software. Popular software such as [GnuPG](https://gnupg.org/index.html) are free and easy to use, and available for all major operating systems. When using physical media, the decryption keys (passwords) should always be transmitted separately; this prevents an unauthorized user who manages to obtain either the decryption key or the physical media from accessing the protected data. Data should never be transferred via unencrypted physical media, which poses an extremely high risk for unauthorized access in the event that the device is lost or stolen.

#### Network Protocols

There are many network protocols used for transferring data or establishing secure connections between computers. Data may be transferred peer-to-peer, or may require the use of an intermediate party that typically is not signatory to the data use agreement. Some obsolete but commonly used transfer protocols do not use encryption, are therefore vulnerable to data being read in transfer, and should not be used. Any transfer protocols should be encrypted in transit, while endpoints should have encrypted [on-site storage]. Secure peer-to-peer transfer can use the SSH File Transfer Protocol (SFTP), or authenticated transfer via HTTPS, the same protocol used by banks and most other modern websites, which encrypts the data sent between the client and server. Transfer over a [virtual private network] is also encrypted, regardless of transfer protocols, including for shared directory mounts (Windows shares, NFS). For data access mechanisms that rely on electronic transfers between the data custodian and researcher, using an encrypted transfer protocol is a minimum security practice that should be followed at all times.

#### Cloud Service

The use of cloud storage services^[As of 2020, the following are vendors of cloud storage services: Google Drive, Dropbox, Box, Microsoft OneDrive. Cloud storage-like mechanisms can also be implemented by data providers or intermediaries, by using open source software such as [Nextcloud](https://nextcloud.com/).] also support the encrypted transfer of data. Encryption of data when stored at the vendor's servers may vary, and encryption of data at the endpoints (data custodian, researcher) is determined by the setting for [on-site storage]. While the cloud service may encrypt any data stored on its servers, the cloud storage service may be able (or even legally obligated) to be able to decrypt the data. Thus, utilizing cloud storage services may place the data under the control of a third party, which may be prohibited depending on the data sharing agreement or relevant legal constraints. Many cloud vendors offer enterprise services that can meet higher standards of security suitable for meeting regulatory or legal requirements, or prevent the service provider from decrypting the data. In settings where cloud services are allowed, data sharing agreements may mandate the separate encryption of the data files before placing them on the cloud server. Encrypted cloud services can also fulfill the requirement for a minimally secure electronic transfer protocol.

#### On-site storage

The proper secure data storage is important for any party serving as a data custodian, whether that is the data provider, a third-party, or the researcher. Reliability and security are two main considerations for on-site storage of data.

Reliability of storage refers both to preventing data loss as well as maintaining system uptime. The risk of data loss can be mitigated by using one or more of the following techniques. Multiple disks can be organized in a redundant array (RAID) such that the failure of any one (or sometimes multiple) disks does not result in the loss of data. Robust automated backup strategies tailored to the risk tolerance as well as any legal or data use agreement requirements can be used. Backup strategies involving manual action -- plugging in a USB drive in combination with scheduled backup software -- are fallible, but may be considered as a last resort.

When using servers to store data, maximizing system uptime is important to allow for the uninterrupted use of data for research. Specialized storage servers allow for maintenance, including hot-swapping storage drives, while the server remains available for use. Similarly, having a USB drive with a current backup available mitigates the downtime should data be lost.

Online storage services implement these techniques as a normal part of their business, and may be one way researchers may leverage such techniques, if compliant with data use agreements.

Security in the context of data storage is the prevention of unauthorized access to the data should an adversary gain access to the storage device. On top of [data access controls] for users, the storage device itself needs to be properly configured. When using storage servers, operating systems need to be kept up to date with security patches. Keeping the data fully encrypted when not in use, known as encryption at rest, provides protection in the event that an adversary gets access to the storage device. Full disk encryption (FDE) of the storage device is when the entire hard drive is encrypted and needs to be unlocked before being used, and can be implemented with both hardware or software methods. The data files themselves can also be encrypted (file-level encryption), and only decrypted when used.

Full disk encryption occurs once when systems (servers, laptops) are booted up, and can be combined with [biometric authentication]. Data encryption may require that a hardware token be present any time data is processed, but such a hardware token may be embedded in the computer, or attached as a USB device. File-level encryption can also be used when using online storage systems. Operating system-level FDE is built into all major operating systems: [FileVault](https://support.apple.com/en-us/HT204837) on MacOS, [Bitlocker](https://docs.microsoft.com/en-us/windows/security/information-protection/bitlocker/bitlocker-overview) on modern Microsoft Windows operating systems, and various systems on Linux OS.^[https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019]

#### Data access controls

Data access controls are of particular relevance for systems where multiple researchers utilize the same computing resources for access to or analysis of data. Access control regulates what users can view or use in a computing environment, preventing unauthorized users from accessing confidential data. Access controls can be implemented by setting user permissions on directories at the operating system level on a computer. Another method is to use a virtual machine, which is a completely isolated computing environment running on a host computer. A host computer can run multiple virtual machines, with each researcher or research project having a specific virtual machine. Each virtual machine is configured to provide access only to a specific (limited) set of data files, as defined by the access permissions of the research team. In addition, software availability or network access can be customized on a per-project basis. Containers, popularly known as `Docker`, or Linux techniques such as `chroot`, achieve similar goals, with varying degrees of isolation and performance penalties.

#### VPN

Virtual private networks (VPN’s) are used to allow two computers to connect over public networks as if they were directly connected on a private network. This is useful for data access mechanisms that allow researchers to access data from a many possible locations as well as for data transfers, as VPN's allow the encryption (and therefore security) data passing through a public network. VPNs utilize an encrypted channel established between the remote computer and the network to securely transfer data and gain access to resources on the network. As typically implemented, users must authenticate themselves, such as with usernames and passwords, to access the VPN. Many universities have VPN services that allow researchers to access university networks from a remote location. In instances where a data sharing partnership has to implement a VPN from scratch, such as setting up a VPN service at a data provider sharing data for the first time, there are VPN configuration settings built into the Windows Server operating system; open source options are also available.

#### IP address restrictions

When any network is involved, network access controls may be implemented. One way to ensure that only an authorized system has access to a remote system is to restrict the IP address of the devices that are allowed to connect to the server. This can be useful for performing data transfers as well as for remote access to data. There are two types of restrictions, blacklisting and whitelisting. Blacklisting specific addresses is used to block known or potential bad actors but otherwise does not restrict connections to the server; whitelisting only authorized users is the primary use of IP restrictions in an access control mechanism. This is frequently an option built into the software for managing the server. For example, software used for managing ||secure file transfer protocols|| can restrict the IP addresses that it will accept connections from. For data providers and researchers, this can be restricted to specific devices that the researcher registers with the data provider as the access computer. Other, more sophisticated network access controls may also be implemented, as dictated by any one of the involved parties' IT security staff. Restricting the IP address to specific devices can help protect against both unauthorized users, who would need to gain access to an authorized device, as well as allow for the monitoring of the whitelisted devices to guard against misuse of the data.

#### Remote desktop

Remote desktop software (also referred to as Virtual Desktop Infrastructure, VDI) enables users on one computer to connect to another computer over a network. This is used in data access mechanisms when the researcher does not have direct access to the data and performs their analysis remotely on a separate computer. Data custodians must configure the analysis computer to allow for remote desktop connections, and the access provider must provide the appropriate software and network infrastructure to support the remote desktop connections from the access computer. Password and other authentication requirements help protect against access by unauthorized users. Analysis computers (typically servers) configured for remote desktop access typically run Microsoft® or Linux operating systems; clients to access the remote desktop exist on a variety of platforms, including cell phones and Apple computers. Vendors of such systems include [Microsoft®](https://www.microsoft.com/en-us/p/microsoft-remote-desktop/), [Citrix®](https://www.citrix.com/), [VMware®](https://www.vmware.com/), and [NoMachine®](https://www.nomachine.com/).

The use of remote desktop software allows a researcher to use an analysis computer remotely, with the desktop environment of the analysis computer displayed on the client device, the access computer. This enables the data custodian to retain full physical control over the analysis computer, which can be configured to prevent file transfers to the researcher’s computer, prevent the researcher from installing software, and other controls. This can help prevent the misuse of data by authorized users. Allowing the use of remote desktop software by researchers’ devices can be valuable in instances where the data custodian has decided to not allow researchers to hold the data, in research data centers accessing data stored elsewhere, or when an access provider is supporting researchers across a wide geographical area, such as supporting international research on data that cannot leave its home country.

#### Thin Clients

Thin clients are computers that have been optimized for utilizing remote desktop software to connect to a server. As with remote desktops, these are primarily useful in data access mechanisms where researchers must access and analyze data stored on a separate computer. Very restrictive implementations of thin clients can prohibit any usage beyond displaying information from the server and accepting mouse and keyboard input from the user. Thin clients typically operate without local storage, thus preventing users from saving data to the client. However, most thin clients also require a server-side infrastructure to support both access and security updates. Thin clients can be secured with various login and authentication systems to prevent their use by unauthorized users.

Thin clients do not need to be capable of running statistical software or intensive analysis; the analysis will occur on the server that hosts the data and software packages. Generally, researchers would not procure their own thin clients, as they have no utility outside of facilitating remote access. Rather, they are typically provisioned by data custodians or access providers and either housed within a specific access location or provided to the researcher. Thin clients allow the data custodian more control over the researchers' access to the data. This is an added expense compared to allowing the researcher to use remote desktop software on their own computer and requires the access provider have the resources to support and distribute the thin clients.

One of the main advantages of dedicated hardware thin clients is that they are cheaper and simpler than regular computers. As of the time of writing, thin clients can cost as little as $100 for the hardware itself, in contrast with the cheapest entry level computers which are several hundred dollars. Thin clients can be sourced from many manufacturers of enterprise hardware, both as standalone devices for the user to configure as well as full fledged hardware and software package solutions configured by the vendor (these will obviously cost more than just procuring the hardware). Thin clients can be purchased from most business PC vendors, including [Dell®](https://www.dell.com/en-us/work/shop/wyse-endpoints-and-software/sc/cloud-client/thin-clients), [HP®](https://www8.hp.com/us/en/cloud-computing/thin-clients.html), as well as some custom-produced solutions, such as the "[SD-Box](https://www.casd.eu/en/technologie/sd-box/)" developed by and produced for the Centre d’Accès Sécurisé aux Données (CASD).

#### Biometric authentication

Biometrics are physical and biological features unique to individuals. Biometric authentication is the use of biometric features to verify the identity of individual users based on stored information about authorized users. One of the most common biometric technologies in current use is fingerprint scanners for consumer electronics such as laptops and smartphones. Other commonly used technologies include facial recognition, retinal or iris recognition, and voice identification. Biometrics can be used to control access to secured locations as well as to secure individual devices. The main components of such an access system includes the biometric sensor itself, which is connected to a database that contains the set of validated users, and either the physical or electronic lockouts for a given system (e.g. entering a room or logging into a computer) which are controlled by the biometric sensor.

Biometric authentication techniques can serve both as a primary form of identification as well as being layered in two or multiple factor authentication techniques, such as in conjunction with passwords or other devices. Biometric authentication by its nature will only offer protection against unauthorized access; it is possible to track when users access a device or location to serve as a deterrent against misuse but cannot prevent it. While some devices will come with built in biometric authentication, such as the aforementioned fingerprint scanners, mandating additional biometric authentication requires significant resources. Data providers should consider their own resources and the likely threats when deciding whether or not to mandate or implement such systems.
 
#### Physical access cards

Physical access cards are electronic cards that identify the card bearer for a physical access control system. Access to devices or rooms secured by a card reader validates the user’s card with a database that has a set of valid cards and subsequently disables the locks on the system or room that it is protecting. The cards themselves can use magnetic stripes, barcodes, electronic fields, or other systems for interfacing with the card reader. Physical access cards are commonly used in universities and have the advantage of likely having existing infrastructure to support the creation of secure access rooms for researchers receiving administrative data. As with biometric authentication, access cards are mainly intended to protect against unauthorized users. Unlike with biometric authentication, access cards can be easily lost or given to others, with a greater potential for misuse. Protecting the access cards themselves is primarily a policy and training issue.

#### Secure Rooms

Rooms can have various specifications for securing it against unauthorized access. These can serve to particularly harden locations from unauthorized access as well as providing ways of monitoring users, and may be of particular importance for computers and servers which house highly sensitive data. Secure rooms may be required to be fully enclosed by walls that extend from floor to ceiling, minimize the number of possible entryways, have doors, windows, air vents, and other possible entryways secured by bars, mesh, or other methods. Doors and walls may have minimum specifications in terms of materials, construction techniques, and thickness to increase protection against physical attacks. For instance, reinforced doors and walls offer increased protection compared to regular home and office construction materials. Door hinges, access panels, partitions, windows, and other possible ways of entering the room may be installed from the inside of the secure room to prevent their removal from the outside. Additional requirements may extend to physically securing devices within the room. Finally, computer infrastructure may be required to have no outside network connections (a so-called "air-gapped network"), or no network connection at all. These restrictions are typically only utilized when mandated by data providers or required by law for the sharing of data. Building secure rooms is a very costly endeavour, as few offices will meet these specifications without additional construction and hardening.

### Typical access mechanisms

In any data access mechanism, the fundamental setup always involves the original holder of the data and access by a new entity. In the context of this Handbook, the original holder is the data provider, and the new accessor is the researcher. Technology determines how the physical exchange and access may happen. We provide four archetypal examples of data access mechanisms. These are broad categorizations of how data access mechanisms can be set up, and are not not an exhaustive list of possibilities.

#### Remote Execution

Under a ||remote execution|| model, a researcher needs to submit a request to have the data custodian, either the data provider or a third party, run the analysis on behalf of the researcher and share only the summary output. Data custodians maintain full control over the data, and have the unique opportunity to check the researchers’ code prior to execution. Because researchers need to specify the analysis carefully, iterative or exploratory analysis may be inhibited or reduced. For some researchers, this may be perceived as an impediment; however, for researchers working under a pre-registration paradigm, the same restriction may be neutral or even perceived as an advantage.

Remote execution requires that the data custodian maintain a mechanism for executing researchers' code, either through an automated service or having technical staff manually execute the analysis. The mechanism will also conduct disclosure avoidance checks on the output before sending it back to the researchers. The data custodian also needs to create and maintain the systems to facilitate the transfer of the necessary files, including test files—data files that have the same variables and table structures as the real data but containing fictitious values, analysis files, and the output. While these files may not be particularly sensitive, [remote desktop] software and electronic [data transfer mechanisms] may still be useful tools.

Remote execution gives the highest possible protection against adversarial actors via the data access mechanism (breaches of a data provider occurring outside of the data access mechanism can still occur) and provides no opportunity for users to accidentally disclose the research data. It also provides the data provider with the ultimate protection against misuse of the data, as they have the opportunity to vet every analysis file prior to executing it or transferring the results back to the researcher. The tradeoff for the data provider is the cost of providing the necessary resources (systems and staff time) to conduct the analysis. In some instances, cost is recovered by charging researchers.

#### Physical Data Enclave

In a ||physical data enclave|| model, researchers must enter an access controlled location (the "data enclave") to analyze the data. The data provider can act as its own data custodian or appoint a trusted third party to run the enclave on its behalf; enclaves under the control of the researcher are described under researcher provided infrastructure. The data custodian can choose to use [on-site storage] at data enclave or on a remote server that can only be accessed by [thin clients] located within the data enclave; in this case the connection to the remote server typically uses secured [network protocol]s or [virtual-private networks], although a direct connections may also be used. The data custodian typically has staff or automated systems to ensure that only authorized researchers enter the location, which are often secured with [biometric authentication] or [physical access cards]. Strong specifications of security can require that these locations be [secure rooms]. Systems or people, not necessarily the same, may also be responsible for ensuring that only safe outputs are removed from enclaves.

The data custodian has most of the security benefits of remote execution by maintaining full control over the data in the entire research process. Because the data remains under the control of the data custodian and requires physical access by approved users, it is secured against unauthorized access. Physical data enclaves remove the potential bottleneck and additional expense of requiring dedicated staff on the part of the data provider to actually run the analysis on behalf of the researcher.

However, physical data enclaves still impose restrictions on the flexibility of researchers. Instead of waiting for someone to run the remote execution for them, researchers have to schedule visits to a physical location. Travel, with associated costs, is often required. It also requires the data custodian to provide the physical and technical infrastructure for researchers to conduct their research in a secure location. In more basic implementations, a physical data enclave can be as simple as a locked room that only authorized users can enter, either with the data stored on site or with a thin client to access data elsewhere. Meeting more stringent security requirements can impose a substantial initial start-up cost on new sites.

#### Virtual Data Enclave

A ||virtual data enclave|| is conceptually similar to physical data enclaves, except there is no physically controlled space that the researcher must visit in order to access the data. Rather, data custodians maintain servers that house the data, which researchers utilize different technical means to remotely access and perform their analysis. There are two basic approaches to the remote access mechanism: either using [remote desktop] software that the researcher can install on their own computer or a dedicated [thin client] that the data custodian loans the researcher to connect to the server. As with physical enclaves, the data custodian typically also requires the use of secured [network protocols] or [virtual private networks] to access the data.

The virtual data enclave model has a major advantage for researchers in that they no longer have to travel to specific facilities to perform their research, though some restrictions may still apply. Furthermore, instead of the cost of maintaining an entire physical data enclave and the associated staff at each enclave, the data custodian only needs to provide researchers with the necessary thin clients or remote desktop systems and can centralize their data staff.

The primary tradeoff is the slightly lower level of data security because the data custodian no longer controls the physical environment from which the researcher accesses the data, although data providers can specify the level of security for the access location that they deem necessary. Like with physical enclaves, virtual enclaves remain robust against unauthorized access by keeping data stored in a secured environment and requiring authenticated access.

#### Researcher-Provided Infrastructure

In some data sharing arrangements, the data provider has the researcher provide the data storage and analysis infrastructure. The data provider will provide the data to the researcher through a secure transfer mechanism (whether [physical media], over a secure [network protocol], or a [cloud service]). The researcher will need to maintain the [on-site storage] to store the data. Inherent in this process is the data provider having a significantly reduced ability to monitor the usage of the data. Moreso in this model than the others, the data provider depends on contractual agreement with the researcher for preventing the misuse of the data, typically through a data use agreement specifying the nature of safe outputs.

This process allows researchers significantly more flexibility and rapid turnarounds on research findings of importance to their government partners. Allowing researchers to store the data on their own devices may reduce the burden on data providers, who only have to provide the data itself and the staff necessary to transfer it to the researchers. No separate staff or systems are needed to control exit or entry of people and results, since this is delegated to the researcher. On the other hand, data providers may also choose to conduct random on site inspections or have researchers submit their output for approval, which requires staff time. In instances where researchers can work very closely with the data providers’ technical staff with direct access to their data, they can also help the government learn more about their data and improve processes and systems at the government.

### Five Aspects of Data Access Mechanisms

From the four archetypes of data access mechanisms, some distinguishing features become clear. There must exist a data storage and analysis computer, which is the computer or server (often plural) that performs the statistical analysis. This computer can exist at one of several locations. Researchers must be able to access this computer, whether by using a separate access computer to remotely access the analysis computer or by working on the analysis computer directly. The location from where researchers can access the data from also varies across the four models. Other characteristics not accounted for in the archetypes is the level of control that researchers have over the analysis computers and the types of analysis that they are allowed to perform, which can be important contributions to the overall security of a data access mechanism.

We categorize these features as five aspects of data access mechanisms to serve as a framework to evaluate any given setup as it pertains to safe settings. These are:

- the physical **location of analysis computers and data**, which refers to the location where researcher-accessible data and computers used to analyze the data; the analysis computers are by definition at the same location as the data
- the level of **researcher agency over analysis computers** that they are allowed, referring to any technical restrictions on their usage of the analysis computers
- the **location and type of access computers**, which are the computers (end points) that researchers use to access the data, which may be the same or separate from the analysis computers.
- the **level of security of access locations**, referring to the overall rigor of the physical security arrangements for where researchers can access the data from.
- the **range of analysis methods available** to researchers, referring to any restrictions on the types of statistical analysis that researchers can perform on the data.

For each aspect, the classification ranges from maximally restrictive on the researcher while allowing the data custodians to retain the most control over the data and its usage, to minimally restrictive on the researcher with its corresponding tradeoff of the data custodian retaining the least amount of control. For ease of discussion, each classification ranges from **1** to **3**, with 1 corresponding to the most restrictive on the researcher and 3 corresponding to the least restrictive on the researcher.

Note we deliberately do not frame this as a tradeoff between convenience and security. The level of security of any data access mechanism is dependent on a large number of factors, of which the institutional features are merely a component. Proper implementation and maintenance of the technical infrastructure, compliance with restrictions outlined in the DUA, and the training of users and staff are all factors that contribute to the actual security of a data access mechanism.

Additionally, there are certain features that are not included in the five aspects, as those features are dependent on other aspects and do not vary independently. For instance, transfer mechanisms are a technical feature of certain data access mechanisms and not an aspect that all will have; there are not usually meaningful tradeoffs for the ability of researchers to utilize data or perform their research in the choice of data transfer mechanisms should one be necessary. These features are considerations to make when making choices within each aspect, but are not separate aspects themselves.

When proposing and negotiating a potential use sharing agreement, evaluating the physical security arrangements along these five aspects can help researchers and their data providers craft robust mechanisms to protect data when transferring and using data for research.

#### Interactions With the Other Five Safes

Importantly, data access mechanisms interact with the other four safes. Safe projects, people, data, and outputs will all play a role in determining the physical security features necessary for any given data access mechanism to be a safe setting.

A common restriction on safe projects is prohibiting the use of administrative data to identify people. Researchers and data providers should think carefully about the data required to perform research projects, and not request or approve the sharing of data beyond what is necessary to minimize the potential for identifiability. Depending on the risks of this occurring, data providers may mandate the use of technical means of enforcing this as part of the access mechanism, such as by restricting the set of commands that researchers are allowed to run in their analysis programs. These will reduce the control that researchers have over the analysis computers and methods. Alternatively, the data provider may allow limited identification as a necessary part of research projects; for instance, merging external survey data with the administrative data will allow researchers to identify subjects within the administrative data. Ensuring that the data access mechanism has the appropriate safeguards to protect the reidentified data is a necessary condition for this to take place.

In the area of safe data, the sensitivity of the data itself plays a large role in the implementation of data access mechanisms. While social science research has traditionally focused on the protection of individuals within the data, as researchers increasingly make use of data from businesses or other proprietary sources the protection of trade secrets and potential for reputational harm to organizations must also be considered. One common holistic framework, particularly among US research institutions such as MIT^[https://infoprotect.mit.edu/what-needs-protecting], Harvard^[https://security.harvard.edu/dct], Stanford^[https://uit.stanford.edu/guide/riskclassifications], and the University of California system^[https://security.ucop.edu/policies/institutional-information-and-it-resource-classification.html], is to classify data based on the different levels of risk that a breach poses to individuals or organizations. Low risk data typically encompasses information intended to be publicly available, is anonymous, and poses no risk to the security of other data systems, finances, etc. Moderate risk data typically comprises data that is meant to remain confidential but otherwise would not pose more than a mild risk to other data security, reputation, finances, or subjects within the data. High risk data encompasses confidential data protected by law or otherwise would cause reputational damage, harm (including life safety) to subjects within the data, compromise other data systems, or other types of material harm. Much of the data of interest for researchers is considered high risk data within this framework; but even within high risk data there are varying levels of sensitivity. Riskier data can necessitate significant safeguards over some or all of the five aspects of data access mechanisms.

Safe people influence the setup of data access mechanisms in several ways. While many data providers have legal and administrative requirements (background checks, required training, signed affidavits, etc) for researchers before they ever access sensitive data, the physical protections in the data access mechanisms also play an important role. Physical or electronic safeguards of the data, analysis and access computers, and access location guards against adversarial attempts by unauthorized users to gain access to the data. These protections also serve as a line of defense in keeping trusted users from being the source of a breach, both through the actual safeguards around events such as the theft of a computer, and by serving as a visible reminder of the importance of data security.

Ensuring safe outputs can also affect the physical protections built into the data access mechanism. Implementing physical controls to the access location and analysis computers allows for additional checks on the data outputs that users can take out of the access location. Technical solutions such as automated checks of statistical results or the prevention of file transfers implemented within the access and analysis computers also prevents users from generating unauthorized outputs through their access to the data. In settings where these controls on the analysis computer or access location are impractical, the control over outputs is more reliant on non-technical means.

Each of the five aspects of data access mechanisms have specific interactions with the other safes as well as having a tangible tradeoff between improving security, the ability to meaningfully use the data, and the required human and capital costs of implementing features of each aspect. We further highlight such interactions in the descriptions of the five aspects and examples provided.

#### Location of Analysis Computers and Data

The location of the researcher-accessible data and the analysis computer is the first aspect of data access mechanisms.The data and analysis computers can be stored at one of three locations. The data can remain with the data provider, which is the most restrictive for the researcher, most control for the data provider. The data provider can utilize a trusted third party as a data custodian. The data provider can also transfer the data into the custody of the researcher, which is the least restrictive on the researcher and has the least control for the data provider. The party that holds the data acts as the data custodian in a data access mechanism.

| 1 | 2 | 3 |
|---|---|---|
| Data provider | third party | Researcher |

The first option is for the **data provider** to retain custody of the analysis computer and data, acting as the data custodian. Reasons for the data provider to do so may be If the data provider has lower confidence in external parties and their technical capacity, if the data is highly sensitive, or if there are specific legal or policy requirements for the data’s location and security. This gives the data provider maximum control for how for guarding against all types of security threats. The data provider will need to provide the infrastructure and have the requisite technical staff to store the data and to set up the mechanisms for researchers to access the data, whether by having the researchers travel to the data provider or through a remote access or submission system. Data providers that already have existing infrastructure that they can repurpose or already have similar access mechanisms set up as part of their existing work may find this option to be particularly attractive. Furthermore, by acting as its own data custodian, transferring data is not a task that the data provider needs to consider.

> The United States [Federal Statistical Research Data Center (FSRDC)] network makes Census Bureau data available to researchers through its affiliated research data centers. However, the data and analysis computers remain with the Census Bureau itself.

Data providers can choose a **third party** data custodian for ease of access and use for the researcher compared to locating the data and analysis computer at the data provider. For instance, government statistical agencies or data centers at universities can have more expertise with the safe storage and usage of data than a data provider by virtue of having the organization specialize in that task. By being in the business of data custodianship, third parties should have the technical infrastructure and security expertise necessary to guard against adversarial actors. Simultaneously, they are often more familiar with the requirements and use cases of researchers, enabling them to be more responsive to the needs of researchers. Entities without their own research agendas may be particularly appealing as third parties, as that removes one of the incentives for the misuse of the data by an external data custodian. However, transferring the data to a third party opens up the requirement for data providers to have appropriate systems to facilitate the transfer of data, as well requiring that the third party has the capacity to protect the data.

Third party data custodians can unlock the possibility of combining data from multiple data providers. For instance, government departments responsible for immigration and taxes may not be legally allowed to share data, but they may each be able to transfer the data to a national statistical office. Similarly, multiple companies may not be willing or legally allowed to share data with one another, but may be able to transfer the data to trusted third parties. In other situations, one branch within a government department, responsible for enforcement, may transfer the data to another branch, whose business it becomes to make the data accessible.

> The [Private Capital Research Institute (PCRI)] maintains a data access mechanism that has a third party data custodian. PCRI facilitates the collection of data from private capital firms, and the data is stored on analysis computers operated by the National Opinion Research Center (NORC); researchers cannot directly view the data.

A **researcher** acting as the data custodian is an option if the data provider believes it does not need to tightly control the data and analysis computers, if the data is less sensitive, or if the data provider has high trust in the ability of the researcher, having the researcher serve as the data custodian becomes an acceptable option. When this happens, the data provider must be satisfied with the researcher’s capacity to deal with adversarial actors; with the appropriate data transfer mechanisms and storage systems, this does not inherently pose a greater risk. Data providers can mandate that the analysis computer be kept offline with no external network connections. The enforcement of the DUA becomes a key mechanism for preventing the misuse of the data. For the researcher, acting as the data custodian enables more flexibility for accessing the data without traveling or remote access systems, but can be more expensive as they will need to provide the data storage infrastructure.

> The [Aurora Healthcare and MIT] data exchange has the data and analysis computer located with the researcher. Researchers must store the data in accordance with security requirements outlined in their data use agreement.

For data providers, transferring control of the data and analysis computers to a third party or directly to researchers might be desirable when support for many researchers is a burden for the regular business of the data provider. By transferring the data to another party, a data provider may no longer be responsible for the cost of providing computational infrastructure for [data storage][on-site storage] and analysis. However, in this case data providers and the new data custodian will need to utilize secure transfer mechanisms. On the other hand, the data provider may see higher costs for enforcing access restrictions, such as needing to conduct site visits, once physical custody of the data has been transferred. Data providers will rely on the enforcement of data use agreements when giving others custody of their data.

#### Researcher Authority over Analysis Computers

Distinct from the location of the analysis computer and the data is the level of agency that researchers have over the analysis computer. The primary impact this has on researchers is the potential restrictions on the software that they can utilize. In a low agency setting, researchers will be limited to the software that the data provider chooses to allow. In a medium agency setting, researchers may utilize their choice of software, subject to the approval of the data provider. In high agency settings, researchers are free to utilize whatever software that they want without needing prior approval.

| 1 | 2 | 3 |
|---|---|---|
| Low | Medium | High |

In the **low researcher agency** settings, researchers will not have administrative privileges over the analysis computer and will be limited to the software that data providers choose to provide. These restrictions typically take the form of an approved list of software that can be installed or is pre-installed on the analysis computer. These restrictions can affect not only the base software itself but also third party additions for those software such as third party packages for Stata and R. Even if a set of base software is allowed, additional packages not signed by the original developer may not be allowed. The data provider can implement additional restrictions on the computers such as operating system level controls on what researchers can do or controlling the access to specific files and folders. Making hardware changes to the computer will also be restricted; researchers will not be able to make upgrades to the analysis computer outside of any schedule set by the data provider.

> The [Statistics Canada Real Time Remote Access (RTRA)] system is an example of a low researcher agency setting. Researchers can only use SAS and cannot directly view the data, with no exceptions allowed.

In **medium researcher agency** settings, researchers will continue to not have administrative privileges but have limited choices over the analysis software. While they will not be able to install software themselves, there will be some mechanism for approval for making modifications to the analysis computer. This takes the form of a security vetting and approval process for adding new software or making any changes to the analysis computer, which can have varying levels of scrutiny or automation. This allows some flexibility for researchers to utilize software of their preference while allowing the data provider to retain administrative control over the analysis computer to protect against security threats. While these restrictions may trend close to having no flexibility at all in practice, the distinction between no options and even very limited options for the types of software that researchers can use is an important one.

> An example of a system with medium researcher agency is the [FSRDC][Federal Statistical Research Data Centers (FSRDC)] network. The FSRDC has a specific set of software on their secure computing network that is made available to researchers. Additional software can be requested, which must be approved by program managers and security analysts.

Data providers may choose to grant researchers only low or medium agency over analysis computers due to technical requirements related to computer and network security and as a mechanism for disclosure control. These restrictions, implemented through [data access controls], can help harden the analysis computers against direct threats from adversarial actors or researchers unwittingly installing malware on the analysis computers. Maintaining high levels of control allows data providers to easily monitor the activities of researchers on the analysis computer. This can be particularly important if safe data or safe people criteria are relaxed; if more sensitive data is being made available for research or if the data data is available to a wider array of potential users, there is a greater need to guard against the misuse of data.

Implementing these controls comes with their own potential costs, including the technical expertise and resources needed to support such administrative controls over the analysis computers. Low agency settings are particularly limiting for researchers, as certain types of analyses require specialized software which may be unavailable in these environments. Additionally, researchers will need to have the skills to utilize the available software; for instance, R users will need additional training to operate in an environment that only has Stata available. Medium agency settings can be more expensive for data providers, as it will require additional staff and resources to maintain multiple types of software and review researcher requests. Note that it is possible for researchers to have low or medium agency over an analysis computer even if the analysis computer and data location is with the researcher; the data provider can require the use of an analysis computer that is located at the researcher but is under the administrative control of the data provider.

In the **high researcher agency** settings, researchers have administrative privileges to the analysis computer and therefore no restriction on the software that they can use. The researcher may own and physically control the analysis computer, or may be granted administrative privileges to a computer that is owned by the data provider or third party. For researchers, having the ability to choose the analysis software allows them to perform their research with fewer impediments, speeding up research and reducing the potential cost of adapting to a limited or predefined set of options. In settings where researchers provide the analysis computer, they will be able to freely make hardware changes as well. While the proper configuration of the analysis computers by the researchers can mitigate the risk of adversarial actors gaining access to the data, there is a greater opportunity for unauthorized use of the data. To guard against this, data providers can mandate technical solutions such as the use of monitoring or operating system patch management software as well as relying on the enforcement of the DUA.

> One example with high researcher agency is the way that the [National Center for Education Statistics (NCES) restricted-use data license] operates. The researcher must set up a secure data room in accordance with NCES requirements, but researchers provide and retain full administrative control over the analysis computer and can utilize whatever software they want.

Data providers may choose to allow researchers high agency over the analysis computers when the other four safes are fulfilled to the necessary degree. Projects may be deemed safe enough that researchers may have high agency over the analysis computers. Researchers may have proven themselves to be safe custodians of research data, either through past partnerships and previous experience or by fulfilling conditions set by the data provider. The data may be considered safe enough, with limited potential for identification of individuals or other harm, such that it can be stored on computers where parties other than the data provider have administrative privileges. The data provider may have high trust in researchers to produce safe output or have the means to verify that output.

#### Location and Type of Access Computers

The next aspect of any data access mechanism is the location and type of access computers. In some cases, the access computer is co-incidental with the analysis computer. However, when researchers cannot directly use the analysis computer, the access computer is distinct from the analysis computer. Access computers can be located at the non-researcher data custodian, at a third party access provider, or with the researcher. The location of the access computer is not necessarily aligned with the ownership of the access computer. For instance, a researcher may be assigned a computer that serves as an access computer, but which is owned by the data provider.

| 1 | 2 | 3 |
|---|---|---|
| Non-researcher data custodian | Third Party | Researcher |

If the access computer is located at the **non-researcher data custodian**, which can be the data provider or a third party custodian, the data custodian is also the access provider and the researcher must travel to their location. In this setting the access computer can either be the analysis computer itself or a separate access computer maintained at the same location. Data providers wanting maximum protection for the analysis computer or to enable simultaneous usage of the data by multiple researchers may choose to use separate access computers. This allows the access provider maximum control over the access computer and its security arrangements, including physical and electronic monitoring, removing USB access ports, and other measures. Data providers particularly concerned with the sensitivity of the data may consider these restrictions necessary.

> The [New Brunswick Institute for Research, Data and Training (NB-IRDT)] is an example of locating access computers at the data custodian. Researchers wishing to use data held by NB-IRDT must travel to one of the NB-IRDT campuses to utilize the access computers and the data.

Data providers can choose a **third party** access provider that is not the data custodian. Researchers may still have to travel to a separate location but typically over shorter distances or with more flexibility than to the data provider. Data providers utilize third party access providers when being the access provider is too costly for the data provider, is outside of the normal functions of the data custodian, or to enable wider access to the data.  In this arrangement, the third party access provider will need to have the infrastructure to enable remote connections between its access computer and the analysis computer located at the data custodian. Access computers located at third party access providers can have similar physical and electronic protections as those located at the data custodian, typically set by the terms of the agreement between the data provider and the third party access provider. This can take the form of secure workstations with [VPN][virtual private network] setups and [encrypted hard-drives][on-site storage] or dedicated [thin clients] serving as endpoints with remote access to the analysis computer. Increasingly complex and sophisticated access computer security mechanisms also require additional resources for data custodians and access providers to implement. These mechanisms help secure the access computers from adversarial actors, preventing them from using the access computers to gain entry to the analysis computer.

> The [SafePod Network (SPN)] in the United Kingdom is an example of locating access computers at a third-party access provider. Each individual safepod, located at academic institutions, houses an access computer that provides remote access to the UK Administrative Data Research Network

Locating access computers with the **researcher** allows the researcher maximum flexibility on where and when to work with the research data. If the data is at a separate data custodian, this can be accomplished via remote submission or access systems that allow researchers to work from their own location. The terms of the remote access will be defined in the DUA between the researcher and the data provider. When not further defined, a researcher may be able to use any computer for access, for instance, when access is via a secure website. On the other end of the spectrum, data providers can mandate the use of specific methods such as [remote desktop] or even provide [thin clients] to the researcher. These can serve to harden the access points against unauthorized access as well as provide monitoring of the researchers’ use of the access computer.

> An example of access computers located with the researcher is the [Institute for Employment Research (RDC-IAB)] Job Submission Application (JoSuA) system. JoSuA is a web interface that researchers can use from their own computers to submit analysis files to the RDC-IAB.

In the case where te analysis computer is also located with the researcher, it often acts as the access computer. There is little to no security benefit to requiring additional access computers, and may in fact be a security risk as it opens up additional ways of accessing the analysis computer. Data providers can impose requirements on the security and location of the analysis computer to ensure the safety of the data.

> An example of this is the [Ohio Longitudinal Data Archive (OLDA)], which requires that researchers use a computer that is registered with OLDA to download the data servers. This computer also serves as the analysis computer.

#### Security of Access Locations

In addition to the location and type of access computer, the security of the location where the access computer resides is another aspect of data access mechanisms. Access locations can have three levels of security: high security, medium security, and low security arrangements. In instances where a party other than the data provider maintains the access location, data providers can reserve the right to approve the security arrangements, conduct audits, or otherwise directly verify that the operator is in compliance with the mandated security requirements. Data providers and researchers looking to set up new data access mechanisms should weigh the additional resource costs and barriers to research incurred by increasing access location security with the additional protections that higher security access locations provide.h

Note that designating a particular setting as a medium or low security location does not mean that the location is unsafe. Many government, commercial, and university offices qualify as low security locations that determined attackers could access without much issue, yet much of the generation and usage of their own administrative data takes place in such settings. During the quarantine and social distancing efforts that took place during the 2020 covid-19 pandemic, many people were undoubtedly working with administrative data from their homes.

| 1 | 2 | 3 |
|---|---|---|
| High Security | Medium Security | Low Security |

A **high security access location** has strong specifications for physical security, requiring the use of a [secure room][secure rooms]. Access is restricted to approved researchers and staff, with additional hardening of the room beyond just access controls to the access location. Authorized users can be physically monitored in the access location by video or access location staff, in addition to any electronic monitoring on the access computer itself. The additional protections and monitoring guard against unauthorized access as well as the removal of unauthorized outputs from the acces location.

The goal of these arrangements is to provide maximum protection from all types of security threats and may be used for the most sensitive data that is made available to researchers such as personal health data, identified census data, and other forms of high risk data. Many of the implementations of high security access rooms are due to legal requirements on the part of the data provider as a condition for access to the data. Given the expense and intent of the restrictions, high security access locations are almost never under the control of individual researchers. If not already existent at the access location, data custodians or access providers will require expertise from IT and security specialists to assist with defining the specifications and implementation of the features of high security access rooms.

> The [NB-IRDT][New Brunswick Institute for Research, Data and Training (NB-IRDT)] data centers, with their stringent access controls and additional physical safeguards such as bolting the server to the floor in a separate locked cage, falls into the high security category.

A **medium security access location** has a defined location with access restricted to approved researchers. These can rooms be secured with [keycards][physical access cards], biometrics[biometric authentication], or a simple lock and key restricted to approved staff. However, it does not have the additional protections associated with high security access locations. Medium security access locations can be operated by any party in a data access mechanism. These are suitable for preventing a limited set of unauthorized access attempts, but likely will not prevent determined adversarial actors from gaining physical access to the access computers; medium security access locations will work in conjunction with other aspects outlined above to prevent adversarial actors from gaining access to the data itself. Because the location is defined and controlled, medium security setups also allow for the physical monitoring of the users and outputs. Medium security access rooms also can incur significant costs for the location administrator, requiring dedicated space and staff to maintain the access location itself.

> The requirements for the data location outlined in the [NCES restricted-use data license ][National Center for Education Statistics (NCES) Restricted Use Data License] is an example of a medium security arrangement under the control of the researcher. The data must be kept in a locked room with access restricted only to licensed researchers, with the security arrangements subject to random audits by NCES.

A **low security access location** has a mandated location for the access room or other basic security precautions but otherwise has few or no access controls. This can take the form of the data provider mandating certain steps such as storing the access computer in a locked room or other basic precautions, but without a provision that only authorized personnel can enter the location. Data providers can use [IP address restrictions] to ensure that researchers only use an approved device from the agreed upon location. A subset of low security access locations are open access locations where there are no mandated locations or controls and access computers are not treated as any more valuable than any other computer unrelated to the data access mechanism. This is typically seen with public-use data files, remote access or submission systems where a user cannot actually view the data, or when researchers are allowed to store data on their laptops. The risks in these settings can be mitigated through the use of [VPN’s][virtual private network], [remote desktop] software, secure [network protocols], and [encryption] or requiring [biometric authentication] of the access computer. Low security access locations tend to serve more as a psychological reminder and deterrent against unauthorized use, relying primarily upon the protections built into the access computer and rest of the data access mechanism to guard against adversarial actors.

> The [SFUSD-Stanford Partnership] uses low security access locations. While the data is stored on secured servers at Stanford, researchers can access the data from anywhere as long as they take reasonable and appropriate efforts to keep the data secure from unauthorized access, as specified in their data use agreement.

> An organization that allows for open access locations is the [Development Impact Evaluation (DIME)][Development Impact Evaluation (DIME) at the World Bank] group at the World Bank, whose researchers can remotely access the data from any location.

#### Range of Analysis Methods Available

The final aspect of data access mechanisms is the set of analysis methods available to researchers. Analysis methods can be unrestricted, subject to limited restrictions, or be highly restricted. These restrictions can be implemented for technical or security reasons but mainly serve to ensure that researchers cannot misuse the data or generate unsafe output. Note that this aspect of data access mechanisms is distinct from the agency that researchers have the analysis computer. For instance, a data provider may allow for any analysis method, as long as it is implemented in an approved piece of software — a situation where the software choices may be limited (and limiting for researchers), but where the analysis methods within that software are unrestricted. This aspect is also closely related to the statistical protection of the data itself, which pertains more to safe data and safe outputs rather than safe settings.

| 1 | 2 | 3 |
|---|---|---|
| Highly Restricted | Limited Restrictions | Unrestricted |

In settings with **unrestricted** analysis methods, researchers can use the full set of methods available in the software that is available on the analysis computer, subject to other restrictions on the analysis computer as discussed in the previous section. These methods can range from simple tabulations to complex machine learning algorithms. Many data access systems allow for unrestricted analysis methods by maintaining tight control over other aspects of data access mechanisms and other parts of the Five Safes framework.

> [OLDA][Ohio Longitudinal Data Archive (OLDA)] is an example of unrestricted analysis methods, placing no limitations on the methods that researchers can use. OLDA relies on disclosure review, as mandated in their data use agreement, to ensure safe outputs.

Settings with **limited restrictions** limit the availability of commands within the data access mechanism and impose some limitations on the outputs that researchers can generate. This can include a set of prohibited commands within the analysis software or automated checks for cell sizes in outputs. Limitations on researcher agency over analysis computers can also restrict the methods available to researchers; for example, preventing the installation of external packages in software such as Stata or R will limit researchers’ flexibility.

> An example of limited restrictions on analysis methods is the [RDC-IAB][Institute for Employment Research (RDC-IAB)] on site and JoSuA systems, where certain Stata commands are censored by the system and are unavailable to researchers.

**Highly restricted** analysis methods severely curtail what researchers can do. These typically correspond to only permitting a specific set of approved analysis methods. Such restrictions can include limiting the methods available to researchers to a whitelisted set of commands or, in more extreme examples, limit them to the use of tabulator software that can only provide conditional tables. This will impose limitations on the research agendas that can be pursued using the data access mechanism. Highly restricted analysis methods are suitable for data that is being made available to a wide range of users, with relaxed conditions on the rest of the Five Safes framework.

> The [Statistics Canada Real Time Remote Access] system only allows users to use a set of approved SAS commands via their online tool. There are further limits on the number of variables and observations that can be included in analysis.


Restricting the analysis methods available to the researcher is primarily intended to protect the outputs of any analysis, preventing reidentification of subjects located within the data and other misuses of the data. Properly set up, this can allow for the data custodian to forego certain ex post checks of outputs or monitoring of users. However, setting up such systems requires a high degree of technical sophistication and resources available to data custodians; unlike with many of the other dimensions, there are no off-the-shelf implementations of restricting analysis methods available. While this may be intended as a physical restriction on safe projects, researchers and data providers looking to set up new data access mechanisms should be clear on what restrictions may be placed on analysis methods and plan the research project accordingly.

### Typical access mechanisms along the five aspects

Having defined the five aspects of data access mechanisms, we can reexamine archetypical access mechanisms along the five aspects. Each set of data providers and researchers utilizes a unique combination of the five metrics for their data sharing framework.

#### Remote Execution

Remote execution setups will locate the analysis computers and data at the data provider or third party acting as the data custodian. Researchers will have low or medium agency over the analysis computers as they never interact directly with the analysis computers; more flexible models may allow researchers to request specific software. Analysis methods are typically restrictive in remote execution setups, as the researcher can only use methods approved by the data provider or third party that executes the job submission. Access computers can be of any type deemed appropriate by the data provider and may be located with researchers or a third party access provider. There are no specific requirements on the security of access location.

#### Physical Data Enclave

In physical data enclaves, the location of the analysis computer and the data will remain with the data provider or third party data custodian. There is no inherent restriction on either the agency of researchers over the analysis computers or the analysis methods available to the researchers, although typically these will be restricted to some degree as the analysis computer will remain under the control of the data custodian. The defining feature of a physical data enclave is control over the access computers and location. Access computers will be located with the data custodian or a third party access provider. Physical data enclaves will typically use medium or high security access locations.

#### Virtual Data Enclave

Like with physical enclaves, the data and analysis computers are located at the data custodian in a virtual data enclave. Researchers will have restrictions on their agency over analysis computers, particularly as there is no opportunity for them to have physical access. Analysis methods can be as restrictive or as flexible as required by the data provider. The location and type of the access computers can potentially be of any type in a virtual data enclave. Similarly, there can be any level of access location security, as there are no inherent restrictions required in this model.

#### Researcher-Provided Infrastructure

With researcher provided infrastructure, the analysis computers and data are located with the researcher. There does not need to be a distinct access computer in this arrangement. Because researchers are providing the infrastructure, they will have full agency over the analysis computers and have unrestricted analysis methods available to them. The security of the access location can be of any type, as mandated by the data provider.

### Specific data access mechanisms along the five aspects

We can also evaluate how the five aspects map onto the data access mechanisms featured in the case study chapters. We also provide several examples from outside of our case study chapters. To provide a simple way of comparing the access mechanisms at a glance, we also provide a visual representation of the restrictiveness versus flexibility of each of the five aspects in a color coded chart. The more restrictive aspects are colored green, while more flexible aspects are blue. 

#### San Francisco Unified School District (SFUSD)-Stanford Partnership

```{r, echo=FALSE, fig.width=5, fig.height=2}
sfusd = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,3,3))
plot(sfusd)

```

In the SFUSD-Stanford Partnership, SFUSD uses the CEPA Data Warehouse as an intermediary third-party data custodian that ultimately transfers a restricted set of data to the researcher via [cloud services] and stored on Stanford [servers][on-site storage], which includes deidentified individual level data on SFUSD students and staff. The location of the analysis computers and the data are therefore at the researcher. Computers used to analyze SFUSD data are subject to Stanford and SFUSD requirements for data security, including enterprise operating system management and [whole disk encryption][encryption] for any device that holds the data. Otherwise, the researchers have a high degree of agency over the analysis computer. The access locations are low security; researchers must take reasonable measures to physically protect the data but there are no specific requirements or checks on the location of the data itself. Typically this takes the form of storing the researcher’s computer in a locked office, although in the case of graduate student researchers the offices may be shared. The analysis methods are unrestricted, with researchers being able to use any set of statistical software that they can acquire for analysis.

The data access mechanism in the SFUSD-Stanford Partnership only requires one full time data manager at the data custodian to maintain the infrastructure and data transfers, with additional support from a staff member at the data provider and university IT staff. The encrypted storage and computer security measures guard against physical or electronic access by adversarial actors as well as safeguarding the data in the event that a researcher loses their computer. There is no direct monitoring of researchers; the partnership relies on the enforcement of the data use agreements to guard against the misuse of data.

#### New Brunswick Institute for Research, Data and Training (NB-IRDT)

```{r, echo=FALSE, fig.width=5, fig.height=2}
nbirdt = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(2,2,1,1,2))
plot(nbirdt)
```

The NB-IRDT serves as a third party data custodian for the Province of New Brunswick to make deidentified personal and personal health data available to researchers. The data and analysis computers are located at the central NB-IRDT facility. Researchers must also travel to NB-IRDT data centers to access the data; the access computers are thus located at the non-researcher data custodian. Researchers use [thin clients] to remotely access data from a central server, and store their data on a local server at the specific facility that the researcher is at. Researchers have medium agency over the analysis computers, with access to common statistical programs and can request other software packages. NB-IRDT utilizes high security access locations, with researchers performing their research in [secure rooms]; protections include restricting mobile devices and outside materials, physical controls on the servers and workstations, and having dedicated fiber optics cables to handle data connections between the central and satellite locations. The NB-IRDT allows researchers unrestricted analysis methods, relying on manual disclosure control to ensure safe outputs.

The NB-IRDT requires over two dozen staff^[https://www.unb.ca/nbirdt/about/team.html] located at the data custodian, including multiple data analysts, system administrators, and other technical staff to set up and maintain the data access mechanism. The high security for the access location and the protections around it’s analysis computers prevents adversarial actors from gaining physical or electronic access to the data and also allows for the close monitoring of researchers to prevent the misuse of data.

#### Institute for Employment Research (RDC-IAB)

```{r, echo=FALSE, fig.width=5, fig.height=2}
iab1 = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(2,1,2,1,2))
plot(iab1)
```

The RDC-IAB acts as a third-party data custodian for the German Federal Employment Agency. The RDC-IAB uses three different access models, each with its unique implementation. Notably, the RDC-IAB uses different access models for different sets of data; more sensitive data is subject to greater protections while maintaining usability for researchers.

The most restrictive access method is RDC-IAB on-site access, which makes deidentified individual data available to researchers. In this model, the RDC-IAB (acting as the third-party data custodian) maintains the data and analysis computers. Researchers have low agency over the analysis computers, being restricted to approved statistical software; other user provided software is not allowed, and third-party packages for approved software must be approved and installed by RDC-IAB staff. The access computers are located at the RDC-IAB itself or guest RDCs acting as third-party access providers, consisting of secured workstations at RDC-IAB and [thin clients] at its guest RDCs. The access locations are subject to high security, with physical monitoring of researchers. There are limited restrictions on the analysis methods available within the RDC-IAB access mechanism, with certain Stata commands unavailable to researchers.

```{r, echo=FALSE, fig.width=5, fig.height=2}
iab2 = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(2,2,3,3,2))
plot(iab2)
```

In the RDC-IAB JoSuA remote execution system, researchers can still utilize the same microdata but cannot view the data directly. Researchers are limited to viewing the deidentified output from their analysis. This allows the RDC-IAB to relax the controls around the access computers and locations; researchers can utilize their own computers to use the JoSuA interface, and there are no restrictions on access locations. The data and analysis computer remains located with the RDC-IAB, and researchers are subject to the same limitations on their agency over analysis computers and available analysis methods.

```{r, echo=FALSE, fig.width=5, fig.height=2}
iab3 = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,2,3))
plot(iab3)
```

The RDC-IAB also makes data products available for direct download by researchers using a [secure download platform][network protocols], which are further anonymized variants of the microdata available in the other two access methods. In this mechanism, the researcher’s institution acts as the data custodian by hosting the data and the analysis computer, with the researcher’s institution having high agency over the analysis computer. The access computers and access location are also at the researcher’s institution. The RDC-IAB data use agreement for downloading the scientific use files requires a medium security access location, with the building and room required to have some level of access control or monitoring against unauthorized access; options range from receptionists and security guards to admission simple key locks. Note also that scientific use data can only be accessed by European research institutions, though this is a restriction on safe people.

The RDC-IAB has a staff of over two dozen people^[https://www.iab.de/839/section.aspx/Bereichsnummer/17], not counting staff at guest RDCs. Each data center requires at least one staff member, as well as additional staff to maintain the data products and approve projects. The RDC-IAB protects the data and analysis computers from unauthorized access either by maintaining control itself or by mandating strong security around them when in the custody of researchers. In instances where users can view the data directly, the RDC-IAB also relies on the high security of the access locations to further safeguard the data from unauthorized access or misuse.

#### Ohio Longitudinal Data Archive (OLDA)

```{r, echo=FALSE, fig.width=5, fig.height=2}
olda = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,3,3))
plot(olda)
```

The Ohio Longitudinal Data Archive is an intermediary third party data custodian that provides deidentified individual data to researchers on behalf of the state of Ohio. The data is initially located at OLDA before ultimately being transferred to researchers via an [SFTP server][network protocol], where the data and analysis computers are located. The researchers have full agency over the analysis computer, which is required to be a desktop computer with an [IP address registered][IP address restrictions] with OLDA. This computer also doubles as the access computer, and must be located in the researcher’s office. This is a low specification of access location security, placing no additional requirements beyond utilizing a specific space. Researchers have unrestricted analysis methods available for them. Data can be provided in a variety of formats, including CSV files that enable the researcher to use any analysis software or method of their choosing.

OLDA relies on approximately a dozen full time staff to maintain its data access mechanism. It relies heavily on the protections of the data itself and the security of researchers’ institutions to prevent adversarial actors from gaining access or making use of the data it makes available. Similarly, OLDA also relies on the enforcement of its DUA and disclosure review to prevent researchers from misusing the data or generating unauthorized outputs.

#### Aurora Healthcare and MIT

```{r, echo=FALSE, fig.width=5, fig.height=2}
aurora = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,3,3))
plot(aurora)
```

In the data use agreement between Aurora Healthcare and MIT, Aurora Healthcare agreed to make deidentified personal health data for researchers. The data and analysis computers were located at MIT, with data transferred from Aurora Healthcare to MIT Economics Department [servers][on-site storage] via [SFTP][network protocol]. As a result, the researchers had high agency over the analysis computers and unrestricted analysis methods available to them. Researchers could access the data from any computer connected to the MIT network either by being on campus or via a [VPN][virtual private network], with no restrictions on the access location.

This data provider and researchers took advantage of their existing IT staff and infrastructure to facilitate access to the data. The data provider relies on the physical and network security setups at the researcher’s institution to protect the data from adversarial actors. There are no technical controls against the misuse of the data; this highlights the importance of the enforcement of the DUA and the fulfillment of the other Five Safes when crafting data access mechanisms.

#### Private Capital Research Institute (PCRI)

```{r, echo=FALSE, fig.width=5, fig.height=2}
pcri = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(2,1,3,3,2))
plot(pcri)

```
The PCRI data access mechanism shares highly sensitive business information about private capital firms to researchers. In this system, PCRI uses the National Opinion Research Center (NORC) as a third-party location for the data and analysis computers. Researchers have low agency over the analysis computers, being restricted to the Stata. Researchers can only use [thin clients] that are provided to them by NORC. There are no formal restrictions on the location of the access computers, although researchers are required to use their best efforts to prevent unauthorized access. PCRI and NORC implement limited restrictions on the analysis methods available within Stata, prohibiting certain commands and sample sizes.

PCRI itself has three full time and six part-time staff to make the data usable for researchers, but relies on the preexisting resources at NORC for the data access mechanism. The protection against misuse and adversarial actors comes primarily from the storage of the data on secured servers at NORC with its accompanying electronic access controls and monitoring of approved users.

#### City of Cape Town and J-PAL Africa

```{r, echo=FALSE, fig.width=5, fig.height=2}
capetown = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,3,3))
plot(capetown)
```

In the Cape Town partnership, the data was transferred from the data provider to the researcher. As such, the data location, access, and analysis computers are all with the researcher, with the researcher having a full range of analysis methods available. (awaiting updated chapter)

#### Development Impact Evaluation (DIME) at the World Bank

```{r, echo=FALSE, fig.width=5, fig.height=2}
dime = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,3,3))
plot(dime)
```

DIME receives a host of sensitive administrative data, including identified data, from its governmental partners for research use. Governments transfer data directly to DIME via [encrypted protocols][network protocol], which acts as the data custodian and stores the data on its own [servers][on-site storage]. DIME researchers can remotely access the data through [VPN’s][virtual private networks] using [secured laptops][encryption]. Due to the frequent travel by researchers, there are no restrictions on the access locations for DIME researchers. There are no limitations on the analysis methods available to DIME researchers.

DIME works with administrative data from a variety of data providers, including many from low and middle income countries. In cases where the data provider may not have the resources to make the data available, DIME provides the required resources and infrastructure to access the data necessary for its research. Data providers rely on DIME’s security measures, for both its physical IT infrastructure and protocols for its employees, to prevent unauthorized access and the misuse of the data.

#### International Monetary Fund (IMF)

(awaiting updated chapter)

#### Statistics Canada Real Time Remote Access (RTRA)

```{r, echo=FALSE, fig.width=5, fig.height=2}
data = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(1,1,3,3,1))
plot(data)
```

The RTRA system provides access to a Statistics Canada microdata. The data and analysis computers remain with Statistics Canada. Researchers have low agency over the analysis computers, being restricted to only using SAS. The access computers are located with the researcher with open access locations, as they can log into the RTRA via a web interface from any computer. Analysis methods are heavily restricted, with users limited to specific commands within SAS, restricted numbers of procedure calls a day, limits on class variables, and other controls on the SAS environment.[@government_of_canada_system_2011]

The RTRA system is set up by Statistics Canada, which is a major national statistical agency with its associated resources. Researchers only require their own computer to access the data. The data is protected from adversarial actors and misuse by preventing users from viewing the data and automated controlled rounding of the outputs. Additional safeguards primarily concern the evaluation of safe users; a registration and contract are required for access, and researchers must be affiliated with a government department, non-profit organization, or an academic institution.

#### Federal Statistical Research Data Centers (FSRDC)

```{r, echo=FALSE, fig.width=5, fig.height=2}
data = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                 rank=c(1,2,2,1,3))
plot(data)
```

In the United States Federal Statistical Research Data Center (FSRDC) network, federal statistical agencies partner with research institutions to provide secure data access to many different federal statistical products. The data and analysis computers remain with the Census Bureau; for data from other statistical agencies, the Census Bureau acts as a third-party data custodian for the original data provider. Researchers have medium agency over these computers; they are restricted to authorized software but have the ability to request approval for additional software. Within the confines of software availability, analysis methods are otherwise unrestricted. Access computers are [thin clients] located at the partner institutions serving as third-party access providers, which maintain high security access locations in accordance with Census Bureau requirements.[@united_states_census_bureau_federal_nodate] 

Each network RDC has several full staff members to maintain the access computers and access location; initial startup costs could reach hundreds of thousands dollars, with ongoing operating costs for staff time.[@united_states_census_bureau_hosting_nodate]The maintenance of the data and analysis computer is a massive undertaking performed by the data provider. The FSRDC network relies on all aspects of data access mechanisms to protect the data that it makes available for researchers. of highest level of security for protecting sensitive data, but are also more expensive than other methods which rely more on trust and less on physical security.

#### Safepod

```{r, echo=FALSE, fig.width=5, fig.height=2}
data = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                 rank=c(1,2,2,2,3))
plot(data)
```

The SafePod network in the United Kingdom makes deidentified administrative data from the Office of National Statistics, UK Data Service, SAIL Databank, and NHS Scotland available for researchers. A SafePod is a prefabricated room with a single [thin client] with remote access to analysis computers and data located with the data provider.[@university_of_bristol_safepod_nodate] The agency that researchers have over analysis computers and restrictions on analysis methods remain at the discretion of each data provider; using the Office of National Statistics as an example, researchers have medium agency over the analysis computers and unrestricted, being allowed access to a predefined list of statistical software with no further restrictions beyond software availability.[@office_for_national_statistics_accessing_nodate] The unique aspect of the SafePod is the security of the access locations. SafePods are a minimalistic yet robust implementation of a medium security location (an access controlled space with CCTV monitoring) that can exist within low security environments such as university libraries.

SafePods are relatively cheap, requiring only a suitable location to place a prefabricated room and can use existing staff members to manage access to the SafePod. While the SafePod is still a physical location that requires installation and ongoing staff and maintenance, it is an example of innovation in more access locations to provide protection against the various security threats at a lower cost than a traditional full scale research data center.

#### National Center for Education Statistics (NCES) Restricted Use Data License

```{r, echo=FALSE, fig.width=5, fig.height=2}
nces = data.frame(metrics=c("Location of Data and Analysis Computer","Researcher Agency Over Analysis Computer","Location and Type of Access Computer","Security of Access Room","Range of Analysis Methods"),
                  rank=c(3,3,3,2,3))
plot(nces)
```

The NCES, a part of the United States Department of Education, allows researchers to apply for a restricted use data license for deidentified individual level data on education. Under the terms of the license, the researchers serve as the data custodian and receive the data on an [encrypted CD][physical media] from NCES. As such, the data and analysis computers are located with the researcher, and the analysis computer is the access computer. The license has specific requirements for the security of the analysis computers and [storage of data][on-site storage]. Researchers have high authority over the analysis computer and unrestricted analysis methods, being able to use any software or methods available to them. The license mandates a medium level of security for the access location, requiring that it must be a locked room with access restricted to authorized users but without additional specifications for security. The security arrangements must be approved by NCES prior to the receipt of restricted use data and are subject to unannounced inspections.[@national_center_for_education_statistics_restricted-use_nodate]

The NCES restricted licenses require minimal resources for the data access mechanism; using physical media minimizes the technical resources needed to set up and harden a transfer mechanism. Researchers can utilize their existing university resources to set up the access location. The license requires primarily on the security of the access location and specifications for data storage to protect against adversarial actors. NCES relies on its disclosure review process to protect against misuse.

### Guidance for Data Providers and Researchers

Through outlining the five aspects of data access mechanisms and examining how existing data access mechanisms fit into this model, we can draw various conclusions and provide some guidance for data providers and researchers looking to implement new data access mechanisms.

For data providers with the capacity and resources to implement technological solutions, there exist several examples of its potential for increased opportunities for wider and more convenient access to data. Access mechanisms such as the RDC-IAB in person access model, NB-IRDT, and the FSRDC network represent traditional, highly secured and highly technically sophisticated methods of provisioning access today. However, the RDC-IAB JoSuA remote access system, the UK SafePod Network, and the Statistics Canada RTRA demonstrate that very similar sets of data can be accessed from a wider range of locations and with fewer resources required through the proper use of innovative technological solutions. These mechanisms all make available data with specific legal requirements around their protection and use to a wide range of researchers. Data providers looking to make their data available should consult with the appropriate legal and information security specialists to determine the relevant legal and regulatory restrictions and how technical solutions can meet these requirements.

On the other hand, setting up data access mechanisms should not be seen as an insurmountable barrier for data providers regardless of the level of existing technical capacity. Not every data sharing partnership requires highly sophisticated mechanisms with large infrastructure investments such as the FSRDC network. There are also many examples of relatively simple data access mechanisms but effective and sufficient for the needs of the data provider and the data sharing partnership. Mechanisms such as the NCES restricted use data license, which in terms of the physical data access mechanism (ignoring the processing of applications and enforcement of the security requirements at the researcher’s end) only requires that the data provider have someone to load data onto a CD, encrypt it, and send it out by mail, demonstrates that this can be done even in situations with potentially very limited resources. The protection of data at rest and in transit with the use of encryption and secure transfer mechanisms are relatively cheap to accomplish; the threat of adversarial actors can be greatly mitigated with a minimal investment in the proper physical resources.

Another observation is that five aspects complement each other and they do not all need to be maintained under the tightest control to create the overall safe setting. While there is the temptation to always maintain the strongest possible protections across all aspects, existing mechanisms show that under the right conditions, a data provider can allow researchers more flexibility in some aspects while maintaining the overall security of the system. Perhaps the most direct example of this is the differences between the RDC-IAB on site access versus remote access models. The same projects, people, and outputs are allowed in both models. Even the same sets of data can be used for analysis, with the only change between the two models being how much of that data is exposed to researchers via the data access mechanism. As a result of this change, the restrictions on access locations in the data access mechanism can be relaxed completely. This has the benefit of allowing much broader access to the data for researchers, with the associated increased utility of the data and additional potential for researchers generating findings relevant for policymakers.

However, data access mechanisms do not exist in a vacuum. The necessary aspects of a data access mechanism and the restrictions that are placed on the researchers’ access to the data should be considered in the context of the other parts of the five safes framework. The conditions that a data access mechanism must provide to fulfill the requirements for safe settings are dependent on its interactions with the other four safes. DIME at the World Bank, OLDA, the SFUSD-Stanford Partnership, Aurora Healthcare and MIT, and the City of Cape Town and J-PAL partnership are all examples where the data providers from a spectrum of high, medium, and low income countries directly transfers highly sensitive individual level data and confidential government data that have great potential for harm in the event of disclosure. However, the proper protections of the data at the researcher and the fulfillment of the other aspects of the five safes data to the data provider’s satisfaction allows the use of data access mechanisms that provide the researchers with a high level of flexibility.

A final related point is that the enforcement of the terms of the ||data use agreement|| is an important factor in determining the level of control that data providers must maintain over the data access system. In situations where the data provider grants greater autonomy to the researcher, the greater the complexity and strength of enforcement of the DUA provisions is required to compensate for that flexibility. This corresponds to a tradeoff between the investment in physical infrastructure and human resources necessary for tight control over a data access mechanism versus the investment in the institutional and legal framework of data access. In the partnerships above, the necessary protections in the data access mechanism are set in large part by the DUA.