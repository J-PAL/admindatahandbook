
@incollection{dwork_generalization_2015,
	title = {Generalization in {Adaptive} {Data} {Analysis} and {Holdout} {Reuse}},
	url = {http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toni and Reingold, Omer and Roth, Aaron},
	editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
	keywords = {primary, OA, value of privacy},
	pages = {2341--2349}
}

@inproceedings{duchi_local_2013,
	address = {Washington, DC, USA},
	series = {{FOCS} '13},
	title = {Local {Privacy} and {Statistical} {Minimax} {Rates}},
	isbn = {978-0-7695-5135-7},
	url = {http://dx.doi.org/10.1109/FOCS.2013.53},
	doi = {10.1109/FOCS.2013.53},
	booktitle = {Proceedings of the 2013 {IEEE} 54th {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	publisher = {IEEE Computer Society},
	author = {Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
	year = {2013},
	keywords = {primary, formal privacy, Differential privacy, estimation, minimax rates, Paywall},
	pages = {429--438}
}

@inproceedings{dinur_revealing_2003,
	address = {New York, NY, USA},
	series = {{PODS} '03},
	title = {Revealing information while preserving privacy},
	isbn = {1-58113-670-6},
	url = {http://doi.acm.org/10.1145/773153.773173},
	doi = {10.1145/773153.773173},
	booktitle = {Proceedings of the {Twenty}-second {ACM} {SIGMOD}-{SIGACT}-{SIGART} {Symposium} on {Principles} of {Database} {Systems}},
	publisher = {ACM},
	author = {Dinur, Irit and Nissim, Kobbi},
	year = {2003},
	note = {event-place: San Diego, California},
	keywords = {primary, formal privacy, Paywall, data reconstruction, integrity and security, subset-sums with noise},
	pages = {202--210},
	file = {Dinur and Nissim - 2003 - Revealing information while preserving privacy.pdf:/home/vilhuber/Zotero/storage/ZPCIU3V7/Dinur and Nissim - 2003 - Revealing information while preserving privacy.pdf:application/pdf}
}

@article{dwork_algorithmic_2014,
	title = {The {Algorithmic} {Foundations} of {Differential} {Privacy}},
	volume = {9},
	issn = {1551-305X},
	url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
	doi = {10.1561/0400000042},
	number = {3-4},
	journal = {Foundations and Trends in Theoretical Computer Science},
	author = {Dwork, Cynthia and Roth, Aaron},
	year = {2014},
	keywords = {background, primary, formal privacy, OA},
	pages = {211--407}
}

@inproceedings{dwork_calibrating_2006,
	address = {Berlin, Heidelberg},
	series = {{TCC}'06},
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	isbn = {978-3-540-32731-8},
	url = {https://link.springer.com/chapter/10.1007%2F11681878_14},
	doi = {10.1007/11681878_14},
	booktitle = {Proceedings of the {Third} conference on {Theory} of {Cryptography}},
	publisher = {Springer-Verlag},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	year = {2006},
	note = {event-place: New York, NY},
	keywords = {primary, formal privacy, Paywall},
	pages = {265--284}
}

@article{duncan_disclosure-limited_1986,
	title = {Disclosure-limited data dissemination},
	volume = {81},
	url = {https://www.jstor.org/stable/2287959},
	doi = {10.1080/01621459.1986.10478229},
	number = {393},
	journal = {Journal of the American Statistical Association},
	author = {Duncan, George and Lambert, Diane},
	year = {1986},
	keywords = {primary, SDL, statistical disclosure limitation, Paywall},
	pages = {10--18},
	file = {1986-1987preprintar27.pdf:/home/vilhuber/Zotero/storage/QBZVUU6H/Disclosure-limited data dissemination.pdf:application/pdf;JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/N4NLKSXY/Duncan and Lambert - 1986 - Disclosure-Limited Data Dissemination.pdf:application/pdf}
}

@article{dalenius_towards_1977,
	title = {Towards a methodology for statistical disclosure control},
	volume = {15},
	doi = {10.1145/320613.320616},
	journal = {Statistik Tidskrift},
	author = {Dalenius, Tore},
	year = {1977},
	keywords = {primary, SDL, statistical disclosure limitation},
	pages = {429--444}
}

@article{cummings_adaptive_2016,
	title = {Adaptive {Learning} with {Robust} {Generalization} {Guarantees}},
	volume = {abs/1602.07726},
	url = {http://arxiv.org/abs/1602.07726},
	journal = {CoRR},
	author = {Cummings, Rachel and Ligett, Katrina and Nissim, Kobbi and Roth, Aaron and Wu, Zhiwei Steven},
	year = {2016},
	keywords = {primary, OA, value of privacy}
}

@article{couper_risk_2008,
	title = {Risk of disclosure, perceptions of risk, and concerns about privacy and confidentiality as factors in survey participation},
	volume = {24},
	url = {http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/risk-of-disclosure-perceptions-of-risk-and-concerns-about-privacy-and-confidentiality-as-factors-in-survey-participation.pdf},
	number = {2},
	journal = {Journal of official statistics},
	author = {Couper, Mick P and Singer, Eleanor and Conrad, Frederick G and Groves, Robert M},
	year = {2008},
	keywords = {primary, OA, value of privacy},
	pages = {255}
}

@book{us_department_of_commerce_us_2018,
	title = {U.{S}.{\textbackslash} {Department} of {Commerce} {Announces} {Reinstatement} of {Citizenship} {Question} to the 2020 {Decennial} {Census}},
	url = {https://www.commerce.gov/news/press-releases/2018/03/us-department-commerce-announces-reinstatement-citizenship-question-2020},
	author = {{U.S. Department of Commerce}},
	year = {2018},
	keywords = {primary, OA, policy}
}

@book{hr4174_confidential_2018,
	title = {Confidential {Information} {Protection} and {Statistical} {Efficency} {Act}},
	url = {https://www.congress.gov/bill/115th-congress/house-bill/4174},
	author = {{H.R.4174}},
	year = {2018},
	keywords = {background, primary, policy}
}

@book{44_us_code_confidential_2002,
	title = {Confidential {Information} {Protection} and {Statistical} {Efficency} {Act}},
	url = {http://www.law.cornell.edu/topn/confidential_information_protection_and_statistical_efficiency_act_of_2002},
	author = {{44 U.S. Code}},
	year = {2002},
	keywords = {background, primary, policy}
}

@article{childs_confidence_2015,
	title = {Confidence in {U}.{S}. federal statistical agencies},
	volume = {8},
	issn = {2168-0094},
	url = {https://www.surveypractice.org/article/2833-confidence-in-u-s-federal-statistical-agencies},
	doi = {10.29115/sp-2015-0024},
	abstract = {At a time when public confidence in the Federal government is at an all-time low, Federal statistical agencies were interested in knowing whether their image would suffer as well. Using data gathered in the Gallup Daily Poll to answer this question, we found that, as level of knowledge about federal statistics increases and for data users, respondents' discrimination among government entities seems to increase – the strength of the relationships between confidence in the Federal Statistical System, on one hand, and in Congress and the Military, on the other, decreases. In a time when confidence in Congress is particularly poor, increasing knowledge about the statistical system and increasing the public's use of statistical data, through programs like "Statistics in Schools" could help people differentiate between sectors of the government, thus increasing confidence in the Federal Statistical System.},
	number = {5},
	journal = {Survey Practice},
	author = {Childs, Jennifer Hunter and King, Ryan and Fobia, Aleia},
	year = {2015},
	keywords = {primary, OA, Confidence in Institutions, official statistics, Trust in Government, Trust in Official Statistics}
}

@article{card_inequality_2012,
	title = {Inequality at work: the effect of peer salaries on job satisfaction},
	volume = {102},
	url = {http://www.aeaweb.org/articles?id=10.1257/aer.102.6.2981},
	doi = {10.1257/aer.102.6.2981},
	number = {6},
	journal = {American Economic Review},
	author = {Card, David and Mas, Alexandre and Moretti, Enrico and Saez, Emmanuel},
	month = may,
	year = {2012},
	keywords = {primary, Paywall, value of data},
	pages = {2981--3003}
}

@article{cummings_empirical_2014,
	title = {The {Empirical} {Implications} of {Privacy}-{Aware} {Choice}},
	volume = {abs/1401.0336},
	url = {http://arxiv.org/abs/1401.0336},
	journal = {CoRR},
	author = {Cummings, Rachel and Echenique, Federico and Wierman, Adam},
	year = {2014},
	keywords = {primary, formal privacy, OA}
}

@book{13_us_code_usc_1954,
	title = {{USC}: {Title} 13 - {Census} {Act}},
	url = {https://www.law.cornell.edu/uscode/pdf/lii_usc_TI_13.pdf},
	author = {{13 U.S. Code}},
	year = {1954},
	keywords = {background, primary, policy}
}

@article{campbell_privacy_2015,
	title = {Privacy {Regulation} and {Market} {Structure}},
	volume = {24},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jems.12079},
	doi = {10.1111/jems.12079},
	abstract = {This paper models how regulatory attempts to protect the privacy of consumers' data affect the competitive structure of data-intensive industries. Our results suggest that the commonly used consent-based approach may disproportionately benefit firms that offer a larger scope of services. Therefore, though privacy regulation imposes costs on all firms, it is small firms and new firms that are most adversely affected. We then show that this negative effect will be particularly severe for goods where the price mechanism does not mediate the effect, such as the advertising-supported Internet.},
	number = {1},
	journal = {Journal of Economics \& Management Strategy},
	author = {Campbell, James and Goldfarb, Avi and Tucker, Catherine},
	year = {2015},
	keywords = {primary, Paywall, economics of privacy},
	pages = {47--73}
}

@article{brenner_impossibility_2014,
	title = {Impossibility of {Differentially} {Private} {Universally} {Optimal} {Mechanisms}},
	volume = {43},
	url = {https://doi.org/10.1137/110846671},
	doi = {10.1137/110846671},
	number = {5},
	journal = {SIAM Journal on Computing},
	author = {Brenner, Hai and Nissim, Kobbi},
	year = {2014},
	keywords = {Formal Privacy, primary, OA},
	pages = {1513--1540}
}

@article{anderson_challenges_2007,
	title = {Challenges to the confidentiality of {US} federal statistics, 1910-1965},
	volume = {23},
	url = {https://www.scb.se/contentassets/ff271eeeca694f47ae99b942de61df83/challenges-to-the-confidentiality-of-u.s.-federal-statistics-1910-1965.pdf},
	number = {1},
	journal = {Journal of Official Statistics},
	author = {Anderson, Margo and Seltzer, William},
	year = {2007},
	keywords = {primary, Statistical Disclosure Limitation, SDL, OA},
	pages = {1}
}

@article{acquisti_economics_2016,
	title = {The {Economics} of {Privacy}},
	volume = {54},
	url = {http://www.aeaweb.org/articles?id=10.1257/jel.54.2.442},
	doi = {10.1257/jel.54.2.442},
	number = {2},
	journal = {Journal of Economic Literature},
	author = {Acquisti, Alessandro and Taylor, Curtis and Wagman, Liad},
	month = jun,
	year = {2016},
	keywords = {Economics of Privacy, primary, Free},
	pages = {442--492}
}

@article{bergemann_design_2018,
	title = {The {Design} and {Price} of {Information}},
	volume = {108},
	url = {http://www.aeaweb.org/articles?id=10.1257/aer.20161079},
	doi = {10.1257/aer.20161079},
	number = {1},
	journal = {American Economic Review},
	author = {Bergemann, Dirk and Bonatti, Alessandro and Smolin, Alex},
	month = jan,
	year = {2018},
	keywords = {primary, Paywall, value of data, data unions},
	pages = {1--48},
	file = {d2049-r.pdf:/home/vilhuber/Zotero/storage/KXW8UGUY/d2049-r.pdf:application/pdf}
}

@techreport{abowd_economic_2018,
	type = {eprint},
	title = {An {Economic} {Analysis} of {Privacy} {Protection} and {Statistical} {Accuracy} as {Social} {Choices}},
	url = {https://arxiv.org/abs/1808.06303},
	number = {1808.06303},
	institution = {arXiv},
	author = {Abowd, John M. and Schmutte, Ian M.},
	year = {2018},
	keywords = {background, Economics of Privacy, Formal Privacy, Statistical Disclosure Limitation, OA, secondary}
}

@article{abowd_economic_2019,
	title = {An {Economic} {Analysis} of {Privacy} {Protection} and {Statistical} {Accuracy} as {Social} {Choices}},
	volume = {109},
	doi = {10.1257/aer.20170627},
	abstract = {Statistical agencies face a dual mandate to publish accurate statistics while protecting respondent privacy. Increasing privacy protection requires decreased accuracy. Recognizing this as a resource allocation problem, we propose an economic solution: operate where the marginal cost of increasing privacy equals the marginal benefit. Our model of production, from computer science, assumes data are published using an efficient differentially private algorithm. Optimal choice weighs the demand for accurate statistics against the demand for privacy. Examples from U.S.{\textbackslash} statistical programs show how our framework can guide decision-making. Further progress requires a better understanding of willingness-to-pay for privacy and statistical accuracy.},
	number = {1},
	journal = {American Economic Review},
	author = {Abowd, John and Schmutte, Ian},
	year = {2019},
	keywords = {background, Economics of Privacy, Formal Privacy, primary, Statistical Disclosure Limitation, Paywall, Computer Science - Cryptography and Security},
	pages = {171--202},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/YBM3P4XL/Abowd and Schmutte - 2019 - An Economic Analysis of Privacy Protection and Sta.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/P8UY5T4B/1808.html:text/html}
}

@article{abowd_economic_2015,
	title = {Economic analysis and statistical disclosure limitation},
	url = {http://www.brookings.edu/ /media/Projects/BPEA/Spring-2015-Revised/AbowdText.pdf?la=en},
	doi = {10.1353/eca.2016.0004},
	journal = {Brookings Papers on Economic Activity},
	author = {Abowd, John and Schmutte, Ian M.},
	year = {2015},
	keywords = {primary, Statistical Disclosure Limitation, SDL, Sloan-annual-report, OA},
	pages = {221--267}
}

@article{abowd_why_2016,
	title = {Why {Statistical} {Agencies} {Need} to {Take} {Privacy}-loss {Budgets} {Seriously}, and {What} {It} {Means} {When} {They} {Do}},
	url = {https://digitalcommons.ilr.cornell.edu/ldi/32/},
	journal = {The 13th Biennial Federal Committee on Statistical Methodology (FCSM) Policy Conference},
	author = {Abowd, John M.},
	year = {2016},
	keywords = {primary, OA, Official Statistics}
}

@article{abowd_how_2017,
	title = {How {Will} {Statistical} {Agencies} {Operate} {When} {All} {Data} {Are} {Private}?},
	volume = {7},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/404},
	doi = {10.29012/jpc.v7i3.404},
	number = {3},
	journal = {Journal of Privacy and Confidentiality},
	author = {Abowd, John M.},
	year = {2017},
	keywords = {primary, OA, Official Statistics}
}

@misc{noauthor_design_nodate,
	title = {The {Design} and {Price} of {Information}: {Publications} {\textbar} {Dirk} {Bergemann}},
	url = {http://campuspress.yale.edu/dirkbergemann/research/publications/},
	urldate = {2020-02-27},
	note = {Published Paper \#7 contains a free PDF of "The Design and Price of Information"},
	file = {Publications | Dirk Bergemann:/home/vilhuber/Zotero/storage/SEB6W8NQ/publications.html:text/html}
}

@misc{noauthor_daniel_nodate,
	title = {Daniel {Kifer} - {Penn} {State}: ℓ-{Diversity}: {Privacy} {Beyond} k-{Anonymity} \& {Privacy}: {Theory} meets {Practice} on the {Map}.},
	url = {http://www.cse.psu.edu/~duk17/},
	urldate = {2020-02-27},
	note = {7th publication from the bottom contains link to free PDF for "ℓ-Diversity: Privacy Beyond k-Anonymity"
11th publication from the bottom contains link to free PDF for "Privacy: Theory meets Practice on the Map."},
	file = {Daniel Kifer - Penn State:/home/vilhuber/Zotero/storage/YNZKDFQM/~duk17.html:text/html}
}

@misc{jorgensen_et_al_conservative_nodate,
	title = {Conservative or liberal? {Personalized} differential privacy via {Graham} {Cormode}'s webpage},
	url = {http://dimacs.rutgers.edu/~graham/},
	urldate = {2020-02-27},
	author = {Jorgensen et al.},
	note = {Under the "Research" tab, \#23 in Conference Publications leads to a free PDF of "Conservative or liberal? personalized differential privacy."},
	file = {Graham Cormode's mess of pages:/home/vilhuber/Zotero/storage/YKM3FQUR/~graham.html:text/html}
}

@misc{rothblum_publications_2014,
	title = {Publications: {A} {Multiplicative} {Weights} {Mechanism} for {Privacy}-{Preserving} {Data} {Analysis}},
	url = {https://guyrothblum.wordpress.com/about/publications/},
	abstract = {Recent Manuscripts On Prover-Efficient Public-Coin Emulation of Interactive Proofs G. Arnon and G. N. Rothblum Worst-Case to Average-Case Reductions for Subclasses of P O. Goldreich and G. N. Rothb…},
	language = {en},
	urldate = {2020-02-27},
	journal = {Guy Rothblum's Homepage},
	author = {Rothblum, Guy N.},
	month = nov,
	year = {2014},
	note = {Links to a free PDF of "A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis" about halfway through his publications list},
	file = {Snapshot:/home/vilhuber/Zotero/storage/6RLQ97RD/publications.html:text/html}
}

@article{dwork_calibrating_2016,
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	volume = {7},
	copyright = {Copyright (c) 2016-2017 the authors},
	issn = {2575-8527},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/405},
	doi = {10.29012/jpc.v7i3.405},
	language = {en},
	number = {3},
	urldate = {2020-02-27},
	journal = {Journal of Privacy and Confidentiality},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	year = {2016},
	note = {Number: 3},
	keywords = {primary, formal privacy, differential privacy, OA, noise addition, private data analysis, statistical data privacy},
	pages = {17--51},
	file = {Full Text PDF:/home/vilhuber/Zotero/storage/KR6JFPEK/Dwork et al. - 2016 - Calibrating Noise to Sensitivity in Private Data A.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/ZSRBJGE2/405.html:text/html}
}

@techreport{manski_communicating_2014,
	type = {Working {Paper}},
	title = {Communicating {Uncertainty} in {Official} {Economic} {Statistics}},
	url = {http://www.nber.org/papers/w20098},
	abstract = {Federal statistical agencies in the United States and analogous agencies elsewhere commonly report official economic statistics as point estimates, without accompanying measures of error. Users of the statistics may incorrectly view them as error-free or may incorrectly conjecture error magnitudes. This paper discusses strategies to mitigate misinterpretation of official statistics by communicating uncertainty to the public. Sampling error can be measured using established statistical principles. The challenge is to satisfactorily measure the various forms of non-sampling error. I find it useful to distinguish transitory statistical uncertainty, permanent statistical uncertainty, and conceptual uncertainty. I illustrate how each arises as the Bureau of Economic Analysis periodically revises GDP estimates, the Census Bureau generates household income statistics from surveys with non-response, and the Bureau of Labor Statistics seasonally adjusts employment statistics.},
	number = {20098},
	urldate = {2020-02-27},
	institution = {National Bureau of Economic Research},
	author = {Manski, Charles F},
	month = may,
	year = {2014},
	doi = {10.3386/w20098},
	note = {Series: Working Paper Series},
	file = {Full Text PDF:/home/vilhuber/Zotero/storage/V2PTDKCQ/Manski - 2014 - Communicating Uncertainty in Official Economic Sta.pdf:application/pdf}
}

@techreport{card_inequality_2010,
	type = {Working {Paper}},
	title = {Inequality at {Work}: {The} {Effect} of {Peer} {Salaries} on {Job} {Satisfaction}},
	shorttitle = {Inequality at {Work}},
	url = {http://www.nber.org/papers/w16396},
	abstract = {We use a simple theoretical framework and a randomized manipulation of access to information on peers' wages to provide new evidence on the effects of relative pay on individual job satisfaction and job search intentions. A randomly chosen subset of employees of the University of California (UC) was informed about a new website listing the pay of University employees. All employees were then surveyed about their job satisfaction and job search intentions. Our information treatment doubles the fraction of employees using the website, with the vast majority of new users accessing data on the pay of colleagues in their own department. We find an asymmetric response to the information treatment: workers with salaries below the median for their pay unit and occupation report lower pay and job satisfaction, while those earning above the median report no higher satisfaction. Likewise, below-median earners report a significant increase in the likelihood of looking for a new job, while above-median earners are unaffected. Our findings suggest that job satisfaction depends directly on relative pay comparisons, and that this relationship is non-linear.},
	number = {16396},
	urldate = {2020-02-27},
	institution = {National Bureau of Economic Research},
	author = {Card, David and Mas, Alexandre and Moretti, Enrico and Saez, Emmanuel},
	month = sep,
	year = {2010},
	doi = {10.3386/w16396},
	note = {Series: Working Paper Series},
	file = {Full Text PDF:/home/vilhuber/Zotero/storage/AZ6URC4P/Card et al. - 2010 - Inequality at Work The Effect of Peer Salaries on.pdf:application/pdf}
}

@misc{sweeney_achieving_nodate,
	title = {{ACHIEVING} k-{ANONYMITY} {PRIVACY} {PROTECTION} {USING} {GENERALIZATION} {AND} {SUPPRESSION}},
	url = {https://dataprivacylab.org/projects/kanonymity/kanonymity2.html},
	urldate = {2020-02-27},
	author = {Sweeney, Latanya},
	file = {k-anonymity:/home/vilhuber/Zotero/storage/64QEW8GM/kanonymity2.html:text/html}
}

@techreport{campbell_privacy_2013,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Privacy {Regulation} and {Market} {Structure}},
	url = {https://papers.ssrn.com/abstract=1729405},
	abstract = {This paper models how regulatory attempts to protect the privacy of consumers' data affect the competitive structure of data-intensive industries. Our results suggest that the commonly used consent-based approach may disproportionately benefit firms that offer a larger scope of services. Therefore, though privacy regulation imposes costs on all firms, it is small firms and new firms that are most adversely affected. We then show that this negative effect will be particularly severe for goods where the price mechanism does not mediate the effect, such as the advertising-supported internet.},
	language = {en},
	number = {ID 1729405},
	urldate = {2020-02-27},
	institution = {Social Science Research Network},
	author = {Campbell, James David and Goldfarb, Avi and Tucker, Catherine E.},
	month = aug,
	year = {2013},
	doi = {10.2139/ssrn.1729405},
	keywords = {antitrust, privacy, regulation},
	file = {Snapshot:/home/vilhuber/Zotero/storage/W3RYZIEF/papers.html:text/html;Submitted Version:/home/vilhuber/Zotero/storage/I4CC2Q6X/Campbell et al. - 2013 - Privacy Regulation and Market Structure.pdf:application/pdf}
}

@article{goldfarb_shifts_2012,
	title = {Shifts in {Privacy} {Concerns}},
	volume = {102},
	issn = {0002-8282},
	url = {https://www.jstor.org/stable/23245555},
	number = {3},
	urldate = {2020-02-27},
	journal = {The American Economic Review},
	author = {Goldfarb, Avi and Tucker, Catherine},
	year = {2012},
	note = {Publisher: American Economic Association},
	keywords = {primary, economics, value of privacy, Paywall, economics of privacy, privacy, measurement, privacy measurement},
	pages = {349--353},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/UYLYABSU/Goldfarb and Tucker - 2012 - Shifts in Privacy Concerns.pdf:application/pdf}
}

@article{spencer_optimal_1985,
	title = {Optimal {Data} {Quality}},
	volume = {80},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2288471},
	doi = {10.2307/2288471},
	abstract = {Commonly accepted hypotheses guide practical determination of needed data quality; for example, as the probability that a decision uses data increases, the needed data quality increases, and the more rudimentary the uses of the data, the less data quality is needed. These hypotheses are formally defined and analyzed in some decision-theoretic models. Conditions under which the hypotheses hold and fail are examined. Particular attention is given to determining needed data quality when the users of the data behave nonoptimally.},
	number = {391},
	urldate = {2020-02-25},
	journal = {Journal of the American Statistical Association},
	author = {Spencer, Bruce D.},
	year = {1985},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {564--573},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/JZLLGCH2/Spencer - 1985 - Optimal Data Quality.pdf:application/pdf}
}

@inproceedings{haney_utility_2017,
	address = {Chicago, Illinois, USA},
	title = {Utility {Cost} of {Formal} {Privacy} for {Releasing} {National} {Employer}-{Employee} {Statistics}},
	isbn = {978-1-4503-4197-4},
	url = {http://dl.acm.org/citation.cfm?doid=3035918.3035940},
	doi = {10.1145/3035918.3035940},
	abstract = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.},
	language = {en},
	urldate = {2020-02-25},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data} - {SIGMOD} '17},
	publisher = {ACM Press},
	author = {Haney, Samuel and Machanavajjhala, Ashwin and Abowd, John M. and Graham, Matthew and Kutzbach, Mark and Vilhuber, Lars},
	year = {2017},
	pages = {1339--1354},
	file = {Haney et al. - 2017 - Utility Cost of Formal Privacy for Releasing Natio.pdf:/home/vilhuber/Zotero/storage/JL6N53AJ/Haney et al. - 2017 - Utility Cost of Formal Privacy for Releasing Natio.pdf:application/pdf}
}

@article{ghosh_universally_2009,
	title = {Universally {Utility}-{Maximizing} {Privacy} {Mechanisms}},
	url = {http://arxiv.org/abs/0811.2841},
	abstract = {A mechanism for releasing information about a statistical database with sensitive data must resolve a trade-off between utility and privacy. Privacy can be rigorously quantified using the framework of \{{\textbackslash}em differential privacy\}, which requires that a mechanism's output distribution is nearly the same whether or not a given database row is included or excluded. The goal of this paper is strong and general utility guarantees, subject to differential privacy. We pursue mechanisms that guarantee near-optimal utility to every potential user, independent of its side information (modeled as a prior distribution over query results) and preferences (modeled via a loss function). Our main result is: for each fixed count query and differential privacy level, there is a \{{\textbackslash}em geometric mechanism\} \$M{\textasciicircum}*\$ -- a discrete variant of the simple and well-studied Laplace mechanism -- that is \{{\textbackslash}em simultaneously expected loss-minimizing\} for every possible user, subject to the differential privacy constraint. This is an extremely strong utility guarantee: \{{\textbackslash}em every\} potential user \$u\$, no matter what its side information and preferences, derives as much utility from \$M{\textasciicircum}*\$ as from interacting with a differentially private mechanism \$M\_u\$ that is optimally tailored to \$u\$.},
	urldate = {2020-02-25},
	journal = {arXiv:0811.2841 [cs]},
	author = {Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
	month = mar,
	year = {2009},
	note = {arXiv: 0811.2841},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Databases},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/I83NTJMP/Ghosh et al. - 2009 - Universally Utility-Maximizing Privacy Mechanisms.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/LHUER6ZH/0811.html:text/html}
}

@article{posner_economics_1981,
	title = {The {Economics} of {Privacy}},
	volume = {71},
	issn = {0002-8282},
	url = {https://www.jstor.org/stable/1815754},
	number = {2},
	urldate = {2020-02-25},
	journal = {The American Economic Review},
	author = {Posner, Richard A.},
	year = {1981},
	note = {Publisher: American Economic Association},
	keywords = {primary, Paywall, economics of privacy},
	pages = {405--409},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/DU7R6MNM/Posner - 1981 - The Economics of Privacy.pdf:application/pdf}
}

@article{ghosh_selling_2011,
	title = {Selling {Privacy} at {Auction}},
	url = {http://arxiv.org/abs/1011.1375},
	abstract = {We initiate the study of markets for private data, though the lens of differential privacy. Although the purchase and sale of private data has already begun on a large scale, a theory of privacy as a commodity is missing. In this paper, we propose to build such a theory. Specifically, we consider a setting in which a data analyst wishes to buy information from a population from which he can estimate some statistic. The analyst wishes to obtain an accurate estimate cheaply. On the other hand, the owners of the private data experience some cost for their loss of privacy, and must be compensated for this loss. Agents are selfish, and wish to maximize their profit, so our goal is to design truthful mechanisms. Our main result is that such auctions can naturally be viewed and optimally solved as variants of multi-unit procurement auctions. Based on this result, we derive auctions for two natural settings which are optimal up to small constant factors: 1. In the setting in which the data analyst has a fixed accuracy goal, we show that an application of the classic Vickrey auction achieves the analyst's accuracy goal while minimizing his total payment. 2. In the setting in which the data analyst has a fixed budget, we give a mechanism which maximizes the accuracy of the resulting estimate while guaranteeing that the resulting sum payments do not exceed the analysts budget. In both cases, our comparison class is the set of envy-free mechanisms, which correspond to the natural class of fixed-price mechanisms in our setting. In both of these results, we ignore the privacy cost due to possible correlations between an individuals private data and his valuation for privacy itself. We then show that generically, no individually rational mechanism can compensate individuals for the privacy loss incurred due to their reported valuations for privacy.},
	urldate = {2020-02-25},
	journal = {arXiv:1011.1375 [cs]},
	author = {Ghosh, Arpita and Roth, Aaron},
	month = nov,
	year = {2011},
	note = {arXiv: 1011.1375},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/QLN7Q25N/Ghosh and Roth - 2011 - Selling Privacy at Auction.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/X7LD2QKZ/1011.html:text/html}
}

@article{nissim_privacy-aware_2012,
	title = {Privacy-{Aware} {Mechanism} {Design}},
	url = {http://arxiv.org/abs/1111.3350},
	abstract = {In traditional mechanism design, agents only care about the utility they derive from the outcome of the mechanism. We look at a richer model where agents also assign non-negative dis-utility to the information about their private types leaked by the outcome of the mechanism. We present a new model for privacy-aware mechanism design, where we only assume an upper bound on the agents' loss due to leakage, as opposed to previous work where a full characterization of the loss was required. In this model, under a mild assumption on the distribution of how agents value their privacy, we show a generic construction of privacy-aware mechanisms and demonstrate its applicability to electronic polling and pricing of a digital good.},
	urldate = {2020-02-25},
	journal = {arXiv:1111.3350 [cs]},
	author = {Nissim, Kobbi and Orlandi, Claudio and Smorodinsky, Rann},
	month = feb,
	year = {2012},
	note = {arXiv: 1111.3350},
	keywords = {Computer Science - Computer Science and Game Theory},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/D42X3BD2/Nissim et al. - 2012 - Privacy-Aware Mechanism Design.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/P5AYJYTG/1111.html:text/html}
}

@article{goroff_balancing_2015,
	title = {Balancing privacy versus accuracy in research protocols},
	volume = {347},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aaa3483},
	doi = {10.1126/science.aaa3483},
	language = {en},
	number = {6221},
	urldate = {2020-02-25},
	journal = {Science},
	author = {Goroff, D. L.},
	month = jan,
	year = {2015},
	keywords = {primary, value of privacy, Paywall},
	pages = {479--480},
	file = {Goroff - 2015 - Balancing privacy versus accuracy in research prot.pdf:/home/vilhuber/Zotero/storage/7HURKGF7/Goroff - 2015 - Balancing privacy versus accuracy in research prot.pdf:application/pdf}
}

@article{fellegi_question_1972,
	title = {On the {Question} of {Statistical} {Confidentiality}},
	volume = {67},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2284695},
	doi = {10.2307/2284695},
	abstract = {In Section 1 the nature of statistical confidentiality is explored, i.e., its essential role in the collection of data by statistical offices, its relationship to privacy and the need for increased attention to potential statistical disclosures because of the increased tabulation and dissemination capabilities of statistical offices. In Section 2 a definition of inadvertent direct disclosure is provided as well as a theorem concerning a test for residual disclosure of tabulations. In Section 3 different media and methods of data dissemination are considered from the point of view of potential for statistical disclosure.},
	number = {337},
	urldate = {2020-02-25},
	journal = {Journal of the American Statistical Association},
	author = {Fellegi, I. P.},
	year = {1972},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	keywords = {primary, SDL, Paywall, statistical disclosure limiation},
	pages = {7--18},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/NJHZHNN6/Fellegi - 1972 - On the Question of Statistical Confidentiality.pdf:application/pdf}
}

@article{duchi_local_2013-1,
	title = {Local {Privacy} and {Minimax} {Bounds}: {Sharp} {Rates} for {Probability} {Estimation}},
	shorttitle = {Local {Privacy} and {Minimax} {Bounds}},
	url = {http://arxiv.org/abs/1305.6000},
	abstract = {We provide a detailed study of the estimation of probability distributions---discrete and continuous---in a stringent setting in which data is kept private even from the statistician. We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental tradeoffs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efficiency continuum. One of the consequences of our results is that Warner's classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents.},
	urldate = {2020-02-25},
	journal = {arXiv:1305.6000 [cs, math, stat]},
	author = {Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
	month = may,
	year = {2013},
	note = {arXiv: 1305.6000},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Information Theory, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/ILRY8BSQ/Duchi et al. - 2013 - Local Privacy and Minimax Bounds Sharp Rates for .pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/YVER59C5/1305.html:text/html}
}

@article{gupta_iterative_2011,
	title = {Iterative {Constructions} and {Private} {Data} {Release}},
	url = {http://arxiv.org/abs/1107.3731},
	abstract = {In this paper we study the problem of approximately releasing the cut function of a graph while preserving differential privacy, and give new algorithms (and new analyses of existing algorithms) in both the interactive and non-interactive settings. Our algorithms in the interactive setting are achieved by revisiting the problem of releasing differentially private, approximate answers to a large number of queries on a database. We show that several algorithms for this problem fall into the same basic framework, and are based on the existence of objects which we call iterative database construction algorithms. We give a new generic framework in which new (efficient) IDC algorithms give rise to new (efficient) interactive private query release mechanisms. Our modular analysis simplifies and tightens the analysis of previous algorithms, leading to improved bounds. We then give a new IDC algorithm (and therefore a new private, interactive query release mechanism) based on the Frieze/Kannan low-rank matrix decomposition. This new release mechanism gives an improvement on prior work in a range of parameters where the size of the database is comparable to the size of the data universe (such as releasing all cut queries on dense graphs). We also give a non-interactive algorithm for efficiently releasing private synthetic data for graph cuts with error O({\textbar}V{\textbar}{\textasciicircum}\{1.5\}). Our algorithm is based on randomized response and a non-private implementation of the SDP-based, constant-factor approximation algorithm for cut-norm due to Alon and Naor. Finally, we give a reduction based on the IDC framework showing that an efficient, private algorithm for computing sufficiently accurate rank-1 matrix approximations would lead to an improved efficient algorithm for releasing private synthetic data for graph cuts. We leave finding such an algorithm as our main open problem.},
	urldate = {2020-02-25},
	journal = {arXiv:1107.3731 [cs]},
	author = {Gupta, Anupam and Roth, Aaron and Ullman, Jonathan},
	month = jul,
	year = {2011},
	note = {arXiv: 1107.3731},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/KZLDR8XJ/Gupta et al. - 2011 - Iterative Constructions and Private Data Release.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/GTCGCWG9/1107.html:text/html}
}

@article{he_blowfish_2014,
	title = {Blowfish {Privacy}: {Tuning} {Privacy}-{Utility} {Trade}-offs using {Policies}},
	shorttitle = {Blowfish {Privacy}},
	url = {http://arxiv.org/abs/1312.3913},
	doi = {10.1145/2588555.2588581},
	abstract = {Privacy definitions provide ways for trading-off the privacy of individuals in a statistical database for the utility of downstream analysis of the data. In this paper, we present Blowfish, a class of privacy definitions inspired by the Pufferfish framework, that provides a rich interface for this trade-off. In particular, we allow data publishers to extend differential privacy using a policy, which specifies (a) secrets, or information that must be kept secret, and (b) constraints that may be known about the data. While the secret specification allows increased utility by lessening protection for certain individual properties, the constraint specification provides added protection against an adversary who knows correlations in the data (arising from constraints). We formalize policies and present novel algorithms that can handle general specifications of sensitive information and certain count constraints. We show that there are reasonable policies under which our privacy mechanisms for k-means clustering, histograms and range queries introduce significantly lesser noise than their differentially private counterparts. We quantify the privacy-utility trade-offs for various policies analytically and empirically on real datasets.},
	urldate = {2020-02-25},
	journal = {Proceedings of the 2014 ACM SIGMOD international conference on Management of data - SIGMOD '14},
	author = {He, Xi and Machanavajjhala, Ashwin and Ding, Bolin},
	year = {2014},
	note = {arXiv: 1312.3913},
	keywords = {Computer Science - Databases},
	pages = {1447--1458},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/HPSKVW5F/He et al. - 2014 - Blowfish Privacy Tuning Privacy-Utility Trade-off.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/A3BRJ3CR/1312.html:text/html}
}

@article{li_theory_2013,
	title = {A {Theory} of {Pricing} {Private} {Data}},
	url = {http://arxiv.org/abs/1208.5258},
	doi = {10.1145/2448496.2448502},
	abstract = {Personal data has value to both its owner and to institutions who would like to analyze it. Privacy mechanisms protect the owner's data while releasing to analysts noisy versions of aggregate query results. But such strict protections of individual's data have not yet found wide use in practice. Instead, Internet companies, for example, commonly provide free services in return for valuable sensitive information from users, which they exploit and sometimes sell to third parties. As the awareness of the value of the personal data increases, so has the drive to compensate the end user for her private information. The idea of monetizing private data can improve over the narrower view of hiding private data, since it empowers individuals to control their data through financial means. In this paper we propose a theoretical framework for assigning prices to noisy query answers, as a function of their accuracy, and for dividing the price amongst data owners who deserve compensation for their loss of privacy. Our framework adopts and extends key principles from both differential privacy and query pricing in data markets. We identify essential properties of the price function and micro-payments, and characterize valid solutions.},
	urldate = {2020-02-25},
	journal = {Proceedings of the 16th International Conference on Database Theory - ICDT '13},
	author = {Li, Chao and Li, Daniel Yang and Miklau, Gerome and Suciu, Dan},
	year = {2013},
	note = {arXiv: 1208.5258},
	keywords = {Computer Science - Databases, Computer Science - Cryptography and Security},
	pages = {33},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/8CDU5ZAL/Li et al. - 2013 - A Theory of Pricing Private Data.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/8WGXHN8R/1208.html:text/html}
}

@article{nissim_redrawing_2014,
	title = {Redrawing the {Boundaries} on {Purchasing} {Data} from {Privacy}-sensitive {Individuals}},
	url = {http://arxiv.org/abs/1401.4092},
	doi = {10.1145/2554797.2554835},
	abstract = {We prove new positive and negative results concerning the existence of truthful and individually rational mechanisms for purchasing private data from individuals with unbounded and sensitive privacy preferences. We strengthen the impossibility results of Ghosh and Roth (EC 2011) by extending it to a much wider class of privacy valuations. In particular, these include privacy valuations that are based on (\{\${\textbackslash}backslash\$epsilon\}, \{\${\textbackslash}backslash\$delta\})-differentially private mechanisms for non-zero \{\${\textbackslash}backslash\$delta\}, ones where the privacy costs are measured in a per-database manner (rather than taking the worst case), and ones that do not depend on the payments made to players (which might not be observable to an adversary). To bypass this impossibility result, we study a natural special setting where individuals have mono- tonic privacy valuations, which captures common contexts where certain values for private data are expected to lead to higher valuations for privacy (e.g. having a particular disease). We give new mech- anisms that are individually rational for all players with monotonic privacy valuations, truthful for all players whose privacy valuations are not too large, and accurate if there are not too many players with too-large privacy valuations. We also prove matching lower bounds showing that in some respects our mechanism cannot be improved significantly.},
	journal = {Proceedings of the 5th Conference on Innovations in Theoretical Computer Science},
	author = {Nissim, Kobbi and Vadhan, Salil and Xiao, David},
	year = {2014},
	keywords = {primary, differential privacy, value of privacy, Paywall, Computer Science - Computer Science and Game Theory, mechanism design},
	pages = {411--422},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/BG2UZW7E/Nissim et al. - 2014 - Redrawing the Boundaries on Purchasing Data from P.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/BGPENURB/1401.html:text/html}
}

@article{varian_economic_1996,
	title = {Economic aspects of personal privacy},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.1701&rep=rep1&type=pdf},
	abstract = {The advent of low-cost technology for manipulating and communicating information has raised significant concerns about personal privacy. Privacy is a complex issue and can be treated from many perspectives; this whitepaper provides an overview of some of the economic issues surrounding privacy.2 In particular, I first describe the role of privacy in economic transactions and argue that consumers will rationally want certain kinds of information about themselves to be available to producers and want other kinds of information to be secret. I then go on to consider how one might define property rights in private information in ways that allow consumers to retain control over how information about them is used.},
	number = {3},
	journal = {Topics in Regulatory Economics and Policy},
	author = {Varian, Hal},
	year = {1996},
	keywords = {primary, OA, economics of privacy},
	pages = {1--12}
}

@techreport{varian_markets_1998,
	title = {Markets for {Information} {Goods}},
	url = {http://people.ischool.berkeley.edu/ hal/Papers/japan/index.html},
	abstract = {Much has been written about the difficulties that “information” poses for neoclassical economics. How ironic that ICE-information, communication, and entertainment-now comprises the largest sector in the American economy. If information poses problems for economic theory, so much the worse for economic theory: real markets seem to deal with information rather well. This paradox is the central theme of this essay: information, that slippery and strange economic good, is, in fact, handled very well by market institutions. The reason is that real markets are much more creative than those simple competitive markets studied in Econ 1. The fact that real-life markets can handle a good as problematic as is a testament to the flexibility and robustness of market institutions.},
	author = {Varian, Hal R},
	year = {1998},
	keywords = {primary, OA, value of data}
}

@article{taylor_consumer_2004,
	title = {Consumer privacy and the market for customer information},
	volume = {35},
	copyright = {Copyright 2004 RAND Corporation},
	issn = {0741-6261},
	url = {http://www.jstor.org/stable/1593765},
	abstract = {I investigate consumer privacy and the market for customer information in electronic retailing. The value of customer information derives from the ability of Internet firms to identify individual consumers and charge them personalized prices. I study two settings, a confidential regime in which the sale of customer information is not possible, and a disclosure regime in which one firm may compile and sell a customer list to another firm that uses it to price discriminate. Welfare comparisons depend critically on whether consumers anticipate sale of the list and on demand elasticity.},
	language = {English},
	number = {4},
	journal = {The RAND Journal of Economics},
	author = {Taylor, Curtis R.},
	year = {2004},
	keywords = {primary, value of data, Free, data union},
	pages = {631--650}
}

@article{machanavajjhala_l-diversity_2007,
	title = {L-diversity: privacy beyond k-anonymity},
	volume = {1},
	issn = {1556-4681},
	url = {http://doi.acm.org/10.1145/1217299.1217302},
	doi = {10.1145/1217299.1217302},
	abstract = {In this article, we show using two simple attacks that a k-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that k-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called L-diversity that can defend against such attacks. In addition to building a formal foundation for L-diversity, we show in an experimental evaluation that L-diversity is practical and can be implemented efficiently.},
	number = {1},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
	year = {2007},
	keywords = {primary, formal privacy, Data privacy, Paywall, {\textbackslash}l-diversity, k-anonymity, privacy-preserving data publishing}
}

@book{schmutte_proceedings_2017,
	address = {Cornell University},
	series = {Labor {Dynamics} {Institute}},
	title = {Proceedings from the 2016 {NSF}-{Sloan} {Workshop} on {Practical} {Privacy}},
	url = {https://digitalcommons.ilr.cornell.edu/ldi/33/},
	editor = {Schmutte, Ian M. and Vilhuber, Lars},
	month = jan,
	year = {2017},
	keywords = {primary, OA, official statistics}
}

@article{sweeney_achieving_2002,
	title = {Achieving k-anonymity privacy protection using generalization and suppression},
	volume = {10},
	doi = {10.1142/s021848850200165x},
	number = {5},
	journal = {International Journal on Uncertainty, Fuzziness and Knowledge-based Systems},
	author = {Sweeney, L.},
	year = {2002},
	keywords = {primary, formal privacy, Paywall},
	pages = {571--588}
}

@article{stigler_introduction_1980,
	title = {An {Introduction} to {Privacy} in {Economics} and {Politics}},
	volume = {9},
	issn = {0047-2530},
	url = {https://www.jstor.org/stable/724174},
	doi = {10.2307/724174},
	abstract = {The enormous increase in interest in privacy in our society is evident in the public press and in the statute books. In some respects this interest in privacy is paradoxical, for the average citizen has more privacy-more areas of his life in which his behavior is not known by his fellows-than ever before. He lives in a large city, where no one is his keeper; in the small towns of former times privacy was won only by the cleverest people. He works in large organizations, and indeed he (or, more likely, some self-appointed spokesman) laments his alienation. He can shake off most of his past simply by moving-to the South, the West-and no earlier generation except the immigrant waves before World War I was as mobile.},
	number = {4},
	journal = {Journal of Legal Studies},
	author = {Stigler, George J.},
	year = {1980},
	keywords = {primary, Paywall, economics of privacy},
	pages = {623--644},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/4JSV7FCI/Stigler - 1980 - An Introduction to Privacy in Economics and Politi.pdf:application/pdf}
}

@article{spencer_effects_2015,
	title = {Effects of {Census} {Accuracy} on {Apportionment} of {Congress} and {Allocations} of {Federal} {Funds}},
	url = {https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html},
	language = {English (US)},
	journal = {JSM Proceedings, Government Statistics Section},
	author = {Spencer, Bruce David and Seeskin, Zachary H.},
	year = {2015},
	keywords = {primary, OA, value of data},
	pages = {3061--3075}
}

@article{spencer_optimal_1985-1,
	title = {Optimal {Data} {Quality}},
	volume = {80},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1985.10478155},
	doi = {10.1080/01621459.1985.10478155},
	abstract = {Abstract Commonly accepted hypotheses guide practical determination of needed data quality; for example, as the probability that a decision uses data increases, the needed data quality increases, and the more rudimentary the uses of the data, the less data quality is needed. These hypotheses are formally defined and analyzed in some decision-theoretic models. Conditions under which the hypotheses hold and fail are examined. Particular attention is given to determining needed data quality when the users of the data behave nonoptimally.},
	number = {391},
	journal = {Journal of the American Statistical Association},
	author = {Spencer, Bruce D.},
	year = {1985},
	keywords = {primary, Paywall, value of data, data unions},
	pages = {564--573}
}

@article{samuelson_pure_1954,
	title = {The pure theory of public expenditure},
	volume = {37},
	url = {https://www.jstor.org/stable/1925895},
	journal = {Review of Economics and Statistics},
	author = {Samuelson, Paul A.},
	year = {1954},
	keywords = {primary, Free, public goods},
	pages = {387--389}
}

@article{prewitt_why_2011,
	title = {Why {It} {Matters} to {Distinguish} {Between} {Privacy} \& {Confidentiality}},
	volume = {3},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/600},
	doi = {10.29012/jpc.v3i2.600},
	number = {2},
	journal = {Journal of Privacy and Confidentiality},
	author = {Prewitt, Kenneth},
	year = {2011},
	keywords = {primary, OA, official statistics},
	pages = {41--47}
}

@techreport{pomatto_cost_2018,
	title = {The {Cost} of {Information}},
	url = {https://arxiv.org/abs/1812.04211},
	number = {1812.04211},
	institution = {arXiv},
	author = {Pomatto, Luciano and Strack, Philipp and Tamuz, Omer},
	year = {2018},
	keywords = {primary, OA, value of data}
}

@article{perez-truglia_effects_2019,
	title = {The effects of income transparency on well-being: evidence from a natural experiment},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2657808},
	doi = {10.2139/ssrn.2657808},
	journal = {SSRN},
	author = {Perez-Truglia, Ricardo},
	month = feb,
	year = {2019},
	keywords = {primary, OA, value of data}
}

@article{ohm_broken_2010,
	title = {Broken promises of privacy: responding to the surprising failure of anonymization},
	volume = {57},
	url = {https://www.uclalawreview.org/broken-promises-of-privacy-responding-to-the-surprising-failure-of-anonymization-2/},
	journal = {UCLA Law Review},
	author = {Ohm, Paul},
	year = {2010},
	keywords = {primary, OA, economics of privacy},
	pages = {1701}
}

@article{nissim_differential_2018,
	title = {Differential {Privacy}: {A} {Primer} for a {Non}-{Technical} {Audience}},
	url = {https://openscholar.mit.edu/sites/default/files/dept/files/nissim_et_al_-_differential_privacy_primer_for_non-technical_audiences_1.pdf},
	doi = {N/A},
	journal = {Privacy Law Scholars Conference 2017},
	author = {Nissim, Kobbi and Steinke, Thomas and Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and O'Brien, David R. and Vadhan, Salil},
	year = {2018},
	keywords = {background, formal privacy, OA}
}

@inproceedings{nissim_privacy-aware_2012-1,
	address = {New York, NY, USA},
	series = {{EC} '12},
	title = {Privacy-aware mechanism design},
	isbn = {978-1-4503-1415-2},
	url = {http://doi.acm.org/10.1145/2229012.2229073},
	doi = {10.1145/2229012.2229073},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Electronic} {Commerce}},
	publisher = {ACM},
	author = {Nissim, Kobbi and Orlandi, Claudio and Smorodinsky, Rann},
	year = {2012},
	note = {event-place: Valencia, Spain},
	keywords = {primary, formal privacy, differential privacy, Paywall, privacy, mechanism design},
	pages = {774--789}
}

@book{national_academies_of_sciences_engineering_and_medicine_innovations_2017,
	address = {Washington, DC},
	series = {Committee on {National} {Statistics}},
	title = {Innovations in {Federal} {Statistics}: {Combining} {Data} {Sources} {While} {Protecting} {Privacy}},
	isbn = {978-0-309-45428-5},
	url = {https://www.nap.edu/catalog/24652/innovations-in-federal-statistics-combining-data-sources-while-protecting-privacy},
	publisher = {National Academies Press},
	author = {{National Academies of Sciences, Engineering, and Medicine}},
	year = {2017},
	doi = {10.17226/24652},
	keywords = {primary, OA, official statistics}
}

@article{manski_communicating_2015,
	title = {Communicating {Uncertainty} in {Official} {Economic} {Statistics}: {An} {Appraisal} {Fifty} {Years} after {Morgenstern}},
	volume = {53},
	url = {https://www.aeaweb.org/articles?id=10.1257/jel.53.3.631},
	doi = {10.1257/jel.53.3.631},
	number = {3},
	journal = {Journal of Economic Literature},
	author = {Manski, Charles F.},
	year = {2015},
	keywords = {primary, Paywall, official statistics},
	pages = {631--53}
}

@article{li_matrix_2015,
	title = {The matrix mechanism: optimizing linear counting queries under differential privacy},
	volume = {24},
	issn = {0949-877X},
	url = {http://dx.doi.org/10.1007/s00778-015-0398-x},
	doi = {10.1007/s00778-015-0398-x},
	abstract = {Differential privacy is a robust privacy standard that has been successfully applied to a range of data analysis tasks. We describe the matrix mechanism, an algorithm for answering a workload of linear counting queries that adapts the noise distribution to properties of the provided queries. Given a workload, the mechanism uses a different set of queries, called a query strategy, which are answered using a standard Laplace or Gaussian mechanism. Noisy answers to the workload queries are then derived from the noisy answers to the strategy queries. This two-stage process can result in a more complex, correlated noise distribution that preserves differential privacy but increases accuracy. We provide a formal analysis of the error of query answers produced by the mechanism and investigate the problem of computing the optimal query strategy in support of a given workload. We show that this problem can be formulated as a rank-constrained semidefinite program. We analyze two seemingly distinct techniques proposed in the literature, whose similar behavior is explained by viewing them as instances of the matrix mechanism. We also describe an extension of the mechanism in which nonnegativity constraints are included in the derivation process and provide experimental evidence of its efficacy.},
	number = {6},
	journal = {The VLDB Journal},
	author = {Li, Chao and Miklau, Gerome and Hay, Michael and McGregor, Andrew and Rastogi, Vibhor},
	year = {2015},
	keywords = {primary, formal privacy, Paywall},
	pages = {757--781},
	file = {Li et al. - 2015 - The matrix mechanism optimizing linear counting q.pdf:/home/vilhuber/Zotero/storage/EFLZFEVC/Li et al. - 2015 - The matrix mechanism optimizing linear counting q.pdf:application/pdf}
}

@inproceedings{machanavajjhala_privacy_2008,
	title = {Privacy: theory meets practice on the map},
	doi = {10.1109/ICDE.2008.4497436},
	abstract = {In this paper, we propose the first formal privacy analysis of a data anonymization process known as the synthetic data generation, a technique becoming popular in the statistics community. The target application for this work is a mapping program that shows the commuting patterns of the population of the United States. The source data for this application were collected by the U.S. Census Bureau, but due to privacy constraints, they cannot be used directly by the mapping program. Instead, we generate synthetic data that statistically mimic the original data while providing privacy guarantees. We use these synthetic data as a surrogate for the original data. We find that while some existing definitions of privacy are inapplicable to our target application, others are too conservative and render the synthetic data useless since they guard against privacy breaches that are very unlikely. Moreover, the data in our target application is sparse, and none of the existing solutions are tailored to anonymize sparse data. In this paper, we propose solutions to address the above issues.},
	booktitle = {Proceedings of the 2008 {IEEE} 24th {International} {Conference} on {Data} {Engineering}},
	author = {Machanavajjhala, A. and Kifer, D. and Abowd, J. and Gehrke, J. and Vilhuber, L.},
	month = apr,
	year = {2008},
	keywords = {background, primary, data privacy, Data privacy, Paywall, Computer science, Data analysis, data anonymization process, data handling, formal privacy analysis, Law, Legal factors, mapping program, statistical analysis, Statistical analysis, statistical inference, synthetic data generation},
	pages = {277--286}
}

@article{li_theory_2014,
	title = {A {Theory} of {Pricing} {Private} {Data}},
	volume = {39},
	issn = {0362-5915},
	url = {https://dl.acm.org/citation.cfm?doid=2448496.2448502},
	doi = {10.1145/2448496.2448502},
	number = {4},
	journal = {ACM Transactions on Database Systems},
	author = {Li, Chao and Li, Daniel Yang and Miklau, Gerome and Suciu, D A N},
	year = {2014},
	keywords = {primary, differential privacy, value of privacy, Paywall, arbitrage, data pricing},
	pages = {34:1--34:27}
}

@book{harvard_data_privacy_lab_harvard_2018,
	title = {Harvard {Data} {Privacy} {Lab} {Homepage}},
	url = {https://dataprivacylab.org/},
	author = {{Harvard Data Privacy Lab}},
	year = {2018},
	keywords = {background, primary, OA}
}

@techreport{kinney_towards_2011,
	type = {Working {Papers}},
	title = {Towards {Unrestricted} {Public} {Use} {Business} {Microdata}: {The} {Synthetic} {Longitudinal} {Business} {Database}},
	url = {https://ideas.repec.org/p/cen/wpaper/11-04.html},
	abstract = {In most countries, national statistical agencies do not release establishment-level business microdata, because doing so represents too large a risk to establishments{\textbackslash}' confidentiality. One approach with the potential for overcoming these risks is to release synthetic data; that is, the released establishment data are simulated from statistical models designed to mimic the distributions of the underlying real microdata. In this article, we describe an application of this strategy to create a public use file for the Longitudinal Business Database, an annual economic census of establishments in the United States comprising more than 20 million records dating back to 1976. The U.S. Bureau of the Census and the Internal Revenue Service recently approved the release of these synthetic microdata for public use, making the synthetic Longitudinal Business Database the first-ever business microdata set publicly released in the United States. We describe how we created the synthetic data, evaluated analytical validity, and assessed disclosure risk.},
	number = {11-04},
	institution = {Center for Economic Studies, U.S. Census Bureau},
	author = {Kinney, Satkartar K. and Reiter, Jerome P. and Reznek, Arnold P. and Miranda, Javier and Jarmin, Ron S. and Abowd, John M.},
	month = feb,
	year = {2011},
	keywords = {primary, SDL, statistical disclosure limitation, synthetic data, data confidentiality, disclosure limitation, Economic census, OA}
}

@article{kinney_towards_2011-1,
	title = {Towards {Unrestricted} {Public} {Use} {Business} {Microdata}: {The} {Synthetic} {Longitudinal} {Business} {Database}},
	volume = {79},
	issn = {1751-5823},
	url = {http://dx.doi.org/10.1111/j.1751-5823.2011.00153.x},
	doi = {10.1111/j.1751-5823.2011.00153.x},
	abstract = {In most countries, national statistical agencies do not release establishment-level business microdata, because doing so represents too large a risk to establishments' confidentiality. One approach with the potential for overcoming these risks is to release synthetic data; that is, the released establishment data are simulated from statistical models designed to mimic the distributions of the underlying real microdata. In this article, we describe an application of this strategy to create a public use file for the Longitudinal Business Database, an annual economic census of establishments in the United States comprising more than 20 million records dating back to 1976. The U.S. Bureau of the Census and the Internal Revenue Service recently approved the release of these synthetic microdata for public use, making the synthetic Longitudinal Business Database the first-ever business microdata set publicly released in the United States. We describe how we created the synthetic data, evaluated analytical validity, and assessed disclosure risk.},
	number = {3},
	journal = {International Statistical Review},
	author = {Kinney, Satkartar K. and Reiter, Jerome P. and Reznek, Arnold P. and Miranda, Javier and Jarmin, Ron S. and Abowd, John M.},
	year = {2011},
	keywords = {primary, SDL, statistical disclosure limitation, synthetic data, data confidentiality, disclosure limitation, Economic census, Paywall},
	pages = {362--384},
	file = {ces-wp-11-04.pdf:/home/vilhuber/Zotero/storage/TEJ9KWIE/ces-wp-11-04.pdf:application/pdf;JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/DE2S2WHP/Kinney et al. - 2011 - Towards Unrestricted Public Use Business Microdata.pdf:application/pdf}
}

@article{kasiviswanathan_semantics_2014,
	title = {On the '{Semantics}' of {Differential} {Privacy}: {A} {Bayesian} {Formulation}},
	volume = {6},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/634},
	doi = {10.29012/jpc.v6i1.634},
	number = {1},
	journal = {Journal of Privacy and Confidentiality},
	author = {Kasiviswanathan, Shiva P and Smith, Adam},
	year = {2014},
	keywords = {primary, formal privacy, OA},
	pages = {1}
}

@inproceedings{jorgensen_conservative_2015,
	title = {Conservative or liberal? {Personalized} differential privacy},
	url = {https://ieeexplore.ieee.org/document/7113353},
	doi = {10.1109/ICDE.2015.7113353},
	abstract = {Differential privacy is widely accepted as a powerful framework for providing strong, formal privacy guarantees for aggregate data analysis. A limitation of the model is that the same level of privacy protection is afforded for all individuals. However, it is common that the data subjects have quite different expectations regarding the acceptable level of privacy for their data. Consequently, differential privacy may lead to insufficient privacy protection for some users, while over-protecting others. We argue that by accepting that not all users require the same level of privacy, a higher level of utility can often be attained by not providing excess privacy to those who do not want it. We propose a new privacy definition called personalized differential privacy (PDP), a generalization of differential privacy in which users specify a personal privacy requirement for their data. We then introduce several novel mechanisms for achieving PDP. Our primary mechanism is a general one that automatically converts any existing differentially private algorithm into one that satisfies PDP. We also present a more direct approach for achieving PDP, inspired by the well-known exponential mechanism. We demonstrate our framework through extensive experiments on real and synthetic data.},
	booktitle = {Proceedings of the 2015 {IEEE} 31st {International} {Conference} on {Data} {Engineering}},
	author = {Jorgensen, Z. and Yu, T. and Cormode, G.},
	year = {2015},
	keywords = {formal privacy, Privacy, synthetic data, Paywall, aggregate data analysis, data protection, exponential mechanism, formal privacy guarantees, Lead, PDP, personalized differential privacy, primary mechanism, privacy level, privacy protection, real data, utility level},
	pages = {1023--1034}
}

@book{jones_nonconfidential_2017,
	title = {Nonconfidential {Memorandum} on {Census} {Bureau} {Privacy} {Breaches}},
	author = {Jones, Christa},
	month = jun,
	year = {2017},
	doi = {10.5281/zenodo.1208758},
	note = {Published: Memorandum to file},
	keywords = {background, primary, OA}
}

@techreport{jin_artificial_2018,
	type = {Working {Paper}},
	title = {Artificial {Intelligence} and {Consumer} {Privacy}},
	url = {http://www.nber.org/papers/w24253},
	abstract = {Thanks to big data, artificial intelligence (AI) has spurred exciting innovations. In the meantime, AI and big data are reshaping the risk in consumer privacy and data security. In this essay, I first define the nature of the problem and then present a few facts about the ongoing risk. The bulk of the essay describes how the U.S. market copes with the risk in current policy environment. It concludes with key challenges facing researchers and policy makers.},
	number = {24253},
	institution = {National Bureau of Economic Research},
	author = {Jin, Ginger Zhe},
	month = jan,
	year = {2018},
	doi = {10.3386/w24253},
	keywords = {primary, Paywall, economics of privacy},
	file = {Full Text PDF:/home/vilhuber/Zotero/storage/DGGBKLK4/Jin - 2018 - Artificial Intelligence and Consumer Privacy.pdf:application/pdf}
}

@article{hsu_differential_2014,
	title = {Differential {Privacy}: {An} {Economic} {Method} for {Choosing} {Epsilon}},
	issn = {1063-6900},
	url = {http://arxiv.org/abs/1402.3329},
	doi = {10.1109/CSF.2014.35},
	abstract = {Differential privacy is becoming a gold standard for privacy research; it offers a guaranteed bound on loss of privacy due to release of query results, even under worst-case assumptions. The theory of differential privacy is an active research area, and there are now differentially private algorithms for a wide range of interesting problems. However, the question of when differential privacy works in practice has received relatively little attention. In particular, there is still no rigorous method for choosing the key parameter \${\textbackslash}epsilon\$, which controls the crucial tradeoff between the strength of the privacy guarantee and the accuracy of the published results. In this paper, we examine the role that these parameters play in concrete applications, identifying the key questions that must be addressed when choosing specific values. This choice requires balancing the interests of two different parties: the data analyst and the prospective participant, who must decide whether to allow their data to be included in the analysis. We propose a simple model that expresses this balance as formulas over a handful of parameters, and we use our model to choose \${\textbackslash}epsilon\$ on a series of simple statistical studies. We also explore a surprising insight: in some circumstances, a differentially private study can be more accurate than a non-private study for the same cost, under our model. Finally, we discuss the simplifying assumptions in our model and outline a research agenda for possible refinements.},
	journal = {2014 IEEE 27th Computer Security Foundations Symposium},
	author = {Hsu, Justin and Gaboardi, Marco and Haeberlen, Andreas and Khanna, Sanjeev and Narayan, Arjun and Pierce, Benjamin C. and Roth, Aaron},
	month = jul,
	year = {2014},
	keywords = {primary, data privacy, Data privacy, differential privacy, Privacy, Paywall, economics of privacy, Computer Science - Databases, Accuracy, Analytical models, Cost function, data analysis, data analyst, Data models, Databases, Differential Privacy, differentially private algorithms, economic method, Epsilon, privacy guarantee},
	pages = {398--410},
	file = {arXiv Fulltext PDF:/home/vilhuber/Zotero/storage/HXJ5P3W3/Hsu et al. - 2014 - Differential Privacy An Economic Method for Choos.pdf:application/pdf;arXiv.org Snapshot:/home/vilhuber/Zotero/storage/43PBZ9VY/1402.html:text/html}
}

@article{holan_bayesian_2010,
	title = {Bayesian {Multiscale} {Multiple} {Imputation} {With} {Implications} for {Data} {Confidentiality}},
	volume = {105},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2009.ap08629},
	doi = {Paywall, 10.1198/jasa.2009.ap08629},
	abstract = {Many scientific, sociological, and economic applications present data that are collected on multiple scales of resolution. One particular form of multiscale data arises when data are aggregated across different scales both longitudinally and by economic sector. Frequently, such datasets experience missing observations in a manner that they can be accurately imputed, while respecting the constraints imposed by the multiscale nature of the data, using the method we propose known as Bayesian multiscale multiple imputation. Our approach couples dynamic linear models with a novel imputation step based on singular normal distribution theory. Although our method is of independent interest, one important implication of such methodology is its potential effect on confidential databases protected by means of cell suppression. In order to demonstrate the proposed methodology and to assess the effectiveness of disclosure practices in longitudinal databases, we conduct a large-scale empirical study using the U.S. Bureau of Labor Statistics Quarterly Census of Employment and Wages (QCEW). During the course of our empirical investigation it is determined that several of the predicted cells are within 1\% accuracy, thus causing potential concerns for data confidentiality.},
	number = {490},
	journal = {Journal of the American Statistical Association},
	author = {Holan, Scott H. and Toth, Daniell and Ferreira, Marco A. R. and Karr, Alan F.},
	year = {2010},
	keywords = {primary, official statistics, cell suppression, disclosure, dynamic linear models, missing data, multiscale modeling, qcew},
	pages = {564--577}
}

@article{hirshleifer_privacy_1980,
	title = {Privacy: its origin, function, and future},
	volume = {9},
	url = {https://www.jstor.org/stable/724176},
	doi = {10.1086/467659},
	number = {4},
	journal = {The Journal of Legal Studies},
	author = {Hirshleifer, Jack},
	year = {1980},
	keywords = {primary, Paywall, economics of privacy},
	pages = {649--664},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/59IXYYZL/Hirshleifer - 1980 - Privacy Its Origin, Function, and Future.pdf:application/pdf}
}

@article{heffetz_privacy_2014,
	title = {Privacy and {Data}-{Based} {Research}},
	volume = {28},
	url = {https://www.jstor.org/stable/23723485},
	doi = {10.1257/jep.28.2.75},
	number = {2},
	journal = {Journal of Economic Perspectives},
	author = {Heffetz, Ori and Ligett, Katrina},
	year = {2014},
	keywords = {background, primary, Paywall},
	pages = {75--98},
	file = {JSTOR Full Text PDF:/home/vilhuber/Zotero/storage/THETLP7P/Heffetz and Ligett - 2014 - Privacy and Data-Based Research.pdf:application/pdf}
}

@inproceedings{gupta_iterative_2012,
	address = {Berlin, Heidelberg},
	series = {{TCC}'12},
	title = {Iterative constructions and private data release},
	isbn = {978-3-642-28913-2},
	url = {https://link.springer.com/chapter/10.1007%2F978-3-642-28914-9_19},
	doi = {10.1007/978-3-642-28914-9_19},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Theory} of {Cryptography}},
	publisher = {Springer-Verlag},
	author = {Gupta, Anupam and Roth, Aaron and Ullman, Jonathan},
	year = {2012},
	note = {event-place: Sicily, Italy},
	keywords = {primary, formal privacy, Paywall},
	pages = {339--356}
}

@incollection{he_blowfish_2014-1,
	title = {Blowfish privacy: tuning privacy-utility trade-offs using policies},
	isbn = {978-1-4503-2376-5},
	url = {https://dl.acm.org/citation.cfm?doid=2588555.2588581},
	booktitle = {Proceedings of the 2014 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {He, Xi and Machanavajjhala, Ashwin and Ding, Bolin},
	year = {2014},
	doi = {10.1145/2588555.2588581},
	keywords = {primary, formal privacy, Privacy, Differential privacy, Paywall, Blowfish privacy},
	pages = {1447--1458}
}

@techreport{harris-kojetin_statistical_2005,
	type = {Research {Report}},
	title = {Statistical {Policy} {Working} {Paper} 22: {Report} on {Statistical} {Disclosure} {Limitation} {Methodology}},
	url = {https://nces.ed.gov/FCSM/pdf/spwp22.pdf},
	institution = {U.S. Federal Committee on Statistical Methodology},
	author = {Harris-Kojetin, Brian A. and Alvey, Wendy L. and Carlson, Lynda and Cohen, Steven B. and Cohen, Steve H. and Cox, Lawrence H. and Fay, Robert E. and Fecso, Ronald and Fixler, Dennis and Gates, Gerald and Graubard, Barry and Iwig, William and Kennickell, Arthur and Kirkendall, Nancy J. and Schechter, Susan and Schmitt, Rolf R. and Seastrom, Marilyn and Sirken, Monroe G. and Spruill, Nancy L. and Tucker, Clyde and Tupek, Alan R. and Williamson, G. David and Groves, Robert},
	year = {2005},
	keywords = {primary, SDL, statistical disclosure limitation, OA}
}

@article{hardt_multiplicative_2010,
	title = {A {Multiplicative} {Weights} {Mechanism} for {Privacy}-{Preserving} {Data} {Analysis}},
	issn = {0272-5428},
	url = {https://ieeexplore.ieee.org/document/5670948},
	doi = {10.1109/FOCS.2010.85},
	abstract = {We consider statistical data analysis in the interactive setting. In this setting a trusted curator maintains a database of sensitive information about individual participants, and releases privacy-preserving answers to queries as they arrive. Our primary contribution is a new differentially private multiplicative weights mechanism for answering a large number of interactive counting (or linear) queries that arrive online and may be adaptively chosen. This is the first mechanism with worst-case accuracy guarantees that can answer large numbers of interactive queries and is efficient (in terms of the runtime's dependence on the data universe size). The error is asymptotically optimal in its dependence on the number of participants, and depends only logarithmically on the number of queries being answered. The running time is nearly linear in the size of the data universe. As a further contribution, when we relax the utility requirement and require accuracy only for databases drawn from a rich class of databases, we obtain exponential improvements in running time. Even in this relaxed setting we continue to guarantee privacy for any input database. Only the utility requirement is relaxed. Specifically, we show that when the input database is drawn from a smooth distribution - a distribution that does not place too much weight on any single data item - accuracy remains as above, and the running time becomes poly-logarithmic in the data universe size. The main technical contributions are the application of multiplicative weights techniques to the differential privacy setting, a new privacy analysis for the interactive setting, and a technique for reducing data dimensionality for databases drawn from smooth distributions.},
	journal = {2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
	author = {Hardt, Moritz and Rothblum, Guy N.},
	year = {2010},
	keywords = {primary, formal privacy, Paywall, data dimensionality reduction, data universe, differ},
	pages = {61--70}
}

@incollection{hardt_simple_2012,
	title = {A {Simple} and {Practical} {Algorithm} for {Differentially} {Private} {Data} {Release}.},
	url = {http://papers.nips.cc/paper/4548-a-simple-and-practical-algorithm-for-differentially-private-data-release.pdf},
	abstract = {We present new theoretical results on differentially private data release useful with respect to any target class of counting queries, coupled with experimental results on a variety of real world data sets. Specifically, we study a simple combination of the multiplicative weights approach of [Hardt and Rothblum, 2010] with the exponential mechanism of [McSherry and Talwar, 2007]. The multiplicative weights framework allows us to maintain and improve a distribution approximating a given data set with respect to a set of counting queries. We use the exponential mechanism to select those queries most incorrectly tracked by the current distribution. Combing the two, we quickly approach a distribution that agrees with the data set on the given set of queries up to small error. The resulting algorithm and its analysis is simple, but nevertheless improves upon previous work in terms of both error and running time. We also empirically demonstrate the practicality of our approach on several data sets commonly used in the statistical community for contingency table release.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	author = {Hardt, Moritz and Ligett, Katrina and McSherry, Frank},
	year = {2012},
	keywords = {primary, formal privacy, OA},
	pages = {2339--2347}
}

@incollection{haney_utility_2017-1,
	series = {{SIGMOD} '17},
	title = {Utility {Cost} of {Formal} {Privacy} for {Releasing} {National} {Employer}-{Employee} {Statistics}},
	url = {http://dx.doi.org/10.1145/3035918.3035940},
	abstract = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures. In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter \${\textbackslash}epsilon{\textbackslash}geq\$ 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
	booktitle = {Proceedings of the 2017 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Haney, Samuel and Machanavajjhala, Ashwin and Abowd, John M. and Graham, Matthew and Kutzbach, Mark and Vilhuber, Lars},
	year = {2017},
	doi = {10.1145/3035918.3035940},
	keywords = {primary, Paywall, official statistics}
}

@inproceedings{ghosh_universally_2009-1,
	address = {New York, NY, USA},
	series = {{STOC} '09},
	title = {Universally {Utility}-maximizing {Privacy} {Mechanisms}},
	isbn = {978-1-60558-506-2},
	url = {http://doi.acm.org/10.1145/1536414.1536464},
	doi = {10.1145/1536414.1536464},
	booktitle = {Proceedings of the {Forty}-first {Annual} {ACM} {Symposium} on {Theory} of {Computing}},
	publisher = {ACM},
	author = {Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
	year = {2009},
	note = {event-place: Bethesda, MD, USA},
	keywords = {primary, differential privacy, Paywall, privacy, linear programming, utility},
	pages = {351--360}
}

@article{ghosh_selling_2015,
	title = {Selling privacy at auction},
	volume = {91},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825613000961},
	doi = {10.1016/j.geb.2013.06.013},
	journal = {Games and Economic Behavior},
	author = {Ghosh, Arpita and Roth, Aaron},
	year = {2015},
	keywords = {primary, value of privacy, Paywall},
	pages = {334--346}
}

@techreport{garfinkel_-identification_2015,
	type = {Internal {Report}},
	title = {De-{Identification} of {Personal} {Information}},
	url = {http://costic1206.uvigo.es/sites/default/files/Documents_of_Interest/NISTIR%208053.pdf},
	number = {8053},
	institution = {National Institute of Standards and Technology},
	author = {Garfinkel, Simson},
	year = {2015},
	doi = {10.6028/nist.ir.8053},
	keywords = {primary, SDL, statistical disclosure limitation, OA}
}

@misc{nist_information_technology_laboratory_glossary_nodate,
	title = {Glossary of {Computer} {Security} {Terms}},
	url = {https://csrc.nist.gov/glossary},
	urldate = {2020-03-19},
	author = {{NIST Information Technology Laboratory}},
	file = {Glossary | CSRC:/home/vilhuber/Zotero/storage/2YD6NIG2/glossary.html:text/html}
}

@misc{oecd_oecd_nodate,
	title = {The {OECD} {Glossary} of {Statistical} {Terms}},
	url = {https://stats.oecd.org/glossary/},
	urldate = {2020-03-19},
	author = {{OECD}},
	file = {The OECD Glossary of Statistical Terms:/home/vilhuber/Zotero/storage/D78DIZZW/glossary.html:text/html}
}

@misc{iso_iso_nodate,
	title = {{ISO} 25237:2017: {Health} informatics - {Pseudonymization}},
	shorttitle = {{ISO} 25237:2017(en)},
	url = {https://www.iso.org/standard/63553.html},
	abstract = {Health informatics — Pseudonymization},
	language = {en},
	urldate = {2020-03-19},
	journal = {ISO},
	author = {{ISO}},
	file = {Snapshot:/home/vilhuber/Zotero/storage/DMKQGWXM/63553.html:text/html}
}

@article{cohen_towards_2020,
	title = {Towards formalizing the {GDPR}’s notion of singling out},
	volume = {117},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7165454/},
	doi = {10.1073/pnas.1914598117},
	abstract = {This article addresses a gap between legal and technical conceptions of data privacy and demonstrates how it can be minimized. The article focuses on “singling out,” which is a concept appearing in the GDPR. Our analysis draws on the legislation, regulatory guidance, and mathematical reasoning to derive a technical concept—“predicate singling out”—aimed at capturing a core part of GDPR’s intent. Examination of predicate singling out sheds light on the concept of singling out and the question of whether existing technologies protect against such a threat. Conceptually, this work demonstrates the role that principled analysis supported by mathematical argument can and should play in articulating and informing public policy at the interface between law and technology., There is a significant conceptual gap between legal and mathematical thinking around data privacy. The effect is uncertainty as to which technical offerings meet legal standards. This uncertainty is exacerbated by a litany of successful privacy attacks demonstrating that traditional statistical disclosure limitation techniques often fall short of the privacy envisioned by regulators. We define “predicate singling out,” a type of privacy attack intended to capture the concept of singling out appearing in the General Data Protection Regulation (GDPR). An adversary predicate singles out a dataset x using the output of a data-release mechanism M(x) if it finds a predicate p matching exactly one row in x with probability much better than a statistical baseline. A data-release mechanism that precludes such attacks is “secure against predicate singling out” (PSO secure). We argue that PSO security is a mathematical concept with legal consequences. Any data-release mechanism that purports to “render anonymous” personal data under the GDPR must prevent singling out and, hence, must be PSO secure. We analyze the properties of PSO security, showing that it fails to compose. Namely, a combination of more than logarithmically many exact counts, each individually PSO secure, facilitates predicate singling out. Finally, we ask whether differential privacy and k-anonymity are PSO secure. Leveraging a connection to statistical generalization, we show that differential privacy implies PSO security. However, and in contrast with current legal guidance, k-anonymity does not: There exists a simple predicate singling out attack under mild assumptions on the k-anonymizer and the data distribution.},
	number = {15},
	urldate = {2020-06-02},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Cohen, Aloni and Nissim, Kobbi},
	month = apr,
	year = {2020},
	pmid = {32234789},
	pmcid = {PMC7165454},
	pages = {8344--8352},
	file = {Cohen_Nissim_2020_Towards formalizing the GDPR’s notion of singling out.pdf:/home/vilhuber/Zotero/storage/5FXL3323/Cohen_Nissim_2020_Towards formalizing the GDPR’s notion of singling out.pdf:application/pdf}
}

@article{nissim_is_2018,
	title = {Is privacy privacy?},
	volume = {376},
	issn = {1364-503X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107540/},
	doi = {10.1098/rsta.2017.0358},
	abstract = {This position paper observes how different technical and normative conceptions of privacy have evolved in parallel and describes the practical challenges that these divergent approaches pose. Notably, past technologies relied on intuitive, heuristic understandings of privacy that have since been shown not to satisfy expectations for privacy protection. With computations ubiquitously integrated in almost every aspect of our lives, it is increasingly important to ensure that privacy technologies provide protection that is in line with relevant social norms and normative expectations. Similarly, it is also important to examine social norms and normative expectations with respect to the evolving scientific study of privacy. To this end, we argue for a rigorous analysis of the mapping from normative to technical concepts of privacy and vice versa. We review the landscape of normative and technical definitions of privacy and discuss specific examples of gaps between definitions that are relevant in the context of privacy in statistical computation. We then identify opportunities for overcoming their differences in the design of new approaches to protecting privacy in accordance with both technical and normative standards., This article is part of a discussion meeting issue ‘The growing ubiquity of algorithms in society: implications, impacts and innovations’.},
	number = {2128},
	urldate = {2020-06-02},
	journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
	author = {Nissim, Kobbi and Wood, Alexandra},
	month = sep,
	year = {2018},
	pmid = {30082304},
	pmcid = {PMC6107540},
	keywords = {overview},
	file = {Nissim_Wood_2018_Is privacy privacy.pdf:/home/vilhuber/Zotero/storage/VR4R35BR/Nissim_Wood_2018_Is privacy privacy.pdf:application/pdf}
}

@misc{department_of_health_and_human_services_methods_2012,
	type = {Text},
	title = {Methods for {De}-identification of {PHI}},
	url = {https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html},
	abstract = {Guidance about methods and approaches to achieve de-identification in accordance with the Health Insurance Portability and Accountability Act of 1996.},
	language = {en},
	urldate = {2020-08-26},
	journal = {HHS.gov},
	author = {{Department of Health and Human Services}},
	month = sep,
	year = {2012},
	file = {Snapshot:/home/vilhuber/Zotero/storage/LKKDTY8H/index.html:text/html}
}

@techreport{jia_short-run_2018,
	type = {Working {Paper}},
	title = {The {Short}-{Run} {Effects} of {GDPR} on {Technology} {Venture} {Investment}},
	url = {http://www.nber.org/papers/w25248},
	abstract = {The General Data Protection Regulation (GDPR) came into effect in the European Union in May 2018. We study its short-run impact on investment in new and emerging technology firms. Our findings indicate negative post-GDPR effects on EU ventures, relative to their US counterparts. The negative effects manifest in the overall dollar amounts raised across funding deals, the number of deals, and the dollar amount raised per individual deal.},
	number = {25248},
	institution = {National Bureau of Economic Research},
	author = {Jia, Jian and Jin, Ginger Zhe and Wagman, Liad},
	month = nov,
	year = {2018},
	doi = {10.3386/w25248},
	note = {Series: Working Paper Series},
	keywords = {economics of privacy}
}

@article{hay_boosting_2009,
	title = {Boosting the accuracy of differentially private histograms through consistency},
	volume = {3},
	issn = {2150-8097},
	url = {https://arxiv.org/abs/0904.0942},
	doi = {10.14778/1920841.1920970},
	abstract = {We show that it is possible to significantly improve the accuracy of a general class of histogram queries while satisfying differential privacy. Our approach carefully chooses a set of queries to evaluate, and then exploits consistency constraints that should hold over the noisy output. In a post-processing phase, we compute the consistent input most likely to have produced the noisy output. The final output is differentially-private and consistent, but in addition, it is often much more accurate. We show, both theoretically and experimentally, that these techniques can be used for estimating the degree sequence of a graph very precisely, and for computing a histogram that can support arbitrary range queries accurately.},
	number = {1},
	journal = {Proceedings of the VLDB Endowment},
	author = {Hay, Michael and Rastogi, Vibhor and Miklau, Gerome and Suciu, Dan},
	year = {2009},
	note = {Publisher: VLDB Endowment
\_eprint: arXiv:0904.0942v5},
	keywords = {formal privacy},
	pages = {1021--1032}
}

@article{dwork_differential_2006,
	title = {Differential privacy},
	url = {N/A},
	journal = {Proceedings of the International Colloquium on Automata, Languages and Programming (ICALP)},
	author = {Dwork, Cynthia},
	year = {2006},
	keywords = {formal privacy},
	pages = {1--12}
}

@incollection{hall_privacy-preserving_2010,
	title = {Privacy-{Preserving} {Record} {Linkage}},
	isbn = {978-3-642-15838-4},
	booktitle = {Privacy in {Statistical} {Databases}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hall, Roband and Fienberg, Stephen E.},
	editor = {Domingo-Ferrer, Josepand and Magkos, Emmanouil},
	year = {2010},
	doi = {10.1007/978-3-642-15838-4_24},
	keywords = {SDL, statistical disclosure limitation},
	pages = {269--283}
}

@techreport{athey_digital_2017,
	type = {Working {Paper}},
	title = {The {Digital} {Privacy} {Paradox}: {Small} {Money}, {Small} {Costs}, {Small} {Talk}},
	url = {http://www.nber.org/papers/w23488},
	number = {23488},
	institution = {National Bureau of Economic Research},
	author = {Athey, Susan and Catalini, Christian and Tucker, Catherine},
	year = {2017},
	doi = {10.3386/w23488},
	note = {Series: Working Paper Series},
	keywords = {economics of privacy}
}

@article{kairouz_extremal_2016,
	title = {Extremal {Mechanisms} for {Local} {Differential} {Privacy}},
	volume = {17},
	issn = {1532-4435},
	url = {http://papers.nips.cc/paper/5392-extremal-mechanisms-for-local-differential-privacy},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},
	month = jan,
	year = {2016},
	note = {Publisher: JMLR.org},
	keywords = {formal privacy, estimation, statistical inference, f-divergences, hypothesis testing, information theoretic utilities, local differential privacy, mutual information, privacy-preserving machine learning algorithms},
	pages = {492--542}
}

@inproceedings{nikolov_geometry_2013,
	series = {{STOC} '13},
	title = {The {Geometry} of {Differential} {Privacy}: {The} {Sparse} and {Approximate} {Cases}},
	isbn = {978-1-4503-2029-0},
	doi = {10.1145/2488608.2488652},
	booktitle = {Proceedings of the {Forty}-fifth {Annual} {ACM} {Symposium} on {Theory} of {Computing}},
	publisher = {ACM},
	author = {Nikolov, Aleksandar and Talwar, Kunal and Zhang, Li},
	year = {2013},
	keywords = {formal privacy},
	pages = {351--360}
}

@article{spence_monopoly_1975,
	title = {Monopoly, {Quality}, and {Regulation}},
	volume = {6},
	issn = {0361915X},
	url = {http://www.jstor.org/stable/3003237},
	abstract = {This paper deals with market problems that arise when a monopoly sets some aspect of product quality as well as price. It is argued that the market failure is associated with the inability of prices to convey information about the value attached to quality by inframarginal consumers. In the regulatory context, this market problem appears in the form of a difficult informational question for the regulator; what is the average valuation of quality over all the consumers in the market? The paper suggests that rate-of-return regulation may have attractive features when quality is a variable.},
	number = {2},
	journal = {The Bell Journal of Economics},
	author = {Spence, A. Michael},
	year = {1975},
	note = {Publisher: [RAND Corporation, Wiley]},
	keywords = {data unions},
	pages = {417--429}
}

@incollection{odlyzko_privacy_2004,
	address = {Boston, MA},
	title = {Privacy, {Economics}, and {Price} {Discrimination} on the {Internet}},
	isbn = {978-1-4020-8090-6},
	booktitle = {Economics of {Information} {Security}},
	publisher = {Springer US},
	author = {Odlyzko, Andrew},
	editor = {Camp, L. Jean and Lewis, Stephen},
	year = {2004},
	doi = {10.1007/1-4020-8090-5_15},
	keywords = {economics of privacy},
	pages = {187--211}
}

@incollection{alvim_differential_2012,
	address = {Berlin, Heidelberg},
	title = {Differential {Privacy}: {On} the {Trade}-{Off} between {Utility} and {Information} {Leakage}},
	isbn = {978-3-642-29420-4},
	url = {https://doi.org/10.1007/978-3-642-29420-4_3},
	abstract = {Differential privacy is a notion of privacy that has become very popular in the database community. Roughly, the idea is that a randomized query mechanism provides sufficient privacy protection if the ratio between the probabilities that two adjacent datasets give the same answer is bound by e ϵ . In the field of information flow there is a similar concern for controlling information leakage, i.e. limiting the possibility of inferring the secret information from the observables. In recent years, researchers have proposed to quantify the leakage in terms of min-entropy leakage, a concept strictly related to the Bayes risk. In this paper, we show how to model the query system in terms of an information-theoretic channel, and we compare the notion of differential privacy with that of min-entropy leakage. We show that differential privacy implies a bound on the min-entropy leakage, but not vice-versa. Furthermore, we show that our bound is tight. Then, we consider the utility of the randomization mechanism, which represents how close the randomized answers are to the real ones, in average. We show that the notion of differential privacy implies a bound on utility, also tight, and we propose a method that under certain conditions builds an optimal randomization mechanism, i.e. a mechanism which provides the best utility while guaranteeing ϵ-differential privacy.},
	booktitle = {Formal {Aspects} of {Security} and {Trust}: 8th {International} {Workshop}, {FAST} 2011, {Leuven}, {Belgium}, {September} 12-14, 2011. {Revised} {Selected} {Papers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Alvim, Mário S. and Andrés, Miguel E. and Chatzikokolakis, Konstantinos and Degano, Pierpaolo and Palamidessi, Catuscia},
	editor = {Barthe, Gilles and Datta, Anupam and Etalle, Sandro},
	year = {2012},
	doi = {10.1007/978-3-642-29420-4_3},
	keywords = {Formal Privacy},
	pages = {39--54}
}

@article{waldman_how_2000,
	title = {How {Congress} {Does} the {Difficult}},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420919},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Waldman, Sidney},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	pages = {803--808}
}

@article{brunell_making_2000,
	title = {Making {Sense} of the {Census}: {It}'s {Political}},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420918},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Brunell, Thomas L.},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {official statistics},
	pages = {801--802}
}

@article{chen_truthful_2016,
	title = {Truthful {Mechanisms} for {Agents} {That} {Value} {Privacy}},
	volume = {4},
	issn = {2167-8375},
	url = {http://doi.acm.org/10.1145/2892555},
	doi = {10.1145/2892555},
	number = {3},
	journal = {ACM Trans. Econ. Comput.},
	author = {Chen, Yiling and Chong, Stephen and Kash, Ian A. and Moran, Tal and Vadhan, Salil},
	year = {2016},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {formal privacy, Differential privacy, mechanism design, social choice, truthfulness, VCG},
	pages = {13:1--13:30}
}

@inproceedings{xiao_is_2013,
	address = {New York, NY, USA},
	series = {{ITCS} '13},
	title = {Is {Privacy} {Compatible} with {Truthfulness}?},
	isbn = {978-1-4503-1859-4},
	url = {http://doi.acm.org/10.1145/2422436.2422448},
	doi = {10.1145/2422436.2422448},
	booktitle = {Proceedings of the 4th {Conference} on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {ACM},
	author = {Xiao, David},
	year = {2013},
	note = {event-place: Berkeley, California, USA},
	keywords = {differential privacy, economics of privacy, mechanism design},
	pages = {67--86}
}

@article{bassily_practical_2017,
	title = {Practical {Locally} {Private} {Heavy} {Hitters}},
	volume = {abs/1707.04982},
	url = {http://arxiv.org/abs/1707.04982},
	journal = {CoRR},
	author = {Bassily, Raef and Nissim, Kobbi and Stemmer, Uri and Thakurta, Abhradeep},
	year = {2017},
	keywords = {Formal Privacy}
}

@techreport{benjamin_biased_2017,
	type = {Working {Paper}},
	title = {Biased {Beliefs} {About} {Random} {Samples}: {Evidence} from {Two} {Integrated} {Experiments}},
	url = {http://www.nber.org/papers/w23927},
	abstract = {This paper describes results of a pair of incentivized experiments on biases in judgments about random samples. Consistent with the Law of Small Numbers (LSN), participants exaggerated the likelihood that short sequences and random subsets of coin flips would be balanced between heads and tails. Consistent with the Non-Belief in the Law of Large Numbers (NBLLN), participants underestimated the likelihood that large samples would be close to 50\% heads. However, we identify some shortcomings of existing models of LSN, and we find that NBLLN may not be as stable as previous studies suggest. We also find evidence for exact representativeness (ER), whereby people tend to exaggerate the likelihood that samples will (nearly) exactly mirror the underlying odds, as an additional bias beyond LSN. Our within-subject design of asking many different questions about the same data lets us disentangle the biases from possible rational alternative interpretations by showing that the biases lead to inconsistency in answers. Our design also centers on identifying and controlling for bin effects, whereby the probability assigned to outcomes systematically depends on the categories used to elicit beliefs in a way predicted by support theory. The bin effects are large and systematic and affect some results, but we find LSN, NBLLN, and ER even after controlling for them.},
	number = {23927},
	institution = {National Bureau of Economic Research},
	author = {Benjamin, Daniel J. and Moore, Don A. and Rabin, Matthew},
	year = {2017},
	doi = {10.3386/w23927}
}

@article{anderson_history_2000,
	title = {History, {Myth} {Making}, and {Statistics}: {A} {Short} {Story} about the {Reapportionment} of {Congress} and the 1990 {Census}},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420915},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Anderson, Margo and Fienberg, Stephen E.},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {Official Statistics},
	pages = {783--792}
}

@article{billard_census_2000,
	title = {The {Census} {Count}: {Who} {Counts}? {How} {Do} {We} {Count}? {When} {Do} {We} {Count}?},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420913},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Billard, Lynne},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {official statistics},
	pages = {767--774}
}

@article{anderson_partisan_2000,
	title = {Partisan {Politics} at {Work}: {Sampling} and the 2000 {Census}},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420917},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Anderson, Margo and Fienberg, Stephen E.},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {Official Statistics},
	pages = {795--799}
}

@article{brunell_rejoinder_2000,
	title = {Rejoinder to {Anderson} and {Fienberg}},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420916},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Brunell, Thomas L.},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {official statistics},
	pages = {793--794}
}

@article{brunell_using_2000,
	title = {Using {Statistical} {Sampling} to {Estimate} the {U}. {S}. {Population}: {The} {Methodological} and {Political} {Debate} over {Census} 2000},
	volume = {33},
	issn = {10490965, 15375935},
	url = {http://www.jstor.org/stable/420914},
	number = {4},
	journal = {PS: Political Science and Politics},
	author = {Brunell, Thomas L.},
	year = {2000},
	note = {Publisher: [American Political Science Association, Cambridge University Press]},
	keywords = {official statistics},
	pages = {775--782}
}

@article{warner_randomized_1965,
	title = {Randomized {Response}: {A} {Survey} {Technique} for {Eliminating} {Evasive} {Answer} {Bias}},
	volume = {60},
	issn = {01621459},
	url = {http://www.jstor.org/stable/2283137},
	abstract = {For various reasons individuals in a sample survey may prefer not to confide to the interviewer the correct answers to certain questions. In such cases the individuals may elect not to reply at all or to reply with incorrect answers. The resulting evasive answer bias is ordinarily difficult to assess. In this paper it is argued that such bias is potentially removable through allowing the interviewee to maintain privacy through the device of randomizing his response. A randomized response method for estimating a population proportion is presented as an example. Unbiased maximum likelihood estimates are obtained and their mean square errors of conventional estimates under various assumptions about the underlying population.},
	number = {309},
	journal = {Journal of the American Statistical Association},
	author = {Warner, Stanley L.},
	year = {1965},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	keywords = {SDL, statistical disclosure limitation},
	pages = {63--69}
}

@techreport{jack_environmental_2017,
	type = {Working {Paper}},
	title = {Environmental externalities and intrahousehold inefficiency},
	institution = {Northwestern University},
	author = {Jack, Kelsey and Jayachandran, Seema and Rao, Sarojini},
	year = {2017}
}

@article{mulry_total_1991,
	title = {Total {Error} in {PES} {Estimates} of {Population}},
	volume = {86},
	abstract = {We describe a methodology for estimating the accuracy of dual systems estimates (DSE's) of population, census estimates of population, and estimates of undercount in the census. The DSE's are based on the census and a post-enumeration survey (PES). We apply the methodology to the 1988 dress rehearsal census of St. Louis and east-central Missouri and we discuss its applicability to the 1990 census and PES. The methodology is based on decompositions of the total (or net) error into components, such as sampling error, matching error, and other nonsampling errors. Limited information about the accuracy of certain components of error, notably failure of assumptions in the "capture-recapture" model, but others as well, lead us to offer tentative estimates of the errors of the census, DSE, and undercount estimates for 1988. Improved estimates are anticipated for 1990.},
	number = {416},
	journal = {Journal of the American Statistical Association},
	author = {Mulry, Mary H. and Spencer, Bruce D.},
	year = {1991},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	keywords = {official statistics},
	pages = {839--855}
}

@article{mulry_accuracy_1993,
	title = {Accuracy of the 1990 {Census} and {Undercount} {Adjustments}},
	volume = {88},
	abstract = {In July 1991 the Census Bureau recommended to its parent agency, the Department of Commerce, that the 1990 census be adjusted for undercount. The Secretary of Commerce decided not to adjust, however. Those decisions relied at least partly on the Census Bureau's analyses of the accuracy of the census and of the proposed undercount adjustments based on the Post-Enumeration Survey (PES). Error distributions for the nation, states, and smaller geographic units were estimated with extensions of methods applied to test censuses. To summarize and assess the relative importance of errors in different units, the Census Bureau used aggregate loss functions. This article describes the total error analysis and loss function analysis of the Census Bureau. In its decision not to adjust the census, the Department of Commerce cited different criteria than aggregate loss functions. Those criteria are identified and discussed.},
	number = {423},
	journal = {Journal of the American Statistical Association},
	author = {Mulry, Mary H. and Spencer, Bruce D.},
	year = {1993},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	keywords = {official statistics},
	pages = {1080--1091}
}

@article{mcsherry_privacy_2009,
	title = {Privacy {Integrated} {Queries}},
	url = {https://www.microsoft.com/en-us/research/publication/privacy-integrated-queries/},
	abstract = {We report on the design and implementation of the Privacy Integrated Queries (PINQ) platform for privacy-preserving data analysis. PINQ provides analysts with a programming interface to unscrubbed data through a SQL-like language. At the same time, the design of PINQ's analysis language and its careful implementation provide formal guarantees of differential privacy for any and all uses of the platform. PINQ's unconditional structural guarantees require no trust placed in the expertise or diligence of the analysts, substantially broadening the scope for design and deployment of privacy-preserving data analysis, especially by non-experts.},
	journal = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data (SIGMOD)},
	author = {McSherry, Frank},
	year = {2009},
	note = {Publisher: Association for Computing Machinery, Inc.},
	keywords = {formal privacy}
}

@article{arrieta-ibarra_should_2018,
	title = {Should {We} {Treat} {Data} as {Labor}? {Moving} beyond "{Free}"},
	volume = {108},
	url = {http://www.aeaweb.org/articles?id=10.1257/pandp.20181003},
	doi = {10.1257/pandp.20181003},
	journal = {AEA Papers and Proceedings},
	author = {Arrieta-Ibarra, Imanol and Goff, Leonard and Jiménez-Hernández, Diego and Lanier, Jaron and Weyl, E. Glen},
	year = {2018},
	keywords = {economics of privacy},
	pages = {38--42}
}

@book{us_census_bureau_restricted-access_2018,
	title = {Restricted-{Access} {Microdata}},
	url = {https://www.census.gov/research/data/restricted_use_microdata.html},
	author = {{U.S. Census Bureau}},
	year = {2018},
	keywords = {policy}
}

@article{differential_privacy_team_learning_2017,
	title = {Learning with {Privacy} at {Scale}},
	volume = {1},
	url = {https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html},
	number = {8},
	journal = {Apple Machine Learning Journal},
	author = {{Differential Privacy Team}},
	year = {2017},
	keywords = {formal privacy}
}

@article{ding_collecting_2017,
	title = {Collecting {Telemetry} {Data} {Privately}},
	url = {https://www.microsoft.com/en-us/research/publication/collecting-telemetry-data-privately/},
	abstract = {The collection and analysis of telemetry data from user’s devices is routinely performed by many software companies. Telemetry collection leads to improved user experience but poses significant risks to users’ privacy. Locally differentially private (LDP) algorithms have recently emerged as the main tool that allows data collectors to estimate various population statistics, while preserving privacy. The guarantees provided by such algorithms are typically very strong for a single round of telemetry collection, but degrade rapidly when telemetry is collected regularly. In particular, existing LDP algorithms are not suitable for repeated collection of counter data such as daily app usage statistics. In this paper, we develop new LDP mechanisms geared towards repeated collection of counter data, with formal privacy guarantees even after being executed for an arbitrarily long period of time. For two basic analytical tasks, mean estimation and histogram estimation, our LDP mechanisms for repeated data collection provide estimates with comparable or even the same accuracy as existing single-round LDP collection mechanisms. We conduct empirical evaluation on real-world counter datasets to verify our theoretical results. Our mechanisms have been deployed by a Fortune 500 company to collect telemetry across millions of devices.},
	journal = {Advances in Neural Information Processing Systems 30},
	author = {Ding, Bolin and Kulkarni, Janardhan and Yekhanin, Sergey},
	year = {2017},
	keywords = {formal privacy}
}

@article{wood_differential_2018,
	title = {Differential {Privacy}: {A} {Primer} for a {Non}-{Technical} {Audience}},
	volume = {21},
	shorttitle = {Differential {Privacy}},
	url = {http://www.jetlaw.org/journal-archives/volume-21/volume-21-issue-1/differential-privacy-a-primer-for-a-non-technical-audience/},
	abstract = {Differential privacy is a formal mathematical framework for quantifying and managing privacy risks. It provides provable privacy protection against a wide range of potential attacks, including those currently unforeseen. Differential privacy is primarily studied in the context of the collection, analysis, and release of aggregate statistics. These range from simple statistical estimations, such as averages, to machine learning. Tools for differentially private analysis are now in early stages of implementation and use across a variety of academic, industry, and government settings. Interest in the concept is growing among potential users of the tools, as well as within legal and policy communities, as it holds promise as a potential approach to satisfying legal requirements for privacy protection when handling personal information. In particular, differential privacy may be seen as a technical solution for analyzing and sharing data while protecting the privacy of individuals in accordance with existing legal or policy requirements for de-identification or disclosure limitation. This primer seeks to introduce the concept of differential privacy and its privacy implications to non-technical audiences. It provides a simplified and informal, but mathematically accurate, description of differential privacy. Using intuitive illustrations and limited mathematical formalism, it discusses the definition of differential privacy, how differential privacy addresses privacy risks, how differentially private analyses are constructed, and how such analyses can be used in practice. A series of illustrations is used to show how practitioners and policymakers can conceptualize the guarantees provided by differential privacy. These illustrations are also used to explain related concepts, such as composition (the accumulation of risk across multiple analyses), privacy loss parameters, and privacy budgets. This primer aims to provide a foundation that can guide future decisions when analyzing and sharing statistical data about individuals, informing individuals about the privacy protection they will be afforded, and designing policies and regulations for robust privacy protection.},
	number = {1},
	urldate = {2019-04-23},
	journal = {Vanderbilt Journal of Entertainment and Technology Law},
	author = {Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and Honaker, James and Nissim, Kobbi and O'Brien, David R. and Steinke, Thomas and Vadhan, Salil},
	year = {2018},
	keywords = {background, primary, formal privacy}
}

@book{eeckhoudt_economic_2005,
	title = {Economic and {Financial} {Decisions} {Under} {Uncertainty}},
	publisher = {Princeton University Press},
	author = {Eeckhoudt, Louis and Gollier, Christian and Schlesinger, Harris},
	year = {2005}
}

@article{kuo_differentially_2018,
	title = {Differentially {Private} {Hierarchical} {Group} {Size} {Estimation}},
	volume = {abs/1804.00370},
	url = {http://arxiv.org/abs/1804.00370},
	doi = {10.14778/3236187.3236202},
	journal = {CoRR},
	author = {Kuo, Yu-Hsuan and Chiu, Cho-Chun and Kifer, Daniel and Hay, Michael and Machanavajjhala, Ashwin},
	year = {2018},
	note = {\_eprint: 1804.00370},
	keywords = {formal privacy}
}

@techreport{burman_synthetic_2017,
	title = {A {SYNTHETIC} {INCOME} {TAX} {RETURN} {DATA} {FILE}: {TENTATIVE} {WORK} {PLAN} {AND} {DISCUSSION} {DRAFT}},
	url = {https://www.taxpolicycenter.org/sites/default/files/publication/142421/2001396-a-synthetic-income-tax-return-data-file-tentative-work-plan_and_discussion_draft.pdf},
	institution = {Tax Policy Center, Urban Institute and Brookings Institution},
	author = {Burman, Leonard E. and Engler, Alex and Khitatrakun, Surachai and Nunns, James R. and Armstrong, Sarah},
	year = {2017}
}

@article{ruggles_frozen_2011,
	title = {Frozen {Film} and {FOSDIC} {Forms}: {Restoring} the 1960 {U}.{S}. {Census} of {Population} and {Housing}},
	volume = {44},
	doi = {10.1080/01615440.2011.561778},
	abstract = {Abstract In this article, the authors describe a collaboration of the Minnesota Population Center (MPC), the U.S. Census Bureau, and the National Archives and Records Administration to restore the lost data from the 1960 Census. The data survived on refrigerated microfilm in a cave in Lenexa, Kansas. The MPC is now converting the data to usable form. Once the restored data are processed, the authors intend to develop three new data sources based on the 1960 census. These data will replace the most inadequate sample in the series of public-use census microdata spanning the years from 1850 to 2000, extend the chronological scope of the public census summary files, and provide a powerful new resource for the Census Bureau and its Research Data Centers.},
	number = {2},
	journal = {Historical Methods: A Journal of Quantitative and Interdisciplinary History},
	author = {Ruggles, Steven and Schroeder, Matthew and Rivers, Natasha and Alexander, J. Trent and Gardner, Todd K.},
	year = {2011},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01615440.2011.561778},
	pages = {69--78}
}

@inproceedings{kifer_towards_2010,
	address = {New York, NY, USA},
	series = {{PODS} '10},
	title = {Towards an {Axiomatization} of {Statistical} {Privacy} and {Utility}},
	isbn = {978-1-4503-0033-9},
	url = {http://doi.acm.org/10.1145/1807085.1807106},
	doi = {10.1145/1807085.1807106},
	booktitle = {Proceedings of the {Twenty}-ninth {ACM} {SIGMOD}-{SIGACT}-{SIGART} {Symposium} on {Principles} of {Database} {Systems}},
	publisher = {ACM},
	author = {Kifer, Daniel and Lin, Bing-Rong},
	year = {2010},
	note = {event-place: Indianapolis, Indiana, USA},
	keywords = {value of privacy, data unions, privacy, utility, axioms},
	pages = {147--158}
}

@book{golub_matrix_1996,
	title = {Matrix {Computations}, {Third} {Edition}},
	publisher = {The Johns Hopkins University Press},
	author = {Golub, Gene H. and Loan, Charles F. Van},
	year = {1996},
	keywords = {reference}
}

@techreport{abowd_session_2016,
	type = {Presentation},
	title = {Session 12: {Statistical} {Tools}: {Methods} of {Confidentiality} {Protection}},
	url = {https://hdl.handle.net/1813/45060},
	abstract = {“Understanding Social and Economic Data” (aka INFO7470) is designed to provide students a detailed overview of the US federal statistical system, where data comes from and how it can be used for research. The course also aims to teach students basic and advanced techniques for acquiring and transforming raw information into social and economic data. The course is taught as a mixture of self-guided online videos (MOOC-style) together with in-classroom discussions of the material. Students from multiple universities, scattered across the country and participating via videoconference, and from multiple domains (economics, demography, geography, statistics) contribute to the discussion.},
	number = {45060},
	institution = {Labor Dynamics Institute, Cornell University},
	author = {Abowd, John M. and Vilhuber, Lars},
	month = apr,
	year = {2016}
}

@techreport{abowd_introductory_2019,
	type = {Document},
	title = {Introductory {Readings} in {Formal} {Privacy} for {Economists}},
	url = {http://doi.org/10.5281/zenodo.2662639},
	abstract = {The purpose of this document is to provide scholars with a comprehensive list of readings relevant to the economic analysis of formal privacy, and particularly its application to public statistics. Statistical agencies and tech giants are rapidly adopting formal privacy models which make the tradeoff between privacy and data quality precise. The question then becomes, how much privacy loss should they allow? Abowd and Schmutte (2019) argue that this choice ultimately depends on how decision makers weigh the costs of privacy loss against the benefits of higher-quality data. Making progress on these questions requires familiarity with new tools from computer science and statistics, the objectives and policy environment within which statistical agencies operate, along with the economic analysis of information. We have organized these references into a reading course focused on 10-15 primary references in each of six different topics: Formal Privacy Policy and Official Statistics Statistical Disclosure Limitation Economics of Privacy Value of Privacy and Data Accuracy},
	language = {eng},
	number = {2662639},
	urldate = {2020-07-17},
	institution = {Labor Dynamics Institute, Cornell University},
	author = {Abowd, John M. and Schmutte, Ian and Sexton, William and Vilhuber, Lars},
	month = may,
	year = {2019},
	doi = {10.5281/zenodo.2662639},
	note = {Publisher: Zenodo},
	keywords = {Economics of Privacy, Statistical Disclosure Limitation, Privacy, Economics, Official Statistics, Differential Privacy},
	file = {Zenodo Snapshot:/home/vilhuber/Zotero/storage/P3SWI8DM/2662639.html:text/html}
}

@techreport{basu_measuring_2020,
	title = {Measuring discrepancies in {Airbnb} guest acceptance rates using anonymized demographic data},
	url = {https://news.airbnb.com/wp-content/uploads/sites/4/2020/06/Project-Lighthouse-Airbnb-2020-06-12.pdf},
	abstract = {privacy model of p-sensitive k-anonymity},
	urldate = {2020-07-07},
	institution = {Airbnb},
	author = {Basu, Sid and Berman, Ruthie and Bloomston, Adam and Campbell, John and Diaz, Anne and Era, Nanako and Evans, Benjamin and Palkar, Sukhada and Wharton, Skyler},
	year = {2020},
	file = {Project-Lighthouse-Airbnb-2020-06-12.pdf:/home/vilhuber/Zotero/storage/X8EI44UQ/Project-Lighthouse-Airbnb-2020-06-12.pdf:application/pdf}
}

@techreport{dula_tabular_2004,
	type = {Research {Report}},
	title = {Tabular {Statistical} {Disclosure} {Control}: {Optimization} {Techniques} in {Suppression} and {Controlled} {Tabular} {Adjustment}},
	url = {https://www.census.gov/srd/papers/pdf/rrs2004-04.pdf},
	abstract = {The problem of disseminating tabular data such that the amount of information provided satisﬁes the public need while protecting individually identiﬁable data is a problem in all governmental statistical agencies. The problem falls into the category of Statistical Disclosure Control and provides many diﬃcult policy and technical challenges for these agencies. In order to achieve the double mission of dissemination and conﬁdentiality protection, the agencies must balance conﬂicting objectives. Traditionally, agencies have relied on selective suppression of sensitive cells. Because of the diﬃculty of suppressing optimally and the problems that may result from publishing tables with omitted cell values, new ideas have been proposed based on selective adjustment of cell values. One such method is Controlled Tabular Adjustment by Cox and Dandekar [2002]. In this paper we discuss the theoretical, computational and practical issues of these two approaches to Statistical Disclosure Control.},
	language = {en},
	number = {2004-04},
	institution = {U.S. Census Bureau},
	author = {Dula, Jose H and Fagan, James T and Massell, Paul B},
	year = {2004},
	pages = {35},
	file = {Dula et al. - Tabular Statistical Disclosure Control Optimizati.pdf:/home/vilhuber/Zotero/storage/QMT7FI4R/Dula et al. - Tabular Statistical Disclosure Control Optimizati.pdf:application/pdf}
}

@book{statistik_der_bundesagentur_fur_arbeit_grundlagen_2018,
	title = {Grundlagen: {Definitionen} - {Statistische} {Geheimhaltung}: {Rechtliche} {Grundlagen} und fachliche {Regelungen} der {Statistik} der {Bundesagentur} für {Arbeit}},
	url = {https://statistik.arbeitsagentur.de/Statischer-Content/Grundlagen/Rechtsgrundlagen/Statistische-Geheimhaltung/Generische-Publikationen/Statistische-Geheimhaltung.pdf},
	author = {{Statistik der Bundesagentur für Arbeit}},
	year = {2018}
}

@article{komarova_identification_2020,
	title = {Identification and {Formal} {Privacy} {Guarantees}},
	url = {http://arxiv.org/abs/2006.14732},
	abstract = {Empirical economic research crucially relies on highly sensitive individual datasets. At the same time, increasing availability of public individual-level data makes it possible for adversaries to potentially de-identify anonymized records in sensitive research datasets. This increasing disclosure risk has incentivised large data curators, most notably the US Census bureau and several large companies including Apple, Facebook and Microsoft to look for algorithmic solutions to provide formal non-disclosure guarantees for their secure data. The most commonly accepted formal data security concept in the Computer Science community is differential privacy. It restricts the interaction of researchers with the data by allowing them to issue queries to the data. The differential privacy mechanism then replaces the actual outcome of the query with a randomised outcome. While differential privacy does provide formal data security guarantees, its impact on the identification of empirical economic models and on the performance of estimators in those models has not been sufficiently studied. Since privacy protection mechanisms are inherently finite-sample procedures, we define the notion of identifiability of the parameter of interest as a property of the limit of experiments. It is linked to the asymptotic behavior in measure of differentially private estimators. We demonstrate that particular instances of regression discontinuity design and average treatment effect may be problematic for inference with differential privacy because their estimators can only be ensured to converge weakly with their asymptotic limit remaining random and, thus, may not be estimated consistently. This result is clearly supported by our simulation evidence. Our analysis suggests that many other estimators that rely on nuisance parameters may have similar properties with the requirement of differential privacy.},
	urldate = {2020-07-04},
	journal = {arXiv:2006.14732 [econ, stat]},
	author = {Komarova, Tatiana and Nekipelov, Denis},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.14732},
	keywords = {Statistics - Methodology, Economics - Econometrics},
	file = {arXiv.org Snapshot:/home/vilhuber/Zotero/storage/VXXVKQAC/2006.html:text/html;Komarova_Nekipelov_2020_Identification and Formal Privacy Guarantees.pdf:/home/vilhuber/Zotero/storage/CS27UUV9/Komarova_Nekipelov_2020_Identification and Formal Privacy Guarantees.pdf:application/pdf}
}

@article{goroff_privacy_2018,
	title = {Privacy {Protective} {Research}: {Facilitating} {Ethically} {Responsible} {Access} to {Administrative} {Data}},
	volume = {675},
	issn = {0002-7162},
	shorttitle = {Privacy {Protective} {Research}},
	url = {https://doi.org/10.1177/0002716217742605},
	doi = {10.1177/0002716217742605},
	abstract = {Companies and government entities collect substantial amounts of administrative data through the Internet; mobile communications; and a vast infrastructure of devices and sensors embedded in healthcare facilities, retail outlets, public transportation, social networks, workplaces, and homes. They use administrative data to test new products and services, improve existing offerings, conduct research, and foster innovation. However, the lack of a clear legal framework and ethical guidelines for use of administrative data jeopardizes the value of important research. Concerns over legal impediments and ethical restrictions threaten to diminish productive collaboration between researchers and private sector businesses. This article provides strategies for organizations to minimize risks of reidentification and privacy violations for individual data subjects. In addition, it suggests that privacy and ethical concerns would best be managed by supporting the development of administrative data centers to lower transaction costs and increase the reproducibility of research conducted on administrative data.},
	language = {en},
	number = {1},
	urldate = {2020-06-24},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	author = {Goroff, Daniel and Polonetsky, Jules and Tene, Omer},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	pages = {46--66},
	file = {Goroff et al_2018_Privacy Protective Research.pdf:/home/vilhuber/Zotero/storage/4GMDTQI8/Goroff et al_2018_Privacy Protective Research.pdf:application/pdf}
}

@techreport{dupriez_dissemination_2010,
	type = {Working {Paper}},
	title = {Dissemination of {Microdata} {Files} - {Principles}, {Procedures} and {Practices}},
	url = {http://ihsn.org/dissemination-of-microdata-files},
	abstract = {In all countries, data producers face growing demand for microdata. Determining the best way to disseminate these data is a challenge. Formal policies and procedures defining the conditions of access to microdata must be formulated. This guide provides an overview of such policies and procedures, and documents existing best practices.},
	number = {005},
	urldate = {2019-11-15},
	institution = {The World Bank},
	author = {Dupriez, Olivier and Boyko, Ernie},
	year = {2010},
	file = {Dissemination of Microdata Files - Principles, Procedures and Practices | IHSN:/home/vilhuber/Zotero/storage/LBV9MC48/dissemination-of-microdata-files.html:text/html}
}

@article{de_montjoye_privacy-conscientious_2018,
	title = {On the privacy-conscientious use of mobile phone data},
	volume = {5},
	copyright = {2018 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata2018286},
	doi = {10.1038/sdata.2018.286},
	abstract = {The breadcrumbs we leave behind when using our mobile phones—who somebody calls, for how long, and from where—contain unprecedented insights about us and our societies. Researchers have compared the recent availability of large-scale behavioral datasets, such as the ones generated by mobile phones, to the invention of the microscope, giving rise to the new field of computational social science.},
	language = {en},
	number = {1},
	urldate = {2020-06-24},
	journal = {Scientific Data},
	author = {de Montjoye, Yves-Alexandre and Gambs, Sébastien and Blondel, Vincent and Canright, Geoffrey and de Cordes, Nicolas and Deletaille, Sébastien and Engø-Monsen, Kenth and Garcia-Herranz, Manuel and Kendall, Jake and Kerry, Cameron and Krings, Gautier and Letouzé, Emmanuel and Luengo-Oroz, Miguel and Oliver, Nuria and Rocher, Luc and Rutherford, Alex and Smoreda, Zbigniew and Steele, Jessica and Wetter, Erik and Pentland, Alex “Sandy” and Bengtsson, Linus},
	month = dec,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {180286},
	file = {de Montjoye et al_2018_On the privacy-conscientious use of mobile phone data.pdf:/home/vilhuber/Zotero/storage/DEIUKRBP/de Montjoye et al_2018_On the privacy-conscientious use of mobile phone data.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/46UH32P3/sdata2018286.html:text/html}
}

@techreport{marini_comparing_2018,
	title = {Comparing privacy laws: {GDPR} v. {CCPA}},
	url = {https://fpf.org/wp-content/uploads/2018/11/GDPR_CCPA_Comparison-Guide.pdf},
	urldate = {2020-06-20},
	institution = {Future of Privacy Forum},
	author = {Marini, Alice and Kateifides, Alexis and Bates, Joel},
	year = {2018},
	file = {GDPR_CCPA_Comparison-Guide.pdf:/home/vilhuber/Zotero/storage/3PB2283M/GDPR_CCPA_Comparison-Guide.pdf:application/pdf}
}

@misc{noauthor_research_nodate,
	title = {The {Research} {Exception} to the {CCPA} {Right} to {Delete} - {Clarip}},
	url = {https://www.clarip.com/data-privacy/ca-privacy-right-delete-research-exception/},
	urldate = {2020-06-20},
	note = {Library Catalog: www.clarip.com},
	file = {Snapshot:/home/vilhuber/Zotero/storage/ZGUTNA7S/ca-privacy-right-delete-research-exception.html:text/html}
}

@misc{noauthor_quick_nodate,
	title = {Quick {Overview}: {Understanding} the {California} {Consumer} {Privacy} {Act} ({CCPA}) {\textbar} {Association} of {Corporate} {Counsel} ({ACC})},
	url = {https://www.acc.com/resource-library/quick-overview-understanding-california-consumer-privacy-act-ccpa},
	urldate = {2020-06-20},
	file = {Quick Overview\: Understanding the California Consumer Privacy Act (CCPA) | Association of Corporate Counsel (ACC):/home/vilhuber/Zotero/storage/57CYY4E8/quick-overview-understanding-california-consumer-privacy-act-ccpa.html:text/html}
}

@article{molnar-gabor_germany_2018,
	title = {Germany: a fair balance between scientific freedom and data subjects' rights?},
	volume = {137},
	issn = {1432-1203},
	shorttitle = {Germany},
	doi = {10.1007/s00439-018-1912-1},
	abstract = {With the German Bundestag's adoption of the Data Protection Adaptation and Implementation Act EU (DSAnpUG-EU) on 30 June 2017, the adaptation of German law to the General Data Protection Regulation (GDPR) has begun (Gesetz zur Anpassung des Datenschutzrechts an die Verordnung (EU) 2016/679 und zur Umsetzung der Richtlinie (EU) 2016/680 (Datenschutz-Anpassungs- und -Umsetzungsgesetz-DSAnpUG-EU) v. 30. Juni 2017, BGBl. 2017 I p. 2097 et seq.). Despite being directly binding on all EU member states, the GDPR does not render national data protection provision obsolete-they are covered by the GDPR's opening clauses which include regulatory mandates and room for derogation. This creates considerable need for national legislative adaptation. Art. 1 DSAnpUG-EU contains the necessary amendments to the Federal Data Protection Law (BDSG(neu)), thus creating the second major building block of future German data protection alongside the GDPR itself. Nevertheless, there are still numerous sector-specific regulations in other federal laws and the data protection laws of the 16 states also need amendments. Adjustment in Germany is well on its way, but implementation in general is still ongoing, with further consequences for data processing and sharing.},
	language = {eng},
	number = {8},
	journal = {Human Genetics},
	author = {Molnár-Gábor, Fruzsina},
	month = aug,
	year = {2018},
	pmid = {30116955},
	pmcid = {PMC6132636},
	keywords = {Computer Security, Humans, Information Dissemination, Databases, Genetic, Genetic Privacy, Genetic Research, Germany},
	pages = {619--626},
	file = {Molnár-Gábor_2018_Germany.pdf:/home/vilhuber/Zotero/storage/U6VJLIY7/Molnár-Gábor_2018_Germany.pdf:application/pdf}
}

@article{greene_adjusting_2019,
	title = {Adjusting to the {GDPR}: {The} {Impact} on {Data} {Scientists} and {Behavioral} {Researchers}},
	volume = {7},
	issn = {2167-647X},
	shorttitle = {Adjusting to the {GDPR}},
	doi = {10.1089/big.2018.0176},
	abstract = {Rapid growth in the availability of behavioral big data (BBD) has outpaced the speed of updates to ethical research codes and regulation of data privacy and human subjects' data collection, storage, and use. The introduction of the European Union's (EU's) General Data Protection Regulation (GDPR) in May 2018 will have far-reaching effects on data scientists and researchers who use BBD, not only in the EU, but around the world. Consequently, many companies are struggling to comply with the Regulation. At the same time, academics interested in research collaborations with companies are finding it more difficult to obtain data. In light of the importance of BBD in both industry and academia, data scientists and behavioral researchers would benefit from a deeper understanding of the GDPR's key concepts, definitions, and principles, especially as they apply to the data science workflow. We identify key GDPR concepts and principles and describe how they can impact the work of data scientists and researchers in this new data privacy regulation era.},
	language = {eng},
	number = {3},
	journal = {Big Data},
	author = {Greene, Travis and Shmueli, Galit and Ray, Soumya and Fell, Jan},
	year = {2019},
	pmid = {31033336},
	keywords = {Privacy, Computer Security, Humans, data protection, behavioral big data, Behavioral Research, Data Science, European Union, GDPR, information quality (InfoQ), privacy and policy},
	pages = {140--162},
	file = {Greene et al_2019_Adjusting to the GDPR.pdf:/home/vilhuber/Zotero/storage/8EHR745R/Greene et al_2019_Adjusting to the GDPR.pdf:application/pdf}
}

@article{newell_cross-cultural_1998,
	title = {A {CROSS}-{CULTURAL} {COMPARISON} {OF} {PRIVACY} {DEFINITIONS} {AND} {FUNCTIONS}: {A} {SYSTEMS} {APPROACH}},
	volume = {18},
	issn = {0272-4944},
	shorttitle = {A {CROSS}-{CULTURAL} {COMPARISON} {OF} {PRIVACY} {DEFINITIONS} {AND} {FUNCTIONS}},
	url = {http://www.sciencedirect.com/science/article/pii/S0272494498901037},
	doi = {10.1006/jevp.1998.0103},
	abstract = {As a further step in developing a systems model of privacy, variables involved in the process of achieving a condition of privacy were examined cross-culturally. Subjects were students from Ireland, Senegal and the United States. Striking commonalities were found in the reasons why subjects required privacy, the affect that was associated with a desire for privacy, the definition of privacy as a condition of the person, the duration of the average privacy experience and the change in affect at the completion of the experience which supported the suggestion that privacy has a therapeutic effect. Within culture, variability was associated with age, gender and in the case of Senegal, with income. Between culture, variability was hardly noticeable. The majority of the subjects in each culture believed that not being disturbed was the most important element of privacy and grief, fatigue and need to focus were the main affective sets associated with seeking privacy. It is believed that several universals have been identified which may be used in later research, and that the study supports a systems-based model of privacy.},
	language = {en},
	number = {4},
	urldate = {2020-06-20},
	journal = {Journal of Environmental Psychology},
	author = {Newell, Patricia Brierley},
	month = dec,
	year = {1998},
	pages = {357--371},
	file = {ScienceDirect Snapshot:/home/vilhuber/Zotero/storage/VVZDUD89/S0272494498901037.html:text/html}
}

@article{futagami_keeping_1998,
	title = {Keeping one step ahead of the {Joneses}: status, the distribution of wealth, and long run growth},
	volume = {36},
	issn = {0167-2681},
	url = {https://www.sciencedirect.com/science/article/pii/S0167268198000729?via%3Dihub},
	doi = {10.1016/S0167-2681(98)00072-9},
	abstract = {Assuming that the utility of each agent depends on its relative wealth position in the society, this paper constructs an endogenous growth model. It is shown that even if the subjective discount rates differ across agents, there exists a unique balanced growth equilibrium in which each agent owns a positive share of the world wealth. It is also shown that if the agents are identical then an increase in savings incentives always raises the long run growth rate but if they are heterogeneous then an increase in savings incentives may lower the long run growth rate.},
	number = {1},
	journal = {Journal of Economic Behavior and Organization},
	author = {Futagami, Koichi and Shibata, Akihisa},
	year = {1998},
	keywords = {Wealth preference},
	pages = {109--126}
}

@article{funk_how_2016,
	title = {How accurate are surveyed preferences for public policies? evidence from a unique institutional setup},
	volume = {98},
	url = {https://www.mitpressjournals.org/doi/10.1162/REST_a_00585},
	doi = {10.1162/REST_a_00585},
	number = {3},
	journal = {Review of Economics and Statistics},
	author = {Funk, Patricia},
	year = {2016},
	pages = {442--454}
}

@incollection{fienberg_differential_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables},
	volume = {6344},
	isbn = {978-3-642-15837-7},
	url = {http://dx.doi.org/10.1007/978-3-642-15838-4_17},
	language = {English},
	booktitle = {Privacy in {Statistical} {Databases}},
	publisher = {Springer Berlin Heidelberg},
	author = {Fienberg, Stephen E. and Rinaldo, Alessandro and Yang, Xiaolin},
	editor = {Domingo-Ferrer, Josep and Magkos, Emmanouil},
	year = {2010},
	doi = {10.1007/978-3-642-15838-4_17},
	keywords = {formal privacy},
	pages = {187--199}
}

@book{fienberg_statistics_2007,
	title = {Statistics for {Social} and {Behavioral} {Sciences}},
	isbn = {978-0-387-32916-1},
	author = {Fienberg, E},
	year = {2007},
	doi = {10.1007/978-0-387-98138-3},
	keywords = {reference}
}

@article{fanti_building_2015,
	title = {Building a {RAPPOR} with the unknown: privacy-preserving learning of associations and data dictionaries},
	volume = {abs/1503.01214},
	url = {http://arxiv.org/abs/1503.01214},
	doi = {10.1515/popets-2016-0015},
	journal = {CoRR},
	author = {Fanti, Giulia C. and Pihur, Vasyl and Erlingsson, Úlfar},
	year = {2015},
	keywords = {formal privacy}
}

@article{fan_challenges_2014,
	title = {Challenges of {Big} {Data} analysis},
	volume = {1},
	issn = {2095-5138},
	url = {http://nsr.oxfordjournals.org/cgi/doi/10.1093/nsr/nwt032},
	doi = {10.1093/nsr/nwt032},
	number = {2},
	journal = {National Science Review},
	author = {Fan, J. and Han, F. and Liu, H.},
	year = {2014},
	keywords = {big data, data storage, incidental endogeneity, noise accumulation, spurious correlation},
	pages = {293--314}
}

@article{fang_optimal_2010,
	title = {Optimal {Provision} of {Multiple} {Excludable} {Public} {Goods}},
	volume = {2},
	url = {https://www.aeaweb.org/articles?id=10.1257/mic.2.4.1},
	doi = {10.1257/mic.2.4.1},
	abstract = {This paper studies the optimal provision mechanism for multiple excludable public goods. For a class of problems with symmetric goods and binary valuations, we show that the optimal mechanism involves bundling if a regularity condition, akin to a hazard rate condition, on the distribution of valuations is satisfied. Relative to separate provision mechanisms, the optimal bundling mechanism may increase the asymptotic provision probability of socially efficient public goods from zero to one, and decreases the extent of use exclusions. If the regularity condition is violated, the optimal solution replicates the separate provision outcome for the two-good case. (JEL D82, H41)},
	number = {November},
	journal = {American Economic Journal: Microeconomics},
	author = {Fang, Hanming and Norman, Peter},
	year = {2010},
	keywords = {public goods},
	pages = {1--37}
}

@inproceedings{fang_adaptive_2012,
	address = {Berlin, Heidelberg},
	title = {Adaptive {Differentially} {Private} {Histogram} of {Low}-{Dimensional} {Data}},
	isbn = {978-3-642-31680-7},
	abstract = {We want to publish low-dimensional points, for example 2D spatial points, in a differentially private manner. Most existing mechanisms publish noisy frequency counts of points in a fixed predefined partition. Arguably, histograms with adaptive partition, for example V-optimal and equi-depth histograms, which have smaller bin-widths in denser regions, would provide more statistical information. However, as the adaptive partitions leak significant information about the dataset, it is not clear how differentially private partitions can be published accurately. In this paper, we propose a simple method based on the observation that the sensitivity of publishing the sorted sequence of a dataset is independent of the size of dataset. Together with isotonic regression, the dataset can be reconstructed with high accuracy. One advantage of the proposed method is its simplicity, in the sense that there are only a few parameters to be determined. Furthermore, the parameters can be estimated solely from the privacy requirement ϵ and the total number of points, and hence do not leak information about the data. Although the parameters are chosen to minimize the earth mover's distance between the published data and original data, empirical studies show that the proposed method also achieves high accuracy w.r.t. to some other measurements, for example range query and order statistics.},
	booktitle = {Privacy {Enhancing} {Technologies}},
	publisher = {Springer Berlin Heidelberg},
	author = {Fang, Chengfang and Chang, Ee-Chien},
	editor = {Fischer-Hübner, Simone and Wright, Matthew},
	year = {2012},
	keywords = {formal privacy},
	pages = {160--179}
}

@article{erlingsson_rappor_2014,
	title = {{RAPPOR}: {Randomized} {Aggregatable} {Privacy}-{Preserving} {Ordinal} {Response}},
	url = {http://dl.acm.org/citation.cfm?id=2660267.2660348},
	doi = {10.1145/2660267.2660348},
	abstract = {Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.},
	journal = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security - CCS '14},
	author = {Erlingsson, Úlfar and Pihur, Vasyl and Korolova, Aleksandra},
	year = {2014},
	note = {ISBN: 9781450329576
\_eprint: 1407.6981},
	keywords = {formal privacy, statistical inference, privacy protection, cloud computing, crowdsourcing, population statistics},
	pages = {1054--1067}
}

@article{epstein_taste_1980,
	title = {A {Taste} for {Privacy}? {Evolution} and the {Emergence} of a {Naturalistic} {Ethic}},
	volume = {9},
	issn = {0047-2530},
	url = {http://www.jstor.org/stable/724177},
	doi = {10.1086/467660},
	number = {4},
	journal = {The Journal of Legal Studies},
	author = {Epstein, Richard A.},
	year = {1980},
	keywords = {Value of Privacy},
	pages = {665--681}
}

@article{edwards_linkage_1992,
	title = {Linkage analysis using loglinear models},
	volume = {13},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/0167947392901364},
	doi = {http://dx.doi.org/10.1016/0167-9473(92)90136-4},
	abstract = {Analysis of linkage between a set of genes or genetic markers is used to study their relative positions on the chromosomes. An exposition of linkage analysis is given in terms of loglinear models. It is shown that under a simplifying assumption (that of no interference) the independence graphs of the appropriate loglinear models consist of simple serial strings, exactly homologous with the chromosomes. Data from an experiment studying barley powdery mildew are analyzed by means of two loglinear model selection procedures, using asymptotic and exact tests respectively. Comparison of these and other approaches is given in a brief discussion.},
	number = {3},
	journal = {Computational Statistics \& Data Analysis},
	author = {Edwards, David},
	year = {1992},
	keywords = {linkage analysis},
	pages = {281--290}
}

@book{edition_internet_2009,
	title = {Internet {Policy} and {Economics}: {Challenges} and {Perspectives}},
	isbn = {978-1-4419-0037-1},
	author = {Edition, Second},
	year = {2009},
	doi = {10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C},
	note = {ISSN: 1433-7851}
}

@article{easterbrook_privacy_1980,
	title = {Privacy and the {Optimal} {Extent} of {Disclosure} under the {Freedom} of {Information} {Act}},
	volume = {9},
	issn = {0047-2530},
	url = {http://www.jstor.org/stable/724181},
	doi = {10.1086/467664},
	number = {4},
	journal = {The Journal of Legal Studies},
	author = {Easterbrook, Frank H},
	year = {1980},
	keywords = {economics of privacy},
	pages = {775--800}
}

@article{dwork_boosting_2010,
	title = {Boosting and {Differential} {Privacy}},
	url = {https://ieeexplore.ieee.org/document/5670947},
	doi = {10.1109/FOCS.2010.12},
	journal = {2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
	author = {Dwork, Cynthia and Rothblum, Guy N. and Vadhan, Salil},
	year = {2010},
	note = {ISBN: 978-1-4244-8525-3},
	keywords = {formal privacy},
	pages = {51--60}
}

@article{dwork_concentrated_2016,
	title = {Concentrated differential privacy},
	volume = {abs/1603.01887},
	url = {http://arxiv.org/abs/1603.01887},
	journal = {CoRR},
	author = {Dwork, Cynthia and Rothblum, Guy N.},
	year = {2016},
	keywords = {formal privacy}
}

@article{dwork_privacy-preserving_2004,
	title = {Privacy-preserving datamining on vertically partitioned databases},
	volume = {3152},
	issn = {0302-9743},
	url = {http://research.microsoft.com/apps/pubs/default.aspx?id=64353},
	abstract = {In a recent paper Dinur and Nissim considered a statistical database in which a trusted database administrator monitors queries and introduces noise to the responses with the goal of maintaining data privacy [5]. Under a rigorous definition of breach of privacy, Dinur and Nissim proved that unless the total number of queries is sub-linear in the size of the database, a substantial amount of noise is required to avoid a breach, rendering the database almost useless. As databases grow increasingly large, the possibility of being able to query only a sub-linear number of times becomes realistic. We further investigate this situation, generalizing the previous work in two impor- tant directions: multi-attribute databases (previous work dealt only with single-attribute databases) and vertically partitioned databases, in which different subsets of attributes are stored in different databases. In addi- tion, we show how to use our techniques for datamining on published noisy statistics.},
	journal = {Proceedings of Advances in Cryptology (CRYPTO)},
	author = {Dwork, Cynthia and Nissim, Kobbi},
	year = {2004},
	note = {ISBN: 3540226680},
	keywords = {formal privacy, data privacy, data mining, statistical databases, vertically parti-},
	pages = {528--544}
}

@article{dwork_differential_2010,
	title = {Differential privacy under continual observation},
	issn = {0737-8017},
	url = {https://dl.acm.org/citation.cfm?doid=1806689.1806787},
	doi = {10.1145/1806689.1806787},
	abstract = {Differential privacy is a recent notion of privacy tailored to privacy-preserving data analysis [11]. Up to this point, research on differentially private data analysis has focused on the setting of a trusted curator holding a large, static, data set; thus every computation is a "one-shot" object: there is no point in computing something twice, since the result will be unchanged, up to any randomness introduced for privacy. However, many applications of data analysis involve repeated computations, either because the entire goal is one of monitoring, e.g., of traffic conditions, search trends, or incidence of influenza, or because the goal is some kind of adaptive optimization, e.g., placement of data to minimize access costs. In these cases, the algorithm must permit continual observation of the system's state. We therefore initiate a study of differential privacy under continual observation. We identify the problem of maintaining a counter in a privacy preserving manner and show its wide applicability to many different problems.},
	journal = {Stoc},
	author = {Dwork, Cynthia and Naor, Moni and Pitassi, Toniann and Rothblum, Guy N},
	year = {2010},
	note = {ISBN: 9781450300506},
	keywords = {formal privacy, private data analysis, privacy},
	pages = {715--724}
}

@article{yang_differential_2012,
	title = {Differential {Privacy} for {Protecting} {Multi}-dimensional {Contingency} {Table} {Data}: {Extensions} and {Applications}},
	volume = {4},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/613},
	doi = {10.29012/jpc.v4i1.613},
	abstract = {The methodology of differential privacy has provided a strong definition of privacy which in some settings, using a mechanism of doubly-exponential noise addition, also allows for extraction of informative statistics from databases. In a recent paper, Barak et al. extend this approach to the release of a specified set of margins from a multi-way contingency table. Privacy protection in such settings implicitly focuses on small cell counts that might allow for the identification of units that are unique in the database. We explore how well the mechanism works in the context of a series of examples, and the extent to which the proposed differential-privacy mechanism allows for sensible inferences from the released data. We conclude that the methodology, as it is currently formulated, is problematic in the context of the types of large sparse contingency tables encountered in statistical practice.},
	number = {1},
	journal = {Journal of Privacy and Confidentiality},
	author = {Yang, Xiaolin and Feinberg, Stephen E. and Rinaldoi, Alessandro},
	year = {2012},
	keywords = {formal privacy},
	pages = {101--125}
}

@article{dwork_differential_2009,
	title = {Differential privacy and robust statistics},
	url = {https://dl.acm.org/citation.cfm?doid=1536414.1536466},
	doi = {10.1145/1536414.1536466},
	abstract = {We show by means of several examples that robust statistical estimators present an excellent starting point for differentially private estimators. Our algorithms use a new paradigm for differentially private mechanisms, which we call Propose-Test-Release (PTR), and for which we give a formal definition and general composition theorems.},
	journal = {Proceedings of the 41st annual ACM symposium on Symposium on theory of computing - STOC '09},
	author = {Dwork, Cynthia and Lei, Jing},
	year = {2009},
	note = {ISBN: 9781605585062},
	keywords = {differential privacy, value of privacy, local sensitivity, propose-test-release paradigm, robust statistics},
	pages = {371}
}

@article{dwork_fairness_2011,
	title = {Fairness {Through} {Awareness}},
	url = {http://arxiv.org/abs/1104.3913},
	abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
	journal = {arXiv},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Rich},
	year = {2011},
	note = {\_eprint: 1104.3913}
}

@article{dwork_complexity_2009,
	title = {On the complexity of differentially private data release: efficient algorithms and hardness results},
	issn = {0737-8017},
	url = {https://dl.acm.org/citation.cfm?doid=1536414.1536467},
	doi = {10.1145/1536414.1536467},
	abstract = {We consider private data analysis in the setting in which a trusted and trustworthy curator, having obtained a large data set containing private information, releases to the public a "sanitization" of the data set that simultaneously protects the privacy of the individual contributors of data and offers utility to the data analyst. The sanitization may be in the form of an arbitrary data structure, accompanied by a computational procedure for determining approximate answers to queries on the original data set, or it may be a "synthetic data set" consisting of data items drawn from the same universe as items in the original data set; queries are carried out as if the synthetic data set were the actual input. In either case the process is non-interactive; once the sanitization has been released the original data and the curator play no further role. For the task of sanitizing with a synthetic dataset output, we map the boundary between computational feasibility and infeasibility with respect to a variety of utility measures. For the (potentially easier) task of sanitizing with unrestricted output format, we show a tight qualitative and quantitative connection between hardness of sanitizing and the existence of traitor tracing schemes.},
	journal = {Proceedings of the 41st annual ACM symposium on Symposium on theory of computing - STOC '09},
	author = {Dwork, Cynthia and Naor, Moni and Reingold, Omer and Rothblum, Guy N and Vadhan, Salil},
	year = {2009},
	note = {ISBN: 9781605585062},
	keywords = {formal privacy, differential privacy, privacy, exponential mechanism, cryptography, traitor tracing},
	pages = {381}
}

@article{dwork_difficulties_2010,
	title = {On the difficulties of disclosure prevention in statistical databases or the case for differential privacy},
	volume = {2},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/585},
	doi = {10.29012/jpc.v2i1.585},
	abstract = {In 1977 Tore Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a natural formalization of Dalenius goal cannot be achieved if the database is useful. The key obstacle is the side information that may be available to an adversary. Our results hold under very general conditions regarding the database, the notion of privacy violation, and the notion of utility. Contrary to intuition, a variant of the result threatens the privacy even of someone not in the database. This state of affairs motivated the notion of differential privacy 15, 16, a strong ad omnia privacy which, intuitively, captures the increased risk to ones privacy incurred by participating in a database.},
	number = {1},
	journal = {Journal of Privacy and Confidentiality},
	author = {Dwork, Cynthia and Naor, Moni},
	year = {2010},
	keywords = {formal privacy},
	pages = {93--107}
}

@article{dwork_reusable_2015,
	title = {The reusable holdout: preserving validity in adaptive data analysis},
	volume = {349},
	url = {http://science.sciencemag.org/content/349/6248/636},
	doi = {10.1126/science.aaa9375},
	number = {6248},
	journal = {Science},
	author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
	month = aug,
	year = {2015},
	keywords = {value of privacy},
	pages = {636--638}
}

@article{dwork_firm_2011,
	title = {A firm foundation for private data analysis},
	volume = {54},
	url = {https://dl.acm.org/citation.cfm?doid=1866739.1866758},
	doi = {doi :10.1145/1866739.1866758},
	number = {1},
	journal = {Communications of the ACM},
	author = {Dwork, Cynthia},
	month = jan,
	year = {2011},
	keywords = {formal privacy},
	pages = {86--95}
}

@article{duncan_risk_1989,
	title = {The {Risk} of {Disclosure} for {Microdata}},
	volume = {7},
	copyright = {Copyright 1989 American Statistical Association},
	issn = {0735-0015},
	url = {http://www.jstor.org/stable/1391438},
	doi = {10.1080/07350015.1989.10509729},
	abstract = {Statistical agencies that provide microdata for public use strive to keep the risk of disclosure of confidential information negligible. Assessing the magnitude of the risk of disclosure is not easy, however. Whether a data user or intruder attempts to obtain confidential information from a public-use file depends on the perceived costs of identifying a record, the perceived probability of success, and the information expected to be gained. In this article, a decision-theoretic framework for risk assessment that includes the intruder's objectives and strategy for compromising the data base and the information gained by the intruder is developed. Two kinds of microdata disclosure are distinguished–disclosure of a respondent's identity and disclosure of a respondent's attributes as a result of an unauthorized identification. A formula for the risk of identity disclosure is given, and a simple approximation to it is evaluated.},
	language = {English},
	number = {2},
	journal = {Journal of Business \& Economic Statistics},
	author = {Duncan, George and Lambert, Diane},
	year = {1989},
	note = {Publisher: American Statistical Association},
	keywords = {SDL, statistical disclosure limitation},
	pages = {207--217}
}

@article{dwork_differential_2008,
	title = {Differential privacy: a survey of results},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-79228-4_1},
	doi = {10.1007/978-3-540-79228-4_1},
	journal = {Theory and Applications of Models of Computation},
	author = {Dwork, Cynthia},
	year = {2008},
	note = {Publisher: Springer},
	keywords = {formal privacy},
	pages = {1--19}
}

@inproceedings{duncan_obtaining_1999,
	title = {Obtaining information while preserving privacy: a markov perturbation method for tabular data},
	booktitle = {Statistical {Data} {Protection} ({SDP} '98)},
	publisher = {Eurostat},
	author = {Duncan, George T. and Fienberg, Stephen E.},
	year = {1999},
	keywords = {SDL, statistical disclosure limitation},
	pages = {351--362}
}

@incollection{duncan_disclosure_2001,
	title = {Disclosure limitation methods and information loss for tabular data},
	booktitle = {Confidentiality, {Disclosure} and {Data} {Access}: {Theory} and {Practical} {Applications} for {Statistical} {Agencies}},
	publisher = {Elsevier},
	author = {Duncan, G.T. and Fienberg, S.E. and Krishnan, R. and Padman, R. and Roehrig, S.F.},
	editor = {Doyle, P. and Lane, J. and Theeuwes, J. and Zayatz, L.},
	year = {2001},
	keywords = {SDL, statistical disclosure limitation},
	pages = {135--166}
}

@article{domingo-ferrer_new_2016,
	title = {New directions in anonymization: permutation paradigm, verifiability by subjects and intruders, transparency to users},
	volume = {337},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025515009032},
	doi = {https://doi.org/10.1016/j.ins.2015.12.014},
	journal = {Information Sciences},
	author = {Domingo-Ferrer, Josep and Muralidhar, Krishnamurty},
	month = apr,
	year = {2016},
	keywords = {formal privacy},
	pages = {11--24}
}

@article{davis_bones_2002,
	title = {Bones, {Bombs}, and {Breakpoints}: {The} {Geography} of {Economic} {Activity}},
	volume = {92},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/000282802762024502},
	doi = {10.1257/000282802762024502},
	abstract = {We consider the distribution of economic activity within a country in light of three leading theories-increasing returns, random growth, and locationalfundamentals. To do so, we examine the distribution of regional population in Japan from the Stone Age to the modern era. We also consider the Allied bombing of Japanese cities in WWII as a shock to relative city sizes. Our results support a hybrid theory in which locational fundamentals establish the spatial pattern of relative regional densities, but increasing returns help to determine the degree of spatial differenti- ation. Long-run city size is robust even to large temporary shocks},
	number = {5},
	journal = {American Economic Review},
	author = {Davis, D R and Weinstein, D},
	year = {2002},
	pages = {1269--1289}
}

@article{duncan_fienberg_s_obtaining_1998,
	title = {Obtaining information while preserving privacy: a {Markov} perturbation method for tabular data},
	abstract = {Statistical information can be provided while preserving a specified\${\textbackslash}backslash\$nlevel of confidentiality protection. The general approach is to provide\${\textbackslash}backslash\$ndisclosure-limited data that maximizes its statistical utility subject\${\textbackslash}backslash\$nto confidentiality constraints. Disclosure limitation based on Markov\${\textbackslash}backslash\$nchain methods that respect the underlying uncertainty in real data\${\textbackslash}backslash\$nis examined.},
	journal = {Proceedings of the Statistical Data Protection Conference},
	author = {Duncan Fienberg, S, G},
	year = {1998},
	keywords = {SDL, statistical disclosure limitation, confidentiality, data access, data security, hierarchical, markov chains, models, perturbation methods, simulated data},
	pages = {351--362}
}

@book{cornell_institute_for_social_and_economic_research_and_survey_research_institute_cornell_2017,
	title = {Cornell national social survey (cnss) integrated (beta version)},
	url = {https://digitalcommons.ilr.cornell.edu/ldi/37/},
	publisher = {Cornell Institute for Social and Economic Research},
	author = {{Cornell Institute for Social and Economic Research and Survey Research Institute}},
	month = apr,
	year = {2017},
	doi = {10.5281/zenodo.345385}
}

@article{dalenius_simple_1981,
	title = {A {Simple} {Procedure} for {Controlled} {Rounding}},
	volume = {3},
	journal = {Statistik Tidskrift},
	author = {Dalenius, T.},
	year = {1981},
	keywords = {SDL, statistical disclosure limitation},
	pages = {202--208}
}

@article{cynthia_dwork_differential_2009,
	title = {Differential privacy for statistics: {What} we know and what we want to learn},
	volume = {1},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.206.2441},
	doi = {10.29012/jpc.v1i2.570},
	number = {2},
	journal = {Journal of Privacy and Confidentiality2},
	author = {Cynthia Dwork, Adam Smith},
	year = {2009},
	keywords = {formal privacy},
	pages = {135--154}
}

@techreport{commission_eurobarometer_2013,
	title = {Eurobarometer 80, {Public} opinion in the european union},
	abstract = {Eurobarometer 80 Autumn 2013, Public Opinion in the European Union},
	number = {November},
	institution = {European Commission},
	author = {Commission, European},
	year = {2013},
	keywords = {value of privacy}
}

@article{cole_incorporating_1995,
	title = {Incorporating concern for relative wealth into economic models},
	volume = {19},
	url = {https://go.galegroup.com/ps/i.do?p=AONE&sw=w&u=googlescholar&v=2.1&it=r&id=GALE%7CA17573001&sid=googleScholar&asid=731f5373},
	number = {3},
	journal = {Federal Reserve Bank of Minneapolis Quarterly Review},
	author = {Cole, Harold L and Mailath, George J and Postlewaite, Andrew},
	year = {1995},
	note = {ISBN: 6123402366},
	pages = {12--21}
}

@article{clark_relative_2008,
	title = {Relative income, happiness, and utility: {An} explanation for the {Easterlin} paradox and other puzzles},
	volume = {46},
	issn = {0022-0515},
	url = {https://www.aeaweb.org/articles?id=10.1257/jel.46.1.95},
	doi = {10.1257/jel.46.1.95},
	abstract = {The well-known Easterlin paradox points out that average happiness has remained constant over time despite sharp rises in GNP per head. At the same time, a micro literature has typically found positive correlations between individual income and individual measures of subjective well-being. This paper suggests that these two findings are consistent with the presence of relative income terms in the utility function. Income may be evaluated relative to others (social comparison) or to oneself in the past (habituation). We review the evidence on relative income from the subjective well-being literature. We also discuss the relation (or not) between happiness and utility, and discuss some nonhappiness research (behavioral, experimental, neurological) related to income comparisons. We last consider how relative income in the utility function can affect economic models of behavior in the domains Of consumption, investment, economic growth, savings, taxation, labor supply, wages, and migration.},
	number = {1},
	journal = {Journal of Economic Literature},
	author = {Clark, A E and Frijters, P and Shields, M A},
	year = {2008},
	pmid = {17746758},
	keywords = {value of data, asset prices, germany following reunification, growth, habit formation, job-satisfaction, life satisfaction, loss aversion, panel-data, positive affect, social-status},
	pages = {95--144}
}

@article{chowdhury_disclosure_1999,
	title = {Disclosure {Detection} in {Multivariate} {Categorical} {Databases}: {Auditing} {Confidentiality} {Protection} {Through} {Two} {New} {Matrix} {Operators}},
	volume = {45},
	issn = {0025-1909},
	url = {http://mansci.journal.informs.org/content/45/12/1710.abstract$\backslash$nhttp://mansci.journal.informs.org/cgi/doi/10.1287/mnsc.45.12.1710},
	doi = {10.1287/mnsc.45.12.1710},
	abstract = {As databases grow more prevalent and comprehensive, database administrators seek to limit disclosure of confidential information while still providing access to data. Practical databases accommodate users with heterogeneous needs for access. Each class of data user is accorded access to only certain views. Other views are considered confidential, and hence to be protected. Using illustrations from health care and education, this article addresses inferential disclosure of confidential views in multidimensional categorical databases. It demonstrates that any structural, so data-value-independent method for detecting disclosure can fail. Consistent with previous work for two-way tables, it presents a data-value-dependent method to obtain tight lower and upper bounds for confidential data values. For two-dimensional projections of categorical databases, it exploits the network structure of a linear programming (LP) formulation to develop two transportation flow algorithms that are both computationally efficient and insightful. These algorithms can be easily implemented through two new matrix operators, cell-maxima and cell-minima. Collectively, this method is called matrix comparative assignment (MCA). Finally, it extends both the LP and MCA approaches to inferential disclosure when accessible views have been masked.},
	number = {12},
	journal = {Management Science},
	author = {Chowdhury, Sumit Dutta and Duncan, George T and Krishnan, Ramayya and Roehrig, Stephen F and Mukherjee, Sumitra},
	year = {1999},
	keywords = {SDL, statistical disclosure limitation},
	pages = {1710--1723}
}

@article{chen_truthful_2011,
	title = {Truthful mechanisms for agents that value privacy},
	volume = {abs/1111.5472},
	url = {http://arxiv.org/abs/1111.5472},
	journal = {CoRR},
	author = {Chen, Yiling and Chong, Stephen and Kash, Ian A. and Moran, Tal and Vadhan, Salil P.},
	year = {2011}
}

@inproceedings{childs_development_2012,
	title = {Development of the {Federal} {Statistical} {System} {Public} {Opinion} {Survey}},
	booktitle = {{JSM} {Proceedings} {Survey} {Research} {Methods} {Section}},
	author = {Childs, Jennifer Hunter and Willson, Stephanie and Martinez, Shelly Wilkie and Rasmussen, Laura and Wroblewski, Monica},
	year = {2012},
	note = {event-place: Alexandria, VA},
	keywords = {official statistics}
}

@book{childs_understanding_2014,
	title = {Understanding {Trust} in {Official} {Statistics} in the {United} {States}},
	author = {Childs, Jennifer Hunter},
	month = sep,
	year = {2014},
	keywords = {official statistics}
}

@article{chaudhuri_differentially_2011,
	title = {Differentially {Private} {Empirical} {Risk} {Minimization}},
	volume = {12},
	issn = {1532-4435},
	url = {http://www.jmlr.org/papers/volume12/chaudhuri11a/chaudhuri11a.pdf},
	abstract = {Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or financial records, are analyzed. We provide general techniques to produce privacy-preserving approximations of classifiers learned via (regularized) empirical risk minimization (ERM). These algorithms are private under the \${\textbackslash}backslashepsilon\$-differential privacy definition due to Dwork et al. (2006). First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classification. Then we propose a new method, objective perturbation, for privacy-preserving machine learning algorithm design. This method entails perturbing the objective function before optimizing over classifiers. If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels. We further present a privacy-preserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines. We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets. Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance.},
	journal = {Journal of Machine Learning Research},
	author = {Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D.},
	year = {2011},
	pmid = {21892342},
	note = {\_eprint: 0912.0071},
	keywords = {formal privacy, privacy, classification, empirical risk minimization, optimization},
	pages = {1069--1109}
}

@article{chan_theory_2008,
	title = {Theory and {Applications} of {Models} of {Computation}},
	volume = {4978},
	issn = {0302-9743},
	url = {http://www.springerlink.com/index/u963k75981004046.pdf$\backslash$nhttp://link.springer.com/content/pdf/10.1007/978-3-642-38236-9.pdf},
	doi = {10.1007/978-3-540-79228-4},
	abstract = {Over the past five years a new approach to privacy-preserving data analysis has born fruit 13, 18, 7, 19, 5, 37, 35, 8, 32. This approach differs from much (but not all!) of the related literature in the statistics, databases, theory, and cryptography communities, in that a formal and ad omnia privacy guarantee is defined, and the data analysis techniques presented are rigorously proved to satisfy the guarantee. The key privacy guarantee that has emerged is differential privacy. Roughly speaking, this ensures that (almost, and quantifiably) no risk is incurred by joining a statistical database. In this survey, we recall the definition of differential privacy and two basic techniques for achieving it. We then show some interesting applications of these techniques, presenting algorithms for three specific tasks and three general results on differentially private learning.},
	journal = {Springer},
	author = {Chan, THH and Lau, LC and Trevisan, L},
	year = {2008},
	note = {ISBN: 9783540792277},
	pages = {1--19}
}

@article{bun_concentrated_2016,
	title = {Concentrated differential privacy: simplifications, extensions, and lower bounds},
	volume = {abs/1605.02065},
	url = {http://arxiv.org/abs/1605.02065},
	doi = {10.1007/978-3-662-53641-4_24},
	journal = {CoRR},
	author = {Bun, Mark and Steinke, Thomas},
	year = {2016},
	keywords = {formal privacy}
}

@article{pew_research_center_public_2014,
	title = {Public {Perceptions} of {Privacy} and {Security}},
	url = {N/A},
	journal = {Pew Research Center},
	author = {{Pew Research Center}},
	year = {2014},
	keywords = {value of privacy}
}

@article{card_workplace_2013,
	title = {Workplace {Heterogeneity} and the {Rise} of {West} {German} {Wage} {Inequality}},
	volume = {128},
	abstract = {We study the role of establishment-specific wage premiums in generating recent increases in West German wage inequality. Models with additive fixed effects for workers and establishments are fit into four subintervals spanning the period from 1985 to 2009. We show that these models provide a good approximation to the wage structure and can explain nearly all of the dramatic rise in West German wage inequality. Our estimates suggest that the increasing dispersion of West German wages has arisen from a combination of rising heterogeneity between workers, rising dispersion in the wage premiums at different establishments, and increasing assortativeness in the assignment of workers to plants. In contrast, the idiosyncratic job-match component of wage variation is small and stable over time. Decomposing changes in mean wages between different education groups, occupations, and industries, we find that increasing plant-level heterogeneity and rising assortativeness in the assignment of workers to establishments explain a large share of the rise in inequality along all three dimensions. JEL Codes: J00, J31, J40. Copyright 2013, Oxford University Press.},
	number = {3},
	journal = {The Quarterly Journal of Economics},
	author = {Card, David and Heining, Jörg and Kline, Patrick},
	year = {2013},
	pages = {967--1015}
}

@article{cantor_what_2002,
	title = {What {We} {Want} {Students} {To} {Learn}},
	volume = {34},
	number = {6},
	journal = {Change},
	author = {Cantor, Nancy and Schomberg, Steven},
	year = {2002},
	pages = {46--49}
}

@article{becker_theory_1974,
	title = {A {Theory} of {Social} {Interactions}},
	volume = {82},
	copyright = {Copyright 1974 The University of Chicago Press},
	issn = {0022-3808},
	language = {English},
	number = {6},
	journal = {Journal of Political Economy},
	author = {Becker, Gary S.},
	year = {1974},
	note = {Publisher: The University of Chicago Press},
	pages = {1063--1093}
}

@article{boutilier_optimal_2012,
	title = {Optimal {Social} {Choice} {Functions}: {A} {Utilitarian} {View}},
	volume = {1},
	doi = {10.1145/2229012.2229030},
	abstract = {We adopt a utilitarian perspective on social choice, assuming that agents have (possibly latent) utility func- tions over some space of alternatives. For many reasons one might consider mechanisms, or social choice functions, that only have access to the ordinal rankings of alternatives by the individual agents rather than their utility functions. In this context, one possible objective for a social choice function is the maximiza- tion of (expected) social welfare relative to the information contained in these rankings. We study such optimal social choice functions under three different models, and underscore the important role played by scoring functions. In our worst-case model, no assumptions are made about the underlying distribution and we analyze the worst-case distortion–or degree to which the selected alternative does not maximize social welfare–of optimal social choice functions. In our average-case model, we derive optimal functions under neutral (or impartial culture) distributional models. Finally, a very general learning-theoretic model allows for the computation of optimal social choice functions (i.e., that maximize expected social welfare) under arbitrary, sampleable distributions. In the latter case, we provide both algorithms and sample complexity results for the class of scoring functions, and further validate the approach empirically. Categories and Subject Descriptors: I.2.11 [Distributed Artificial Intelligence]: Multiagent Systems; J.4 [Computer Applications]: Social and Behavioral Sciences–Economics Additional Key Words and Phrases: Social choice, Utility theory, Group decisions},
	number = {212},
	journal = {In Proceedings of ACM Conference on Electronic Commerce},
	author = {Boutilier, Craig and Caragiannis, Ioannis and Haber, Simi and Lu, Tyler and Procaccia, Ariel D and Sheffet, O R},
	year = {2012},
	note = {ISBN: 9781450314152},
	keywords = {public goods},
	pages = {197--214}
}

@inproceedings{blum_learning_2008,
	address = {New York, NY, USA},
	series = {{STOC} '08},
	title = {A learning theory approach to non-interactive database privacy},
	isbn = {978-1-60558-047-0},
	doi = {10.1145/1374376.1374464},
	booktitle = {Proceedings of the 40th annual {ACM} symposium on {Theory} of computing},
	publisher = {ACM},
	author = {Blum, Avrim and Ligett, Katrina and Roth, Aaron},
	year = {2008},
	note = {event-place: Victoria, British Columbia, Canada},
	keywords = {Formal Privacy, learning theory, non-interactive database privacy},
	pages = {609--618}
}

@article{bergstrom_private_1986,
	title = {On the private provision of public goods},
	volume = {29},
	issn = {0047-2727},
	url = {http://www.sciencedirect.com/science/article/pii/0047272786900241 http://www.sciencedirect.com/science/article/pii/0047272786900241/pdf?md5=937f657636d8e9801673dcfdaecb3ec6&pid=1-s2.0-0047272786900241-main.pdf},
	doi = {10.1016/0047-2727(86)90024-1},
	abstract = {We consider a general model of the non-cooperative provision of a public good. Under very weak assumptions there will always exist a unique Nash equilibrium in our model. A small redistribution of wealth among the contributing consumers will not change the equilibrium amount of the public good. However, larger redistributions of wealth will change the set of contributors and thereby change the equilibrium provision of the public good. We are able to characterize the properties and the comparative statics of the equilibrium in a quite complete way and to analyze the extent to which government provision of a public good crowds out private contributions.},
	number = {1},
	journal = {Journal of Public Economics},
	author = {Bergstrom, Theodore and Blume, Lawrence and Varian, Hal},
	year = {1986},
	keywords = {economics of privacy},
	pages = {25--49}
}

@article{bassily_algorithmic_2015,
	title = {Algorithmic stability for adaptive data analysis},
	volume = {abs/1511.02513},
	url = {http://arxiv.org/abs/1511.02513},
	doi = {10.1145/2897518.2897566},
	journal = {CoRR},
	author = {Bassily, Raef and Nissim, Kobbi and Smith, Adam D. and Steinke, Thomas and Stemmer, Uri and Ullman, Jonathan},
	year = {2015}
}

@article{ausubel_efficient_2009,
	title = {An {Efficient} {Auction} for {Multiple} {Objects}},
	volume = {94},
	issn = {0002-8282},
	doi = {10.1257/0002828043052330},
	abstract = {When bidders exhibit multi-unit demands, standard auction methods generally yield inefficient outcomes. This article proposes a new ascending-bid auction for homo- geneous goods, such as Treasury bills or telecommunications spectrum. The auc- tioneer announces a price and bidders respond with quantities. Items are awarded at the current price whenever they are "clinched," and the price is incremented until the market clears. With private values, this (dynamic) auction yields the same outcome as the (sealed-bid) Vickrey auction, but has advantages of simplicity and privacy preservation. With interdependent values, this auction may retain efficiency, whereas the Vickrey auction suffers from a generalized Winner's Curse.},
	number = {August},
	journal = {The American Economic Review},
	author = {Ausubel, Lawrence M.},
	year = {2009},
	keywords = {ascending auctions, auctions, efficient auctions, multi-unit auctions, vickrey auctions},
	pages = {1452--1475}
}

@article{arora_multiplicative_2012,
	title = {The multiplicative weights update method: a meta-algorithm and applications},
	volume = {8},
	issn = {1557-2862},
	url = {http://www.theoryofcomputing.org/articles/v008a006},
	doi = {10.4086/toc.2012.v008a006},
	abstract = {Algorithms in varied fields use the idea of maintaining a distribution over a certain set and use the multiplicative update rule to iteratively change these weights. Their analyses are usually very similar and rely on an exponential potential function. In this survey we present a simple meta-algorithm that unifies many of these disparate algorithms and derives them as simple instantiations of the meta-algorithm. We feel that since this meta-algorithm and its analysis are so simple, and its applications so broad, it should be a standard part of algorithms courses, like "divide and conquer."},
	number = {1},
	journal = {Theory of Computing},
	author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
	year = {2012},
	keywords = {Formal Privacy, algorithms, and phrases, game theory, machine learning},
	pages = {121--164}
}

@article{allen_problematic_2007,
	title = {The {Problematic} {Value} of {Mathematical} {Models} of {Evidence}},
	volume = {36},
	issn = {0047-2530},
	doi = {10.1086/508269},
	abstract = {Abstract This paper discusses mathematical modeling of the value of particular items of evidence. We demonstrate that such formal modeling has only limited use in explaining the value of legal evidence, much more limited than those investigators who construct and discuss the models assume, and thus that the conclusions they draw about the value of evidence are unwarranted. This is done through a discussion of several recent examples that attempt to quantify evidence relating to carpet fibers, infidelity, DNA random match evidence, and character evidence used to impeach a witness. This paper makes the following contributions. Most important, it is another demonstration of the complex relationship between algorithmic tools and legal decision making. Furthermore, at a minimum it highlights the need for both analytical and empirical work to accommodate the reference class problem and the risk of failing to do so. - Copyright 2007 The University of Chicago},
	number = {1},
	journal = {The Journal of Legal Studies},
	author = {Allen, Ronald J. and Pardo, Michael S.},
	year = {2007},
	pages = {107--140}
}

@article{bassily_algorithmic_2016,
	title = {Algorithmic stability for adaptive data analysis},
	url = {https://dl.acm.org/citation.cfm?doid=2897518.2897566},
	doi = {10.1145/2897518.2897566},
	journal = {Symposium on Theory of Computing (STOC'16)},
	author = {Bassily, Raef and Nissim, Kobbi and Smith, Adam D. and Steinke, Thomas and Stemmer, Uri and Ullman, Jonathan},
	year = {2016},
	keywords = {Formal Privacy},
	pages = {1046--1059}
}

@inproceedings{barak_privacy_2007,
	address = {New York, NY, USA},
	series = {{PODS} '07},
	title = {Privacy, accuracy, and consistency too: a holistic solution to contingency table release},
	isbn = {978-1-59593-685-1},
	url = {http://doi.acm.org/10.1145/1265530.1265569},
	doi = {10.1145/1265530.1265569},
	booktitle = {Proceedings of the {Twenty}-sixth {ACM} {SIGMOD}-{SIGACT}-{SIGART} {Symposium} on {Principles} of {Database} {Systems}},
	publisher = {ACM},
	author = {Barak, Boaz and Chaudhuri, Kamalika and Dwork, Cynthia and Kale, Satyen and McSherry, Frank and Talwar, Kunal},
	year = {2007},
	note = {event-place: Beijing, China},
	keywords = {Formal Privacy, privacy, contingency table, OLAP},
	pages = {273--282}
}

@article{avorn_26_2015,
	title = {The \$2.6 {Billion} {Pill} – {Methodologic} and {Policy} {Considerations}},
	issn = {0028-4793},
	url = {https://www.nejm.org/doi/full/10.1056/NEJMp1500848},
	doi = {10.1056/nejmp1500848},
	abstract = {The introduction of several new astonishingly expensive prescription drugs has rekindled debate over the origins of and justifications for those prices.},
	number = {May},
	journal = {The New England journal of medicine},
	author = {Avorn, Jerry},
	year = {2015},
	pmid = {25671249},
	pages = {2012--2014}
}

@article{aronsson_when_2008,
	title = {When the {Joneses}' {Consumption} {Hurts}: {Optimal} {Public} {Good} {Provision} and {Nonlinear} {Income} {Taxation}},
	volume = {92},
	abstract = {This paper considers a model with nonlinear income taxation and public good provision when people care about their relative consumption compared to others. The standard optimality expressions are modified by terms that reflect the extent to which people care about relative consumption. The extent to which the public good provision rule should be modified is shown to depend critically on the preference elicitation format. The modified tax formulas imply substantially higher marginal income tax rates than in the conventional case, under plausible assumptions and available empirical estimates regarding comparison consumption concerns.},
	number = {5-6},
	journal = {Journal of Public Economics},
	author = {Aronsson, Thomas and Johansson-Stenman, Olof},
	month = jun,
	year = {2008},
	pages = {986--997}
}

@article{alessie_habit_1991,
	title = {Habit formation, interdependent preferences and demographic effects in the almost ideal demand system},
	volume = {101},
	url = {http://www.jstor.org/stable/2233548?origin=crossref$\backslash$nhttp://www.jstor.org/stable/10.2307/2233548},
	doi = {10.2307/2233548},
	abstract = {Estimation of demand systems for aggregate consumption data tends to give results that are quite different from results obtained on the basis of micro-data. Apart from the aggregation problem itself, a reasonable explanation for these differences may be that omitted factors cause a different bias in aggregate data than in micro-data. One obvious omitted factor in micro-studies is the interdependence of preferences. The fact that consumer preferences are influenced by the behaviour of others is well-documented in the psychological and sociological literature, yet it is almost universally ignored in micro-studies of consumer demand. Although preference interdependence is not accounted for explicitly in studies based on macro data, it can be said to play a role implicitly: to the extent that the consumption of the Jones' influences the consumption of the Browns and vice versa, these external effects show up in aggregate data since these reflect the consumption of both the Jones' and the Browns.},
	number = {406},
	journal = {The Economic Journal},
	author = {Alessie, Rob and Kapteyn, Arie},
	year = {1991},
	keywords = {Habit formation, interdependent preferences},
	pages = {404--419}
}

@article{akerlof_social_1997,
	title = {Social distance and social decisions},
	volume = {65},
	number = {5},
	journal = {Econometrica},
	author = {Akerlof, George A.},
	month = sep,
	year = {1997},
	pages = {1005--1027}
}

@article{adl_privacy_2012,
	title = {Privacy consensus in anonymization systems via game theory},
	volume = {7371},
	journal = {Proceeding of the 26th Annual IFIP WG Working Conference on Data and Applications Security and Privacy},
	author = {Adl, Rosa Karimi and Askari, Mina and Barker, Ken and Safavi-Naini, Reihaneh},
	year = {2012},
	keywords = {Formal Privacy, privacy, privacy protection, utility, game theory, data anonymization, k -anonymity, privacy parameter setting, trade-off},
	pages = {74--89}
}

@techreport{abowd_revisiting_2017,
	type = {Document},
	title = {Revisiting the economics of privacy: {Population} statistics and confidentiality protection as public goods},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/37/},
	number = {37},
	institution = {Labor Dynamics Institute, Cornell University},
	author = {Abowd, John M. and Schmutte, Ian M.},
	year = {2017},
	keywords = {Economics of Privacy}
}

@article{agrawal_privacy-preserving_2000,
	title = {Privacy-preserving data mining},
	volume = {29},
	issn = {0163-5808},
	url = {http://portal.acm.org/citation.cfm?doid=342009.335438},
	doi = {10.1145/342009.335438},
	abstract = {A fruitful direction for future data mining research will be the development of techniques that incorporate privacy concerns. Specifically, we address the following question. Since the primary task in data mining is the development of models about aggregated data, can we develop accurate models without access to precise information in individual data records? We consider the concrete case of building a decision-tree classifier from training data in which the values of individual records have been perturbed. The resulting data records look very different from the original records and the distribution of data values is also very different from the original distribution. While it is not possible to accurately estimate original values in individual data records, we propose a novel reconstruction procedure to accurately estimate the distribution of original data values. By using these reconstructed distributions, we are able to build classifiers whose accuracy is comparable to the accuracy of classifiers built with the original data.},
	number = {2},
	journal = {Proceedings of ACM SIGMOD International Conference on Management of Data},
	author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
	year = {2000},
	note = {ISBN: 1581132174},
	keywords = {Formal Privacy},
	pages = {439--450}
}

@article{acquisti_conditioning_2005,
	title = {Conditioning prices on purchase history},
	volume = {24},
	number = {3},
	journal = {Marketing Science},
	author = {Acquisti, Alessandro and Varian, Hal R.},
	year = {2005},
	keywords = {Economics of Privacy},
	pages = {367--381}
}

@article{acquisti_what_2013,
	title = {What {Is} {Privacy} {Worth}?},
	volume = {42},
	issn = {0047-2530},
	url = {http://www.journals.uchicago.edu/doi/10.1086/671754},
	doi = {10.1086/671754},
	number = {2},
	journal = {Journal of Legal Studies},
	author = {Acquisti, Alessandro and John, Leslie K. and Loewenstein, George},
	month = jun,
	year = {2013},
	keywords = {Economics of Privacy},
	pages = {249--274}
}

@article{abraham_distinguished_2005,
	title = {Distinguished {Lecture} on {Economics} in {Government}. {What} {We} {Don}'t {Know} {Could} {Hurt} {Us}: {Some} {Reflections} on the {Measurement} of {Economic} {Activity}},
	volume = {19},
	issn = {0895-3309},
	doi = {10.1257/089533005774357833},
	abstract = {Without accurate information on overall economic conditions, workers, firms, voters and policymakers are flying blind-or at least peering through thick fog. Since 1998, the Analytical Perspectives volume of each year's proposed budget for the U.S. government has included a section on "Strengthening Federal Statistics." The routine production of U.S. economic statistics dates back to the early part of the twentieth century. Sharp cyclical fluctuations in economic activity were a principal concern of citizens and policymakers during the early years of the twentieth century. Over the past decade, without a great deal of fanfare, the staff of the federal statistical agencies has worked hard to improve federal economic statistics and especially the economic statistics for the service sector.},
	number = {3},
	journal = {Journal of Economic Perspectives},
	author = {Abraham, Katharine G},
	year = {2005},
	keywords = {Official Statistics},
	pages = {3--18}
}

@techreport{abowd_revisiting_2015,
	type = {Document},
	title = {Revisiting the economics of privacy: {Population} statistics and confidentiality protection as public goods},
	url = {http://digitalcommons.ilr.cornell.edu/ldi/22/},
	number = {22},
	institution = {Labor Dynamics Institute, Cornell University},
	author = {Abowd, John M. and Schmutte, Ian M.},
	year = {2015},
	doi = {10.5281/zenodo.290231}
}

@article{abowd_modeling_2015,
	title = {Modeling endogenous mobility in wage determination},
	url = {https://www.tandfonline.com/doi/abs/10.1080/07350015.2017.1356727},
	doi = {10.2139/ssrn.2627186},
	journal = {Cornell University Labor Dynamics Institute Working Paper 23},
	author = {Abowd, John M. and McKinney, Kevin L. and Schmutte, Ian M.},
	year = {2015}
}

@techreport{abowd_computing_2002,
	title = {Computing person and firm effects using linked longitudinal employer-employee data},
	abstract = {In this paper we provide the exact formulas for the direct least squares estimation of statistical models that include both person and firm effects. We also provide an algorithm for determining the estimable functions of the person and firm effects (the identifiable effects). The computational techniques are also directly applicable to any linear two-factor analysis of covariance with two high-dimension non-orthogonal factors. We show that the application of the exact solution does not change the substantive conclusions about the relative importance of person and firm effects in the explanation of log real compensation; however, the correlation between person and firm effects is negative, not weakly positive, in the exact solution. We also provide guidance for using the methods developed in earlier work to obtain an accurate approximation.o},
	number = {TP-2002-06},
	institution = {LEHD, U.S. Census Bureau},
	author = {Abowd, John M. and Creecy, Robert H. and Kramarz, Francis},
	year = {2002}
}

@techreport{european_commission_special_2011,
	title = {{SPECIAL} {EUROBAROMETER} 359 {Attitudes} on {Data} {Protection} and {Electronic} {Identity} in the {European} {Union}},
	url = {http://ec.europa.eu/public_opinion/index_en.htm},
	abstract = {This report presents the results of the largest survey ever conducted regarding citizen's behaviours and attitudes concerning identity management, data protection and privacy.},
	institution = {European Commission},
	author = {{European Commission}},
	year = {2011},
	keywords = {value of privacy},
	pages = {330}
}

@article{abowd_high_1999,
	title = {High wage workers and high wage firms},
	volume = {67},
	abstract = {We study a longitudinal sample of over one million French workersfrom more than five hundred thousand employing firms. We decompose real total annual compensation per worker into components related to observable employee characteristics, personal heterogeneity, firm heterogeneity, and residual variation. Except for the residual, all components may be correlated in an arbitrary fashion. At the level of the individual, we find that person effects, especiallythose not related to observables like education, are a very important source of wage variation in France. Firm effects, while important, are not as important as person effects. At the level of firms, we find that enterprises that hire high-wage workers are more productive but not more profitable. They are also more capital and high-skilled employee intensive. Enterprises that pay higher wages, controlling for person effects, are more productive and more profitable. They are also more capital intensive but are not more high-skilled labor intensive. We find that person effects explain about 90\% of inter-industry wage differentials and about 75\% of the firm-size wage effect while firm effects explain relatively little of either differential.},
	number = {2},
	journal = {Econometrica},
	author = {Abowd, John M. and Kramarz, Francis and Margolis, David N.},
	year = {1999},
	pages = {251--333}
}

@article{abadi_deep_2016,
	title = {Deep {Learning} with {Differential} {Privacy}},
	url = {https://dl.acm.org/citation.cfm?doid=2976749.2978318},
	doi = {10.1145/2976749.2978318},
	journal = {ArXiv e-prints},
	author = {Abadi, M. and Chu, A. and Goodfellow, I. and Brendan McMahan, H. and Mironov, I. and Talwar, K. and Zhang, L.},
	year = {2016},
	note = {\_eprint: 1607.00133},
	keywords = {Formal Privacy, Computer Science - Cryptography and Security, Computer Science - Learning, Statistics - Machine Learning}
}

@techreport{us_census_bureau_2010-2014_2016,
	type = {[{Computer} file]},
	title = {2010-2014 {ACS} 5-year public use microdata samples ({PUMS})},
	url = {http://www2.census.gov/programs-surveys/acs/data/pums/2014/5-Year/},
	institution = {U.S. Census Bureau},
	author = {{U.S. Census Bureau}},
	month = aug,
	year = {2016},
	note = {Published: Computer file}
}

@techreport{minnesota_population_center_integrated_2016,
	type = {[{Computer} file]},
	title = {Integrated {Health} {Interview} {Series}: {Version} 6.21},
	url = {http://ihis.us/},
	institution = {University of Minnesota},
	author = {{Minnesota Population Center}},
	month = sep,
	year = {2016},
	note = {Published: Computer file}
}

@techreport{cornell_university_cornell_2014,
	type = {[{Computer} file]},
	title = {Cornell {National} {Social} {Survey} ({CNSS}) integrated. beta version},
	url = {https://www.openicpsr.org/openicpsr/project/100424/version/V2/view},
	institution = {Cornell Institute for Social and Economic Research and Survey Research Institute},
	author = {{Cornell University}},
	year = {2014},
	doi = {10.3886/E100424V2},
	note = {Backup Publisher: Cornell Institute for Social and Economic Research and Survey Research Institute}
}

@techreport{us_census_bureau_annual_2013,
	title = {Annual {Estimates} of the {Resident} {Population} for {Selected} {Age} {Groups} by {Sex} for the {United} {States}, {States}, {Counties}, and {Puerto} {Rico} {Commonwealth} and {Municipios}: {April} 1, 2010 to {July} 1, 2012},
	url = {https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=PEP_2012_PEPAGESEX&prodType=table},
	institution = {U.S. Census Bureau},
	author = {{U.S. Census Bureau}},
	month = jun,
	year = {2013}
}

@techreport{us_census_bureau_2015_2015,
	title = {2015 {American} {Community} {Survey} 1-{Year} {Estimates}},
	url = {https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_15_1YR_S2601A&prodType=table},
	institution = {U.S. Census Bureau},
	author = {{U.S. Census Bureau}},
	year = {2015}
}

@article{rubin_bayesian_1981,
	title = {The {Bayesian} {Bootstrap}},
	volume = {9},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2240875},
	abstract = {The Bayesian bootstrap is the Bayesian analogue of the bootstrap. Instead of simulating the sampling distribution of a statistic estimating a parameter, the Bayesian bootstrap simulates the posterior distribution of the parameter; operationally and inferentially the methods are quite similar. Because both methods of drawing inferences are based on somewhat peculiar model assumptions and the resulting inferences are generally sensitive to these assumptions, neither method should be applied without some consideration of the reasonableness of these model assumptions. In this sense, neither method is a true bootstrap procedure yielding inferences unaided by external assumptions.},
	number = {1},
	journal = {The Annals of Statistics},
	author = {Rubin, Donald B.},
	year = {1981},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {130--134}
}

@book{gas_natural_1985,
	address = {Washington, D.C.},
	title = {Natural {Gas} {Needs} in a {Changing} {Regulatory} {Environment}},
	publisher = {National Academy Press},
	author = {Gas, Panel on Statistics on Natural},
	year = {1985},
	doi = {10.17226/19272},
	note = {Section: III}
}

@article{chen_differentially_2016,
	title = {Differentially {Private} {Regression} {Diagnostics}},
	url = {https://ieeexplore.ieee.org/abstract/document/7837832},
	doi = {10.1109/icdm.2016.0019},
	journal = {2016 IEEE International Conference on Data Mining},
	author = {Chen, Yan and Machanavajjhala, Ashwin and Reiter, Jerome P. and Barientos, Andres F.},
	year = {2016},
	keywords = {formal privacy},
	pages = {81--90}
}

@article{moscarini_law_2002,
	title = {The law of large demand for information},
	volume = {70},
	issn = {1468-0262},
	url = {http://dx.doi.org/10.1111/j.1468-0262.2002.00442.x},
	doi = {10.1111/j.1468-0262.2002.00442.x},
	number = {6},
	journal = {Econometrica},
	author = {Moscarini, Giuseppe and Smith, Lones},
	year = {2002},
	note = {Publisher: Blackwell Publishers Ltd},
	keywords = {value of data, Bayesian decision theory, comparison of experiments, demand for information, large deviation theory, logarithmic demand, value of information},
	pages = {2351--2366}
}

@incollection{lee_how_2011,
	address = {Berlin, Heidelberg},
	title = {How much is enough? choosing ϵ for differential privacy},
	isbn = {978-3-642-24861-0},
	url = {http://dx.doi.org/10.1007/978-3-642-24861-0_22},
	booktitle = {Information {Security}: 14th {International} {Conference}, {ISC} 2011 and {Xi}'an, {China} and {October} 26-29, 2011. {Proceedings}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lee, Jaewoo and Clifton, Chris},
	editor = {Lai, Xuejia and Zhou, Jianying and Li, Hui},
	year = {2011},
	doi = {10.1007/978-3-642-24861-0_22},
	keywords = {formal privacy},
	pages = {325--340}
}

@article{buuren_fully_2006,
	title = {Fully conditional specification in multivariate imputation},
	volume = {76},
	doi = {10.1080/10629360600810434},
	abstract = {The use of the Gibbs sampler with fully conditionally specified models, where the distribution of each variable given the other variables is the starting point, has become a popular method to create imputations in incomplete multivariate data. The theoretical weakness of this approach is that the specified conditional densities can be incompatible, and therefore the stationary distribution to which the Gibbs sampler attempts to converge may not exist. This study investigates practical consequences of this problem by means of simulation. Missing data are created under four different missing data mechanisms. Attention is given to the statistical behavior under compatible and incompatible models. The results indicate that multiple imputation produces essentially unbiased estimates with appropriate coverage in the simple cases investigated, even for the incompatible models. Of particular interest is that these results were produced using only five Gibbs iterations starting from a simple draw from observed marginal distributions. It thus appears that, despite the theoretical weaknesses, the actual performance of conditional model specification for multivariate imputation can be quite good, and therefore deserves further study.},
	number = {12},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Buuren, S. Van and Brand, J. P. L. and Groothuis-Oudshoorn, C. G. M. and Rubin, D. B.},
	year = {2006},
	pages = {1049--1064}
}

@book{gelman_bayesian_2013,
	edition = {Third},
	series = {Chapman \& {Hall}/{CRC} {Texts} in {Statistical} {Science}},
	title = {Bayesian {Data} {Analysis}},
	isbn = {978-1-4398-4095-5},
	url = {https://books.google.com/books?id=ZXL6AQAAQBAJ},
	publisher = {Taylor \& Francis},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	year = {2013},
	lccn = {2013039507},
	keywords = {reference}
}

@techreport{mani_mine_2011,
	type = {{CAGE} {Online} {Working} {Paper} {Series}},
	title = {Mine, yours or ours? the efficiency of household investment decisions: an experimental approach},
	url = {http://EconPapers.repec.org/RePEc:cge:wacage:64},
	abstract = {We conduct an experiment to measure the relative importance of key factors that influence the efficiency of household investment decisions. We find that, both for men and women, their spouse's access to information does not affect efficiency. However, they are willing to sacrifice much efficiency for greater personal control over household income. Intriguingly, even when spouses' control over household income is exogenously assigned, inefficiency persists: As a wife's assigned share increases, husbands undercut their own income to reduce hers. This self-destructive and spiteful behavior is best explained by non-economic factors such as identity, seldom emphasized in mainstream household economic models.},
	institution = {Competitive Advantage in the Global Economy (CAGE)},
	author = {Mani, Anandi},
	year = {2011},
	keywords = {BARGAINING, EFFICIENCY, FAMILY, FIELD EXPERIMENT, IDENTITY, INTRA-HOUSEHOLD}
}

@techreport{jack_environmental_2017-1,
	title = {Environmental externalities and intrahousehold inefficiencies},
	url = {https://sites.tufts.edu/kjack/files/2017/08/Intrahh-water-draft-v15.pdf},
	institution = {Northwestern University},
	author = {Jack, Kelsey and Jayachandran, Seema and Rao, Sarojini},
	year = {2017}
}

@article{dwork_preserving_2014,
	title = {Preserving {Statistical} {Validity} in {Adaptive} {Data} {Analysis}},
	volume = {abs/1411.2664},
	url = {http://arxiv.org/abs/1411.2664},
	doi = {10.1145/2746539.2746580},
	journal = {CoRR},
	author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
	year = {2014},
	keywords = {value of privacy}
}

@article{breidert_review_2006,
	title = {A review of methods for measuring willingness-to-pay},
	volume = {2},
	number = {4},
	journal = {Innovative Marketing},
	author = {Breidert, Christoph and Hahsler, Michael and Reutterer, Thomas},
	year = {2006},
	keywords = {public goods},
	pages = {8--32}
}

@article{spencer_needed_1990,
	title = {Needed {Data} {Expenditure} for an {Ambiguous} {Decision} {Problem}},
	volume = {85},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10474981},
	doi = {10.1080/01621459.1990.10474981},
	abstract = {Abstract The amount worth spending to collect and analyze data depends on the uses of the data. We consider the determination of the optimal expenditure in some simple situations when only some aspects of the data use are known. In particular, we consider uses where an action is taken if a statistic exceeds a threshold τ?, which is unknown at the time of data planning and collection (though its value will not depend on the value of the statistic). We analyze the sensitivity of the optimal expenditure to the a priori uncertainty in τ?. For many decision problems, the optimal expenditure decreases with increasing uncertainty about τ?, but we identify some uses for which the optimal expenditure increases with increasing uncertainty about τ?. We also study the effects of other forms of ambiguity. Uncertainty about whether the data will be used typically decreases the optimal expenditure, as does uncertainty about the preferences represented in the decision making.},
	number = {412},
	journal = {Journal of the American Statistical Association},
	author = {Spencer, Bruce D. and Moses, Lincoln E.},
	year = {1990},
	note = {\_eprint: http://www.tandfonline.com/doi/pdf/10.1080/01621459.1990.10474981},
	keywords = {value of data},
	pages = {1099--1104}
}

@article{duchi_privacy_2014,
	title = {Privacy {Aware} {Learning}},
	volume = {61},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/2666468},
	doi = {10.1145/2666468},
	number = {6},
	journal = {J. ACM},
	author = {Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
	year = {2014},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {formal privacy, Differential privacy, machine learning, lower bounds, minimax convergence rates, saddle points},
	pages = {38:1--38:57}
}

@incollection{zhang_information-theoretic_2013,
	title = {Information-theoretic lower bounds for distributed statistical estimation with communication constraints},
	url = {http://papers.nips.cc/paper/4902-information-theoretic-lower-bounds-for-distributed-statistical-estimation-with-communication-constraints.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Zhang, Yuchen and Duchi, John and Jordan, Michael I. and Wainwright, Martin J.},
	year = {2013},
	pages = {2328--2336}
}

@techreport{conrey_census_2012,
	title = {Census {Barriers}, {Attitudes}, and {Motivators} {Survey} {II} {Final} {Report}},
	institution = {ICF Macro},
	author = {Conrey, Frederica R. and ZuWallack, Randal and Locke, Robynne},
	year = {2012},
	keywords = {official statistics}
}

@incollection{vadhan_complexity_2017,
	title = {The {Complexity} of {Differential} {Privacy}},
	isbn = {978-3-319-57048-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-57048-8_7},
	booktitle = {Tutorials on the {Foundations} of {Cryptography}: {Dedicated} to {Oded} {Goldreich}},
	publisher = {Springer International Publishing},
	author = {Vadhan, Salil},
	editor = {Lindell, Yehuda},
	year = {2017},
	doi = {10.1007/978-3-319-57048-8_7},
	keywords = {formal privacy},
	pages = {347--450}
}

@article{duchi_minimax_2016,
	title = {Minimax {Optimal} {Procedures} for {Locally} {Private} {Estimation}},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1389735},
	doi = {10.1080/01621459.2017.1389735},
	journal = {arXiv},
	author = {Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
	year = {2016},
	keywords = {formal privacy}
}

@article{cavallo_learning_2016,
	title = {Learning from {Potentially} {Biased} {Statistics}},
	url = {https://muse.jhu.edu/article/629296/summary},
	doi = {10.1353/eca.2016.0013},
	journal = {BPEA},
	author = {Cavallo, Alberto and Cruces, Guillermo and Perez-Truglia, Ricardo},
	year = {2016},
	pages = {59--108}
}

@article{kasiviswanathan_what_2011,
	title = {What {Can} {We} {Learn} {Privately}?},
	volume = {40},
	issn = {0097-5397},
	number = {3},
	journal = {SIAM J. Comput.},
	author = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
	month = jun,
	year = {2011},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {formal privacy},
	pages = {793--826}
}

@inproceedings{hardt_geometry_2010,
	series = {{STOC} '10},
	title = {On the {Geometry} of {Differential} {Privacy}},
	isbn = {978-1-4503-0050-6},
	doi = {10.1145/1806689.1806786},
	booktitle = {Proceedings of the {Forty}-second {ACM} {Symposium} on {Theory} of {Computing}},
	publisher = {ACM},
	author = {Hardt, Mortiz and Talwar, Kunal},
	year = {2010},
	keywords = {formal privacy},
	pages = {705--714}
}

@techreport{icpsr_disclosure_2020,
	type = {Document},
	title = {Disclosure {Risk} {Worksheet}},
	url = {http://hdl.handle.net/2027.42/156095},
	abstract = {A set of worksheets to assist in assessing and documenting potential disclosure risk to guide remediation steps.},
	number = {156095},
	urldate = {2020-08-21},
	institution = {University of Michigan},
	author = {{ICPSR}},
	month = aug,
	year = {2020},
	file = {Disclosure Risk Worksheet:/home/vilhuber/Zotero/storage/XIGQZ7J2/156095.html:text/html}
}

@misc{petters_data_2020,
	title = {Data {Privacy} {Guide}: {Definitions}, {Explanations} and {Legislation}},
	shorttitle = {Data {Privacy} {Guide}},
	url = {https://www.varonis.com/blog/data-privacy/},
	abstract = {Data privacy is all about keeping your data safe and private. In this guide you’ll learn why it’s important, and the best methods to achieve it.},
	language = {en},
	urldate = {2020-06-20},
	journal = {Inside Out Security},
	author = {Petters, Jeff},
	month = jan,
	year = {2020},
	note = {Library Catalog: www.varonis.com
Section: Data Security},
	file = {Snapshot:/home/vilhuber/Zotero/storage/4XVINRID/data-privacy.html:text/html}
}

@techreport{statistics_canada_confidentiality_2028,
	type = {Record},
	title = {Confidentiality {Classification} {Tool}},
	url = {https://open.canada.ca/ckan/en/dataset/2c910c37-c684-561e-9e0b-1d5bb6ca5fb9},
	language = {en},
	number = {2c910c37-c684-561e-9e0b-1d5bb6ca5fb9},
	urldate = {2020-08-21},
	institution = {Government of Canada},
	author = {{Statistics Canada}},
	month = aug,
	year = {2028},
	file = {Snapshot:/home/vilhuber/Zotero/storage/64WSNB4F/2c910c37-c684-561e-9e0b-1d5bb6ca5fb9.html:text/html}
}

@book{drechsler_synthetic_2011,
	address = {New York},
	series = {Lecture {Notes} in {Statistics}},
	title = {Synthetic {Datasets} for {Statistical} {Disclosure} {Control}: {Theory} and {Implementation}},
	isbn = {978-1-4614-0325-8},
	shorttitle = {Synthetic {Datasets} for {Statistical} {Disclosure} {Control}},
	url = {https://www.springer.com/gp/book/9781461403258},
	abstract = {The aim of this book is to give the reader a detailed introduction to the different approaches to generating multiply imputed synthetic datasets. It describes all approaches that have been developed so far, provides a brief history of synthetic datasets, and gives useful hints on how to deal with real data problems like nonresponse, skip patterns, or logical constraints. Each chapter is dedicated to one approach, first describing the general concept followed by a detailed application to a real dataset providing useful guidelines on how to implement the theory in practice. The discussed multiple imputation approaches include imputation for nonresponse, generating fully synthetic datasets, generating partially synthetic datasets, generating synthetic datasets when the original data is subject to nonresponse, and a two-stage imputation approach that helps to better address the omnipresent trade-off between analytical validity and the risk of disclosure.The book concludes with a glimpse into the future of synthetic datasets, discussing the potential benefits and possible obstacles of the approach and ways to address the concerns of data users and their understandable discomfort with using data that doesn't consist only of the originally collected values. The book is intended for researchers and practitioners alike. It helps the researcher to find the state of the art in synthetic data summarized in one book with full reference to all relevant papers on the topic. But it is also useful for the practitioner at the statistical agency who is considering the synthetic data approach for data dissemination in the future and wants to get familiar with the topic.},
	language = {en},
	urldate = {2020-08-18},
	publisher = {Springer-Verlag},
	author = {Drechsler, Jörg},
	year = {2011},
	doi = {10.1007/978-1-4614-0326-5},
	file = {Snapshot:/home/vilhuber/Zotero/storage/C4MMYFDJ/9781461403258.html:text/html}
}

@misc{templ_sdcmicro_2020,
	title = {{sdcMicro}: {Statistical} {Disclosure} {Control} {Methods} for {Anonymization} of {Data} and {Risk} {Estimation}},
	copyright = {GPL-2},
	shorttitle = {{sdcMicro}},
	url = {https://CRAN.R-project.org/package=sdcMicro},
	abstract = {Data from statistical agencies and other institutions are mostly confidential. This package (see also Templ, Kowarik and Meindl (2017) {\textless}doi:10.18637/jss.v067.i04{\textgreater}) can be used for the generation of anonymized (micro)data, i.e. for the creation of public- and scientific-use files. The theoretical basis for the methods implemented can be found in Templ (2017) {\textless}doi:10.1007/978-3-319-50272-4{\textgreater}. Various risk estimation and anonymisation methods are included. Note that the package includes a graphical user interface (Meindl and Templ, 2019 {\textless}doi:10.3390/a12090191{\textgreater}) that allows to use various methods of this package.},
	urldate = {2020-08-17},
	author = {Templ, Matthias and Meindl, Bernhard and Kowarik, Alexander},
	month = feb,
	year = {2020}
}

@article{templ_statistical_2015,
	title = {Statistical {Disclosure} {Control} for {Micro}-{Data} {Using} the {R} {Package} {sdcMicro}},
	volume = {67},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v67/i04/},
	doi = {10.18637/jss.v067.i04},
	language = {en},
	number = {4},
	urldate = {2020-08-17},
	journal = {Journal of Statistical Software},
	author = {Templ, Matthias and Kowarik, Alexander and Meindl, Bernhard},
	year = {2015},
	file = {Templ et al_2015_Statistical Disclosure Control for Micro-Data Using the iR-i Package.pdf:/home/vilhuber/Zotero/storage/44LBMVFM/Templ et al_2015_Statistical Disclosure Control for Micro-Data Using the iR-i Package.pdf:application/pdf}
}

@misc{hundepool_-argus_2018,
	title = {μ-{ARGUS}},
	url = {http://research.cbs.nl/casc/mu.htm},
	urldate = {2020-08-17},
	author = {Hundepool, Anco and Ramaswamy, Ramya},
	month = mar,
	year = {2018},
	file = {μ-ARGUS:/home/vilhuber/Zotero/storage/S2PH3GWA/mu.html:text/html}
}

@misc{de_wolf_-argus_2018,
	title = {τ-{ARGUS}},
	url = {http://research.cbs.nl/casc/tau.htm},
	urldate = {2020-08-17},
	author = {De Wolf, Peter-Paul},
	month = aug,
	year = {2018},
	file = {τ-ARGUS:/home/vilhuber/Zotero/storage/IRMF5EKE/tau.html:text/html}
}

@inproceedings{hundepool_argus_1998,
	address = {Heidelberg},
	title = {{ARGUS}, {Software} {Packages} for {Statistical} {Disclosure} {Control}},
	isbn = {978-3-662-01131-7},
	doi = {10.1007/978-3-662-01131-7_45},
	abstract = {The paper describes two related software packages for producing safe data: µ-ARGUS for microdata and τ-ARGUS for tabular data.},
	language = {en},
	booktitle = {{COMPSTAT}},
	publisher = {Physica-Verlag HD},
	author = {Hundepool, Anco and Willenborg, Leon},
	editor = {Payne, Roger and Green, Peter},
	year = {1998},
	keywords = {Microdata, Software, Statistical disclosure control, tables},
	pages = {341--345}
}

@misc{templ_simpop_2019,
	title = {{simPop}: {Simulation} of {Synthetic} {Populations} for {Survey} {Data} {Considering} {Auxiliary} {Information}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {{simPop}},
	url = {https://CRAN.R-project.org/package=simPop},
	abstract = {Tools and methods to simulate populations for surveys based on auxiliary data. The tools include model-based methods, calibration and combinatorial optimization algorithms. The package was developed with support of the International Household Survey Network, DFID Trust Fund TF011722 and funds from the World bank.},
	urldate = {2020-08-17},
	author = {Templ, Matthias and Kowarik, Alexander and Meindl, Bernhard and Alfons, Andreas and Ribatet, Mathieu and Gussenbauer, Johannes},
	month = jul,
	year = {2019},
	keywords = {OfficialStatistics}
}

@article{nowok_synthpop_2016,
	title = {synthpop: {Bespoke} {Creation} of {Synthetic} {Data} in {R}},
	volume = {74},
	copyright = {Copyright (c) 2016 Beata Nowok, Gillian M. Raab, Chris Dibben},
	issn = {1548-7660},
	shorttitle = {synthpop},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v074i11},
	doi = {10.18637/jss.v074.i11},
	language = {en},
	number = {1},
	urldate = {2020-08-17},
	journal = {Journal of Statistical Software},
	author = {Nowok, Beata and Raab, Gillian M. and Dibben, Chris},
	month = oct,
	year = {2016},
	note = {Number: 1},
	keywords = {CART, disclosure control, R, synthetic data, UK longitudinal studies},
	pages = {1--26},
	file = {Nowok et al_2016_synthpop.pdf:/home/vilhuber/Zotero/storage/85C8W84T/Nowok et al_2016_synthpop.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/UY7CGEXC/v074i11.html:text/html}
}

@article{raab_practical_2016,
	title = {Practical {Data} {Synthesis} for {Large} {Samples}},
	volume = {7},
	copyright = {Copyright (c) 2016-2017 the authors},
	issn = {2575-8527},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/407},
	doi = {10.29012/jpc.v7i3.407},
	language = {en},
	number = {3},
	urldate = {2020-08-17},
	journal = {Journal of Privacy and Confidentiality},
	author = {Raab, Gillian M. and Nowok, Beata and Dibben, Chris},
	year = {2016},
	note = {Number: 3},
	pages = {67--97},
	file = {Raab et al_2016_Practical Data Synthesis for Large Samples.pdf:/home/vilhuber/Zotero/storage/78I2VQI4/Raab et al_2016_Practical Data Synthesis for Large Samples.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/K6X8MDK9/407.html:text/html}
}

@article{cameron_practitioners_2015,
	title = {A {Practitioner}’s {Guide} to {Cluster}-{Robust} {Inference}},
	volume = {50},
	issn = {0022-166X, 1548-8004},
	url = {http://jhr.uwpress.org/content/50/2/317},
	doi = {10.3368/jhr.50.2.317},
	abstract = {We consider statistical inference for regression when data are grouped into clusters, with regression model errors independent across clusters but correlated within clusters. Examples include data on individuals with clustering on village or region or other category such as industry, and state-year differences-in-differences studies with clustering on state. In such settings, default standard errors can greatly overstate estimator precision. Instead, if the number of clusters is large, statistical inference after OLS should be based on cluster-robust standard errors. We outline the basic method as well as many complications that can arise in practice. These include cluster-specific fixed effects, few clusters, multiway clustering, and estimators other than OLS.},
	language = {en},
	number = {2},
	urldate = {2020-08-17},
	journal = {Journal of Human Resources},
	author = {Cameron, A. Colin and Miller, Douglas L.},
	month = mar,
	year = {2015},
	note = {Publisher: University of Wisconsin Press},
	pages = {317--372},
	file = {Cameron_Miller_2015_A Practitioner’s Guide to Cluster-Robust Inference.pdf:/home/vilhuber/Zotero/storage/D8JXHPQH/Cameron_Miller_2015_A Practitioner’s Guide to Cluster-Robust Inference.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/ZV2QIXC9/317.html:text/html}
}

@article{moulton_random_1986,
	title = {Random group effects and the precision of regression estimates},
	volume = {32},
	issn = {0304-4076},
	url = {http://www.sciencedirect.com/science/article/pii/0304407686900217},
	doi = {10.1016/0304-4076(86)90021-7},
	abstract = {When explanatory variable data in a regression model are drawn from a population with grouped structure, the regression errors are often correlated within groups. Error component and random coefficient regression models are considered as models of the intraclass correlation. This paper analyzes several empirical examples to investigate the applicability of random effects models and the consequences of inappropriately using ordinary least squares (OLS) estimation in the presence of random group effects. The principal findings are that the assumption of independent errors is usually incorrect and the unadjusted OLS standard errors often have a substantial downward bias, suggesting a considerable danger of spurious regression.},
	language = {en},
	number = {3},
	urldate = {2020-08-17},
	journal = {Journal of Econometrics},
	author = {Moulton, Brent R.},
	month = aug,
	year = {1986},
	pages = {385--397},
	file = {ScienceDirect Snapshot:/home/vilhuber/Zotero/storage/GQXJ4AN6/0304407686900217.html:text/html}
}

@inproceedings{kennickell_multiple_1998,
	title = {Multiple imputation in the {Survey} of {Consumer} {Finances}},
	url = {https://www.federalreserve. gov/econresdata/scf/files/impute98.pdf},
	abstract = {Background The SCF is a triennial survey conducted by the Board of Governors of the Federal Reserve System in cooperation with the Statistics of Income Division (SOI) of the IRS.'Data for the survey were collected by the Survey Research Center at the University of ...},
	booktitle = {Proceedings of the {Section} on {Survey} {Research}},
	author = {Kennickell, A B},
	year = {1998}
}

@techreport{abowd_final_2006,
	title = {Final {Report} to the {Social} {Security} {Administration} on the {SIPP}/{SSA}/{IRS} {Public} {Use} {File} {Project}},
	url = {http://hdl.handle.net/1813/43929},
	number = {1813/43929},
	institution = {U.S. Census Bureau},
	author = {Abowd, John M and Stinson, Martha and Benedetto, Gary},
	year = {2006},
	keywords = {Linked admin}
}

@misc{hawala_disclosure_2009,
	type = {presentation},
	title = {Disclosure avoidance for group quarters in the {American} {Community} {Survey}: {Details} of the synthetic data method},
	shorttitle = {Disclosure avoidance for group quarters in the {American} {Community} {Survey}},
	url = {https://ecommons.cornell.edu/handle/1813/47676},
	abstract = {A workshop that brought together university-based researchers, members of the international official statistical community, and other interested user communities was held on July 31, 2009, the Friday before the 2009 Joint Statistical Meetings in Washington DC at the U.S. Census Bureau's Headquarters building in Suitland, MD. The purpose of the workshop was to discuss and critique newly created public-use micro-data files that are based on the concepts of “synthetic data” and “partially synthetic data.”},
	language = {en\_US},
	urldate = {2020-08-17},
	author = {Hawala, Sam and Rodriguez, Rolando},
	month = jul,
	year = {2009},
	note = {Accepted: 2017-04-03T22:45:55Z},
	file = {Hawala_Rodriguez_2009_Disclosure avoidance for group quarters in the American Community Survey.pdf:/home/vilhuber/Zotero/storage/IJBDY6KJ/Hawala_Rodriguez_2009_Disclosure avoidance for group quarters in the American Community Survey.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/NC6UJJWU/47676.html:text/html}
}

@incollection{little_statistical_2004,
	title = {Statistical disclosure techniques based on multiple imputation},
	url = {https://doi.org/10.1002/0470090456.ch13},
	booktitle = {Applied {Bayesian} modeling and causal inference from incomplete-data perspectives},
	publisher = {Wiley},
	author = {Little, Roderick J A and Liu, Fang and Raghunathan, Trivellore E},
	editor = {Gelman, Andrew and Meng, Xiao Li},
	year = {2004},
	keywords = {SDL, statistical disclosure limitation, Libraries, Bayesian Belief Networks, Bayesian inference, Bayesian modeling, Bayesian statistics, causal inference, Decision making, graphical models, incomplete observations, Inference, modeling, Probabilities, probability, Statistical, statistics},
	pages = {141--152}
}

@article{raghunathan_multiple_2003,
	title = {Multiple {Imputation} for {Statistical} {Disclosure} {Limitation}},
	volume = {19},
	url = {http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/multiple-imputation-for-statistical-disclosure-limitation.pdf},
	number = {1},
	journal = {Journal of Official Statistics},
	author = {Raghunathan, Trivellore E and Reiter, Jerry P. and Rubin, Donald B},
	year = {2003},
	keywords = {Linked admin}
}

@article{rubin_discussion_1993,
	title = {Discussion: {Statistical} disclosure limitation},
	volume = {9},
	url = {http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/discussion-statistical-disclosure-limitation2.pdf},
	abstract = {Issues of honoring conﬁdentiality constraints when releasing microdata have always been important but appear to be becoming even more critical. Although there exists interesting work on masking data to preserve conﬁdentiality, the valid analysis of specially masked ...},
	number = {2},
	journal = {Journal of Official Statistics},
	author = {Rubin, Donald B},
	year = {1993},
	keywords = {Linked admin},
	pages = {461--468}
}

@article{little_statistical_1993,
	title = {Statistical analysis of masked data},
	volume = {9},
	url = {http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/statistical-analysis-of-masked-data.pdf},
	abstract = {Abstract: A model-based likelihood theory is presented for the analysis of data masked for conﬁdentiality purposes. The theory builds on frameworks for missing data and treatment assignment, and a theory for coarsened data. It distinguishes a model for the masking ...},
	number = {2},
	journal = {Journal of Official Statistics},
	author = {Little, Roderick JA},
	year = {1993},
	keywords = {Linked admin},
	pages = {407--426}
}

@book{duncan_statistical_2011,
	address = {New York},
	series = {Statistics for {Social} and {Behavioral} {Sciences}},
	title = {Statistical confidentiality: principles and practice},
	isbn = {978-1-4419-7802-8},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1751-5823.2012.00196_11.x},
	publisher = {Springer-Verlag},
	author = {Duncan, George T. and Elliot, Mark and Salazar-González, Juan-José},
	year = {2011},
	doi = {10.1111/j.1751-5823.2012.00196_11.x},
	keywords = {SDL, statistical disclosure limitation, Linked admin}
}

@book{duncan_private_1993,
	title = {Private {Lives} and {Public} {Policies}: {Confidentiality} and {Accessibility} of {Government} {Statistics}},
	isbn = {978-0-309-08651-6},
	shorttitle = {Private {Lives} and {Public} {Policies}},
	url = {https://www.nap.edu/catalog/2122/private-lives-and-public-policies-confidentiality-and-accessibility-of-government},
	abstract = {Americans are increasingly concerned about the privacy of personal data--yet we demand more and more information for public decision making. This volume explores the seeming conflicts between privacy and data access, an issue of concern to federal statistical agencies collecting the data, research organizations using the data, and individuals providing the data.},
	language = {en},
	urldate = {2020-07-17},
	publisher = {National Academies Press},
	editor = {Duncan, George T. and Jabine, Thomas B. and de Wolf, Virginia A.},
	year = {1993},
	doi = {10.17226/2122},
	keywords = {SDL, statistical disclosure limitation},
	file = {Snapshot:/home/vilhuber/Zotero/storage/EN2Z4PZV/private-lives-and-public-policies-confidentiality-and-accessibility-of-government.html:text/html}
}

@article{burkhauser_estimating_2011,
	title = {Estimating trends in {US} income inequality using the {Current} {Population} {Survey}: the importance of controlling for censoring},
	volume = {9},
	issn = {1569-1721, 1573-8701},
	shorttitle = {Estimating trends in {US} income inequality using the {Current} {Population} {Survey}},
	url = {http://link.springer.com/10.1007/s10888-010-9131-6},
	doi = {10.1007/s10888-010-9131-6},
	language = {en},
	number = {3},
	urldate = {2020-08-09},
	journal = {The Journal of Economic Inequality},
	author = {Burkhauser, Richard V. and Feng, Shuaizhang and Jenkins, Stephen P. and Larrimore, Jeff},
	month = sep,
	year = {2011},
	pages = {393--415},
	file = {Burkhauser et al_2011_Estimating trends in US income inequality using the Current Population Survey.pdf:/home/vilhuber/Zotero/storage/MTEACIZY/Burkhauser et al_2011_Estimating trends in US income inequality using the Current Population Survey.pdf:application/pdf}
}

@misc{health_and_retirement_study_disclosure_nodate,
	title = {Disclosure {Limitation} {Review}},
	url = {https://hrs.isr.umich.edu/data-products/restricted-data/disclosure-limitation-review},
	urldate = {2020-08-09},
	author = {{Health and Retirement Study}},
	file = {Disclosure Limitation Review | Health and Retirement Study:/home/vilhuber/Zotero/storage/VHHAZQKB/disclosure-limitation-review.html:text/html}
}

@misc{world_bank_dime_nodate,
	title = {{DIME} {Wiki}: {De}-identification},
	url = {https://dimewiki.worldbank.org/wiki/De-identification},
	urldate = {2020-08-08},
	author = {{World Bank}}
}

@techreport{kopper_j-pal_2020,
	title = {J-{PAL} {Guide} to de-identifying data},
	url = {https://www.povertyactionlab.org/sites/default/files/research-resources/J-PAL-guide-to-deidentifying-data.pdf},
	abstract = {Researchers who plan to publish data on human subjects should take careful steps to protect the confidentiality of study participants through data de-identification—a process that reduces the risk of re-identifying individuals within a given dataset. This guide provides further details on the deidentification process, including various procedures for de-identifying a dataset, a list of common identifiers that need to be reviewed, and sample code that can be used to de-identify data intended for publication. It is intended to be used alongside the accompanying Guide to Publishing Research Data.},
	language = {en},
	urldate = {2020-08-08},
	institution = {J-PAL Global},
	author = {Kopper, Sarah and Sautmann, Anja and Turitto, James},
	month = jan,
	year = {2020},
	pages = {12},
	file = {Kopper et al. - J-PAL GUIDE TO DE-IDENTIFYING DATA.pdf:/home/vilhuber/Zotero/storage/FWY9IET2/Kopper et al. - J-PAL GUIDE TO DE-IDENTIFYING DATA.pdf:application/pdf}
}

@misc{black_6_2020,
	title = {6 {Months} {Until} {Brazil}’s {LGPD} {Takes} {Effect} – {Are} {You} {Ready}?},
	url = {https://www.natlawreview.com/article/6-months-until-brazil-s-lgpd-takes-effect-are-you-ready},
	abstract = {In August 2018, Brazil took a significant step by passing comprehensive data protection legislation: the\&amp;nbsp;General Data Protection Law\&amp;nbsp;(Lei Geral de Prote\&amp;ccedil;\&amp;atilde;o de Dados Pessoais\&amp;nb},
	language = {en},
	urldate = {2020-08-08},
	journal = {The National Law Review},
	author = {Black, Kate and Ramos, Gretchen A. and Biscardi, Giovanni},
	month = mar,
	year = {2020},
	file = {Snapshot:/home/vilhuber/Zotero/storage/FLV4R3XM/6-months-until-brazil-s-lgpd-takes-effect-are-you-ready.html:text/html}
}

@misc{panakal_indias_2019,
	title = {India’s {Proposed} {Privacy} {Law} {Allows} {Government} {Access} and {Some} {Data} {Localization}},
	url = {https://www.natlawreview.com/article/india-s-proposed-privacy-law-allows-government-access-and-some-data-localization},
	abstract = {The world's largest democracy has Constitutional privacy protection, but no omnibus privacy law. The most prominent proposed privacy act looks like GDPR, with special data access rights reserved},
	language = {en},
	urldate = {2020-06-20},
	journal = {The National Law Review},
	author = {Panakal, Dominic Dhil},
	month = dec,
	year = {2019},
	note = {Library Catalog: www.natlawreview.com},
	file = {Snapshot:/home/vilhuber/Zotero/storage/2RAWBEIF/india-s-proposed-privacy-law-allows-government-access-and-some-data-localization.html:text/html}
}

@article{chetty_practical_2019,
	title = {A {Practical} {Method} to {Reduce} {Privacy} {Loss} {When} {Disclosing} {Statistics} {Based} on {Small} {Samples}},
	volume = {9},
	copyright = {Copyright (c) 2019 Raj Chetty, John N Friedman},
	issn = {2575-8527},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/716},
	doi = {10.29012/jpc.716},
	language = {en},
	number = {2},
	urldate = {2020-08-08},
	journal = {Journal of Privacy and Confidentiality},
	author = {Chetty, Raj and Friedman, John N.},
	month = oct,
	year = {2019},
	note = {Number: 2},
	keywords = {Differential Privacy, Administrative Data},
	file = {Chetty_Friedman_2019_A Practical Method to Reduce Privacy Loss When Disclosing Statistics Based on.pdf:/home/vilhuber/Zotero/storage/JSNYRU9W/Chetty_Friedman_2019_A Practical Method to Reduce Privacy Loss When Disclosing Statistics Based on.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/XCY4G56D/716.html:text/html}
}

@article{shlomo_assessing_2010,
	title = {Assessing the protection provided by misclassification-based disclosure limitation methods for survey microdata},
	volume = {4},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/euclid.aoas/1287409374},
	doi = {10.1214/09-AOAS317},
	abstract = {Government statistical agencies often apply statistical disclosure limitation techniques to survey microdata to protect the confidentiality of respondents. There is a need for valid and practical ways to assess the protection provided. This paper develops some simple methods for disclosure limitation techniques which perturb the values of categorical identifying variables. The methods are applied in numerical experiments based upon census data from the United Kingdom which are subject to two perturbation techniques: data swapping (random and targeted) and the post randomization method. Some simplifying approximations to the measure of risk are found to work well in capturing the impacts of these techniques. These approximations provide simple extensions of existing risk assessment methods based upon Poisson log-linear models. A numerical experiment is also undertaken to assess the impact of multivariate misclassification with an increasing number of identifying variables. It is found that the misclassification dominates the usual monotone increasing relationship between this number and risk so that the risk eventually declines, implying less sensitivity of risk to choice of identifying variables. The methods developed in this paper may also be used to obtain more realistic assessments of risk which take account of the kinds of measurement and other nonsampling errors commonly arising in surveys.},
	language = {EN},
	number = {3},
	urldate = {2020-08-08},
	journal = {Annals of Applied Statistics},
	author = {Shlomo, Natalie and Skinner, Chris},
	month = sep,
	year = {2010},
	mrnumber = {MR2758329},
	zmnumber = {1202.62011},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {measurement error, data swapping, Disclosure risk, identification risk, log linear model, post randomization method},
	pages = {1291--1310},
	file = {Shlomo_Skinner_2010_Assessing the protection provided by misclassification-based disclosure.pdf:/home/vilhuber/Zotero/storage/LEQYEATY/Shlomo_Skinner_2010_Assessing the protection provided by misclassification-based disclosure.pdf:application/pdf;Snapshot:/home/vilhuber/Zotero/storage/ET8XHQQF/1287409374.html:text/html}
}

@techreport{abowd_dynamically_2012,
	title = {Dynamically {Consistent} {Noise} {Infusion} and {Partially} {Synthetic} {Data} as {Confidentiality} {Protection} {Measures} for {Related} {Time} {Series}},
	url = {http://dx.doi.org/10.2139/ssrn.2159800},
	abstract = {The Census Bureau's Quarterly Workforce Indicators (QWI) provide detailed quarterly statistics on employment measures such as worker and job flows, tabulated by},
	number = {12-13},
	institution = {U.S. Census Bureau, Center for Economic Studies},
	author = {Abowd, John M and Gittings, R Kaj Kaj and McKinney, Kevin L and Stephens, Bryce and Vilhuber, Lars and Woodcock, Simon D},
	month = oct,
	year = {2012},
	doi = {10.2139/ssrn.2159800},
	keywords = {statistical disclosure limitation, Linked admin, synthetic data, Lars bib, local labor, noise infusion, time-series}
}

@incollection{abowd_lehd_2009,
	title = {The {LEHD} {Infrastructure} {Files} and the {Creation} of the {Quarterly} {Workforce} {Indicators}},
	isbn = {978-0-226-17256-9},
	booktitle = {Producer {Dynamics}: {New} {Evidence} from {Micro} {Data}},
	publisher = {University of Chicago Press},
	author = {Abowd, J M and Stephens, B E and Vilhuber, L and Andersson, F and McKinney, K L and Roemer, M and Woodcock, S D},
	editor = {{T. Dunne and J B Jensen and M J Roberts}},
	year = {2009},
	keywords = {Linked admin}
}

@article{evans_using_1998,
	title = {Using {Noise} for {Disclosure} {Limitation} of {Establishment} {Tabular} {Data}},
	volume = {14},
	issn = {0282-423X},
	number = {4},
	journal = {Journal of Official Statistics},
	author = {Evans, Timothy and Zayatz, Laura and Slanta, John},
	month = dec,
	year = {1998},
	keywords = {Linked admin, admindata.bib},
	pages = {537--551}
}

@article{dwork_fienberg_2018,
	title = {The {Fienberg} {Problem}: {How} to {Allow} {Human} {Interactive} {Data} {Analysis} in the {Age} of {Differential} {Privacy}},
	volume = {8},
	issn = {2575-8527},
	shorttitle = {The {Fienberg} {Problem}},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/687},
	doi = {10.29012/jpc.687},
	abstract = {Differential Privacy is a popular technology for privacy-preserving analysis of large datasets. DP is powerful, but it requires that the analyst interact with data only through a special interface; in particular, the analyst does not see raw data, an uncomfortable situation for anyone trained in classical statistical data analysis. In this note we discuss the (overly) simple problem of allowing a  trusted analyst to choose an ``"interesting" statistic for popular release (the actual computation of the chosen statistic will be carried out in a differentially private way).},
	number = {1},
	urldate = {2020-07-17},
	journal = {Journal of Privacy and Confidentiality},
	author = {Dwork, Cynthia and Ullman, Jonathan},
	month = dec,
	year = {2018},
	file = {Dwork_Ullman_2018_The Fienberg Problem.pdf:/home/vilhuber/Zotero/storage/HMVFA92Z/Dwork_Ullman_2018_The Fienberg Problem.pdf:application/pdf}
}

@techreport{auxier_americans_2019,
	title = {Americans and {Privacy}: {Concerned}, {Confused} and {Feeling} {Lack} of {Control} {Over} {Their} {Personal} {Information}},
	shorttitle = {Americans and {Privacy}},
	url = {https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/},
	abstract = {Majorities of U.S. adults believe their personal data is less secure now, that data collection poses more risks than benefits, and that it is not possible to go through daily life without being tracked.},
	language = {en-US},
	urldate = {2020-07-17},
	institution = {Pew Research Center},
	author = {Auxier, Brooke and Rainie, Lee and Anderson, Monica and Perrin, Andrew and Kumar, Madhu and Turner, Erica},
	month = nov,
	year = {2019}
}

@article{gaboardi_dual_2014,
	title = {Dual {Query} : {Practical} {Private} {Query} {Release} for {High} {Dimensional} {Data}},
	volume = {abs/1402.1526},
	url = {http://arxiv.org/abs/1402.1526},
	doi = {10.29012/jpc.v7i2.650},
	abstract = {We present a practical, differentially private algorithm for answering a large number of queries on high dimensional datasets. Like all algorithms for this task, ours necessarily has worst-case complexity exponential in the dimension of the data. However, our algorithm packages the computationally hard step into a concisely defined integer program, which can be solved non-privately using standard solvers. We prove accuracy and privacy theorems for our algorithm, and then demonstrate experimentally that our algorithm performs well in practice. For example, our algorithm can efficiently and accurately answer millions of queries on the Netflix dataset, which has over 17,000 attributes; this is an improvement on the state of the art by multiple orders of magnitude.},
	journal = {CoRR},
	author = {Gaboardi, Marco and Arias, Emilio Jesús Gallego and Hsu, Justin and Roth, Aaron and Wu, Zhiwei Steven},
	year = {2014},
	keywords = {formal privacy}
}

@article{pai_privacy_2013,
	title = {Privacy and {Mechanism} {Design}},
	issn = {1551-9031},
	url = {http://arxiv.org/abs/1306.2083$\backslash$nhttp://www.arxiv.org/pdf/1306.2083.pdf},
	doi = {10.1145/2509013.2509016},
	abstract = {This paper is a survey of recent work at the intersection of mechanism design and privacy. The connection is a natural one, but its study has been jump-started in recent years by the advent of differential privacy, which provides a rigorous, quantitative way of reasoning about the costs that an agent might experience because of the loss of his privacy. Here, we survey several facets of this study, and differential privacy plays a role in more than one way. Of course, it provides us a basis for modeling agent costs for privacy, which is essential if we are to attempt mechanism design in a setting in which agents have preferences for privacy. It also provides a toolkit for controlling those costs. However, perhaps more surprisingly, it provides a powerful toolkit for controlling the stability of mechanisms in general, which yields a set of tools for designing novel mechanisms even in economic settings completely unrelated to privacy.},
	number = {1306.2083},
	journal = {ArXiv},
	author = {Pai, Mallesh M. and Roth, Aaron},
	year = {2013},
	note = {\_eprint: arXiv:1306.2083v1},
	keywords = {economics of privacy, privacy, mechanism design},
	pages = {1--21}
}

@article{mckenna_optimizing_2018,
	title = {Optimizing error of high-dimensional statistical queries under differential privacy},
	volume = {11},
	url = {https://dl.acm.org/citation.cfm?id=3242939},
	doi = {10.14778/3231751.3231769},
	number = {10},
	journal = {Proceedings of the VLDB Endowment},
	author = {McKenna, Ryan and Miklau, Gerome and Hay, Michael and Machanavajjhala, Ashwin},
	year = {2018},
	keywords = {formal privacy}
}

@article{manski_identification_1993,
	title = {Identification of {Endogenous} {Social} {Effects}: {The} {Reflection} {Problem}},
	volume = {60},
	issn = {0034-6527},
	url = {http://restud.oxfordjournals.org/lookup/doi/10.2307/2298123},
	doi = {10.2307/2298123},
	abstract = {This paper examines the reflection problem that arises when a researcher observing the distribution of behaviour in a population tries to infer whether the average behaviour in some group influences the behaviour of the individuals that comprise the group. It is found that inference is not possible unless the researcher has prior information specifying the composition of reference groups. If this information is available, the prospects for inference depend critically on the population relationship between the variables defining reference groups and those directly affecting outcomes. Inference is difficult to impossible if these variables are functionally dependent or are statistically independent. The prospects are better if the variables defining reference groups and those directly affecting outcomes are moderately related in the population.},
	number = {3},
	journal = {The Review of Economic Studies},
	author = {Manski, Charles F.},
	year = {1993},
	pmid = {1302665},
	pages = {531}
}

@article{machanavajjhala_designing_2015,
	title = {Designing {Statistical} {Privacy} for {Your} {Data}},
	volume = {58},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2660766},
	doi = {10.1145/2660766},
	abstract = {IN 2006, AOL RELEASED a file containing search queries posed by many of its users. The user names were replaced with random hashes, though the query text was not modified. It turns out some users had queried their own names, or " vanity queries, " and nearby locations like local businesses. As a result, it was not difficult for reporters to find and interview an AOL user 1 then learn personal details about her (such as age and medical history) from the rest of her queries. Could AOL have protected all its users by also replacing each word in the search queries with a random hash? Probably not; Kumar et al. 27 showed that word co-occurrence patterns would provide clues about which hashes correspond to which words, thus allowing an attacker to partially reconstruct the original queries. Such privacy concerns are not unique to Web-search data. Businesses, government agencies, and research groups routine-ly collect data about individuals and need to release some form of it for a va-riety of reasons (such as meeting legal requirements, satisfying business ob-ligations, and encouraging reproduc-ible scientific research). However, they must also protect sensitive informa-tion, including identities, facts about individuals, trade secrets, and other application-specific considerations, in the raw data. The privacy challenge is that sensitive information can be inferred in many ways from the data releases. Homer et al. 20},
	number = {3},
	journal = {Communications of the ACM},
	author = {Machanavajjhala, Ashwin and Kifer, Daniel},
	year = {2015},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {primary, formal privacy},
	pages = {58--67}
}

@article{antoun_comparisons_2016,
	title = {Comparisons of {Online} {Recruitment} {Strategies} for {Convenience} {Samples}},
	volume = {28},
	url = {http://dx.doi.org/10.1177/1525822X15603149},
	doi = {10.1177/1525822X15603149},
	abstract = {The rise of social media websites (e.g., Facebook) and online services such as Google AdWords and Amazon Mechanical Turk (MTurk) offers new opportunities for researchers to recruit study participants. Although researchers have started to use these emerging methods, little is known about how they perform in terms of cost efficiency and, more importantly, the types of people that they ultimately recruit. Here, we report findings about the performance of four online sources for recruiting iPhone users to participate in a web survey. The findings reveal very different performances between two types of strategies: those that "pull in" online users actively looking for paid work (MTurk workers and Craigslist users) and those that "push out" a recruiting ad to online users engaged in other, unrelated online activities (Google AdWords and Facebook). The pull-method recruits were more cost efficient and committed to the survey task, while the push-method recruits were more demographically diverse.},
	number = {3},
	journal = {Field Methods},
	author = {Antoun, Christopher and Zhang, Chan and Conrad, Frederick G. and Schober, Michael F.},
	year = {2016},
	note = {\_eprint: http://dx.doi.org/10.1177/1525822X15603149},
	pages = {231--246}
}

@techreport{nissim_differential_2017,
	address = {Cambridge, MA},
	type = {primer},
	title = {Differential {Privacy}: {A} {Primer} for a {Non}-technical {Audience} ({Updated} {Version})},
	url = {https://privacytools.seas.harvard.edu/files/privacytools/files/pedagogical-document-dp_new.pdf},
	abstract = {This document is a primer on differential privacy, which is a formal mathematical framework for guaranteeing privacy protection when analyzing or releasing statistical data. Recently emerging from the theoretical computer science literature, differential privacy is now in initial stages of implementation and use in various academic, industry, and government settings. Using intuitive illustrations and limited mathematical formalism, this document provides an introduction to differential privacy for non-technical practitioners, who are increasingly tasked with making decisions with respect to differential privacy as it grows more widespread in use. In particular, the examples in this document illustrate ways in which social scientists can conceptualize the guarantees provided by differential privacy with respect to the decisions they make when managing personal data about research subjects and informing them about the privacy protection they will be afforded.\&nbsp;\&nbsp;},
	institution = {a product of the "Bridging Privacy Definitions" working group, part of the Privacy Tools for Sharing Research Data project at Harvard University},
	author = {Nissim, Kobbi and Steinke, Thomas and Wood, Alexandra and Bun, Mark and Gaboardi, Marco and O'Brien, David and Vadhan, Salil},
	year = {2017}
}

@article{cummings_privacy_2014,
	title = {Privacy and {Truthful} {Equilibrium} {Selection} for {Aggregative} {Games}},
	volume = {abs/1407.7740},
	url = {http://arxiv.org/abs/1407.7740},
	doi = {10.1007/978-3-662-48995-6_21},
	journal = {CoRR},
	author = {Cummings, Rachel and Kearns, Michael and Roth, Aaron and Wu, Zhiwei Steven},
	year = {2014},
	keywords = {formal privacy}
}

@inproceedings{cummings_accuracy_2015,
	address = {New York, NY, USA},
	series = {{ITCS} '15},
	title = {Accuracy for {Sale}: {Aggregating} {Data} with a {Variance} {Constraint}},
	isbn = {978-1-4503-3333-7},
	url = {http://doi.acm.org/10.1145/2688073.2688106},
	doi = {10.1145/2688073.2688106},
	booktitle = {Proceedings of the 2015 {Conference} on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {ACM},
	author = {Cummings, Rachel and Ligett, Katrina and Roth, Aaron and Wu, Zhiwei Steven and Ziani, Juba},
	year = {2015},
	note = {event-place: Rehovot, Israel},
	keywords = {formal privacy, mechanism design, buying data, vcg mechanism},
	pages = {317--324}
}

@article{cummings_truthful_2015,
	title = {Truthful {Linear} {Regression}},
	volume = {abs/1506.03489},
	url = {http://arxiv.org/abs/1506.03489},
	journal = {CoRR},
	author = {Cummings, Rachel and Ioannidis, Stratis and Ligett, Katrina},
	year = {2015},
	keywords = {formal privacy}
}

@article{cummings_strange_2015,
	title = {The {Strange} {Case} of {Privacy} in {Equilibrium} {Models}},
	volume = {abs/1508.03080},
	url = {http://arxiv.org/abs/1508.03080},
	doi = {10.1145/2940716.2940740},
	journal = {CoRR},
	author = {Cummings, Rachel and Ligett, Katrina and Pai, Mallesh M. and Roth, Aaron},
	year = {2015},
	keywords = {formal privacy}
}

@phdthesis{machanavajjhala_defining_2008,
	type = {phdthesis},
	title = {Defining and {Enforcing} {Privacy} in {Data} {Sharing}},
	school = {Cornell University},
	author = {Machanavajjhala, Ashwin Kumar V.},
	year = {2008},
	keywords = {formal privacy}
}

@article{cummings_coordination_2015,
	title = {Coordination {Complexity}: {Small} {Information} {Coordinating} {Large} {Populations}},
	volume = {abs/1508.03735},
	url = {http://arxiv.org/abs/1508.03735},
	doi = {10.1145/2840728.2840767},
	journal = {CoRR},
	author = {Cummings, Rachel and Ligett, Katrina and Radhakrishnan, Jaikumar and Roth, Aaron and Wu, Zhiwei Steven},
	year = {2015},
	keywords = {formal privacy}
}

@book{abowd_replication_2015,
	title = {Replication {Archive} for: {Economic} {Analysis} and {Statistical} {Disclosure} {Limitation} by {Abowd} and {Schmutte} (2015)},
	url = {https://doi.org/10.5281/zenodo.377008},
	author = {Abowd, John M. and Schmutte, Ian M.},
	month = aug,
	year = {2015},
	doi = {10.5281/zenodo.377008}
}

@inproceedings{aonghusa_plausible_2017,
	title = {Plausible {Deniability} in {Web} {Search} - {From} {Detection} to {Assessment}},
	url = {https://arxiv.org/pdf/1703.03471.pdf},
	doi = {10.1109/tifs.2017.2769025},
	booktitle = {{IEEE} {Transactions} on {Information} {Forensics} and {Security}},
	author = {Aonghusa, P. Mac and Leith, Douglas J.},
	year = {2017},
	pages = {Preliminary preprint}
}

@article{couper_experimental_2010,
	title = {Experimental studies of disclosure risk, disclosure harm, topic sensitivity, and survey participation},
	volume = {26},
	number = {2},
	journal = {Journal of Official Statistics},
	author = {Couper, Mick P and Singer, Eleanor and Conrad, Frederick G and Groves, Robert M},
	year = {2010},
	note = {Publisher: NIH Public Access},
	keywords = {value of privacy},
	pages = {287}
}

@article{perez-truglia_effects_2016,
	title = {The effects of income transparency on well-being: evidence from a natural experiment},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2657808},
	doi = {10.2139/ssrn.2657808},
	journal = {SSRN},
	author = {Perez-Truglia, Ricardo},
	month = feb,
	year = {2016},
	keywords = {primary, value of data}
}

@article{rogers_max-information_2016,
	title = {Max-{Information}, {Differential} {Privacy}, and {Post}-{Selection} {Hypothesis} {Testing}},
	volume = {abs/1604.03924},
	url = {http://arxiv.org/abs/1604.03924},
	doi = {10.1109/focs.2016.59},
	journal = {CoRR},
	author = {Rogers, Ryan M. and Roth, Aaron and Smith, Adam D. and Thakkar, Om},
	year = {2016},
	keywords = {formal privacy}
}

@book{dwork_state_nodate,
	title = {The state of the art.},
	url = {http://web.mit.edu/bigdata-priv/pdf/Cynthia-Dwork.pdf},
	author = {Dwork, Cynthia},
	note = {Published: Microsoft Research Slide Presentation},
	keywords = {formal privacy}
}

@article{greenberg_unrelated_1969,
	title = {The unrelated question randomized response model: theoretical framework},
	volume = {64},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1969.10500991},
	doi = {10.1080/01621459.1969.10500991},
	number = {326},
	journal = {Journal of the American Statistical Association},
	author = {Greenberg, Bernard G. and Abul-Ela, Abdel-Latif A. and Simmons, Walt R. and Horvitz, Daniel G.},
	year = {1969},
	note = {\_eprint: http://www.tandfonline.com/doi/pdf/10.1080/01621459.1969.10500991},
	keywords = {formal privacy},
	pages = {520--539}
}

@book{noauthor_apple_2016,
	title = {Apple previews {iOS} 10, the biggest {iOS} release ever},
	url = {http://www.apple.com/newsroom/2016/06/apple-previews-ios-10-biggest-ios-release-ever.html},
	year = {2016}
}

@inproceedings{kasiviswanathan_power_2013,
	title = {The power of linear reconstruction attacks},
	url = {https://arxiv.org/abs/1210.2381v1},
	booktitle = {Proceedings of the twenty-fourth annual {ACM}-{SIAM} symposium on {Discrete} algorithms {SODA} '13},
	publisher = {ACM Digital Library},
	author = {Kasiviswanathan, Shiva Prasad and Rudelson, Mark and Smith, Adam},
	year = {2013},
	keywords = {formal privacy},
	pages = {1415--1433}
}

@inproceedings{dwork_price_2007,
	title = {The price of privacy and the limits of {LP} decoding},
	doi = {10.1145/1250790.1250804},
	booktitle = {Proceedings of the thirty-ninth annual {ACM} symposium on {Theory} of computing {STOC} '07},
	publisher = {ACM Digital Library},
	author = {Dwork, Cynthia and McSherry, Frank and Talwar, Kunal},
	year = {2007},
	note = {Journal Abbreviation: Proceedings of the thirty-ninth annual ACM symposium on Theory of computing STOC '07},
	keywords = {formal privacy},
	pages = {85--94}
}

@inproceedings{du_using_2003,
	address = {New York, NY, USA},
	series = {{KDD} '03},
	title = {Using randomized response techniques for privacy-preserving data mining},
	isbn = {1-58113-737-0},
	url = {http://doi.acm.org/10.1145/956750.956810},
	doi = {10.1145/956750.956810},
	booktitle = {Proceedings of the {Ninth} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Du, Wenliang and Zhan, Zhijun},
	year = {2003},
	note = {event-place: Washington, D.C.},
	keywords = {formal privacy, privacy, data mining, decision tree, security},
	pages = {505--510}
}

@article{wasserstein_asas_2016,
	title = {The {ASA}'s statement on p-values: context, process, and purpose},
	volume = {70},
	url = {http://dx.doi.org/10.1080/00031305.2016.1154108},
	doi = {10.1080/00031305.2016.1154108},
	number = {2},
	journal = {The American Statistician},
	author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
	year = {2016},
	note = {\_eprint: http://dx.doi.org/10.1080/00031305.2016.1154108},
	pages = {129--133}
}

@inproceedings{dwork_robust_2015,
	title = {Robust traceability from trace amounts},
	url = {https://ieeexplore.ieee.org/document/7354420},
	doi = {10.1109/FOCS.2015.46},
	abstract = {The privacy risks inherent in the release of a large number of summary statistics were illustrated by Homer et al. (PLoS Genetics, 2008), who considered the case of 1-way marginals of SNP allele frequencies obtained in a genome-wide association study: Given a large number of minor allele frequencies from a case group of individuals diagnosed with a particular disease, together with the genomic data of a single target individual and statistics from a sizable reference dataset independently drawn from the same population, an attacker can determine with high confidence whether or not the target is in the case group. In this work we describe and analyze a simple attack that succeeds even if the summary statistics are significantly distorted, whether due to measurement error or noise intentionally introduced to protect privacy. Our attack only requires that the vector of distorted summary statistics is close to the vector of true marginals in L1 norm. Moreover, the reference pool required by previous attacks can be replaced by a single sample drawn from the underlying population. The new attack, which is not specific to genomics and which handles Gaussian as well as Bernouilli data, significantly generalizes recent lower bounds on the noise needed to ensure differential privacy (Bun, Ullman, and Vadhan, STOC 2014, Steinke and Ullman, 2015), obviating the need for the attacker to control the exact distribution of the data.},
	booktitle = {Proceedings of the 2015 {IEEE} 56th {Annual} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS} '15)},
	publisher = {ACM Digital Library},
	author = {Dwork, Cynthia and Smith, Adam and Steinke, Thomas and Ullman, Jonathan and Vadhan, Salil},
	year = {2015},
	keywords = {formal privacy},
	pages = {650--669}
}

@inproceedings{muthukrishnan_optimal_2012,
	title = {Optimal private halfspace counting via discrepancy},
	doi = {10.1145/2213977.2214090},
	booktitle = {Proceedings of the forty-fourth annual {ACM} {Symposium} on {Theory} of {Computing} {STOC} '12},
	publisher = {ACM Digital Library},
	author = {Muthukrishnan, S. and Nikolov, Alexkandar},
	year = {2012},
	keywords = {formal privacy},
	pages = {1285--1292}
}

@book{eisen_natural_1985,
	series = {Committee on {National} {Statistics}},
	title = {Natural {Gas} {Data} {Needs} in a {Changing} {Regulatory} {Environment}},
	publisher = {National Academies Press},
	author = {Eisen, Milton and Kaufman, Gordon M.},
	year = {1985},
	doi = {10.17226/19272}
}

@techreport{national_research_council_privacy_1979,
	address = {Washington, DC},
	title = {Privacy and confidentiality as factors in survey response},
	institution = {National Academy of Sciences},
	author = {{National Research Council}},
	year = {1979},
	keywords = {value of privacy}
}

@article{zhou_differential_2009,
	title = {Differential privacy with compression},
	doi = {10.1109/ISIT.2009.5205863},
	abstract = {This work studies formal utility and privacy guarantees for a simple multiplicative database transformation, where the data are compressed by a random linear or affine transformation, reducing the number of data records substantially, while preserving the number of original input variables.We provide an analysis framework inspired by a recent concept known as differential privacy. Our goal is to show that, despite the general difficulty of achieving the differential privacy guarantee, it is possible to publish synthetic data that are useful for a number of common statistical learning applications. This includes high dimensional sparse regression, principal component analysis (PCA), and other statistical measures based on the covariance of the initial data.},
	journal = {IEEE International Symposium on Information Theory - Proceedings},
	author = {Zhou, Shuheng and Ligett, Katrina and Wasserman, Larry},
	year = {2009},
	note = {ISBN: 9781424443130
\_eprint: 0901.1365},
	keywords = {formal privacy},
	pages = {2718--2722}
}

@article{ye_measuring_1998,
	title = {On {Measuring} and {Correcting} the {Effects} of {Data} {Mining} and {Model} {Selection}},
	volume = {93},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1998.10474094},
	doi = {10.1080/01621459.1998.10474094},
	abstract = {Abstract In the theory of linear models, the concept of degrees of freedom plays an important role. This concept is often used for measurement of model complexity, for obtaining an unbiased estimate of the error variance, and for comparison of different models. I have developed a concept of generalized degrees of freedom (GDF) that is applicable to complex modeling procedures. The definition is based on the sum of the sensitivity of each fitted value to perturbation in the corresponding observed value. The concept is nonasymptotic in nature and does not require analytic knowledge of the modeling procedures. The concept of GDF offers a unified framework under which complex and highly irregular modeling procedures can be analyzed in the same way as classical linear models. By using this framework, many difficult problems can be solved easily. For example, one can now measure the number of observations used in a variable selection process. Different modeling procedures, such as a tree-based regression and a projection pursuit regression, can be compared on the basis of their residual sums of squares and the GDF that they cost. I apply the proposed framework to measure the effect of variable selection in linear models, leading to corrections of selection bias in various goodness-of-fit statistics. The theory also has interesting implications for the effect of general model searching by a human modeler. Abstract In the theory of linear models, the concept of degrees of freedom plays an important role. This concept is often used for measurement of model complexity, for obtaining an unbiased estimate of the error variance, and for comparison of different models. I have developed a concept of generalized degrees of freedom (GDF) that is applicable to complex modeling procedures. The definition is based on the sum of the sensitivity of each fitted value to perturbation in the corresponding observed value. The concept is nonasymptotic in nature and does not require analytic knowledge of the modeling procedures. The concept of GDF offers a unified framework under which complex and highly irregular modeling procedures can be analyzed in the same way as classical linear models. By using this framework, many difficult problems can be solved easily. For example, one can now measure the number of observations used in a variable selection process. Different modeling procedures, such as a tree-based regression and a projection pursuit regression, can be compared on the basis of their residual sums of squares and the GDF that they cost. I apply the proposed framework to measure the effect of variable selection in linear models, leading to corrections of selection bias in various goodness-of-fit statistics. The theory also has interesting implications for the effect of general model searching by a human modeler.},
	number = {441},
	journal = {Journal of the American Statistical Association},
	author = {Ye, Jianming},
	year = {1998},
	keywords = {data mining, degrees of freedom, effect of model selection, goodness-of-fit, half-normal plot, nonparametric regression, sensitivity},
	pages = {120--131}
}

@techreport{singer_privacy_2003,
	type = {techreport},
	title = {Privacy research in census 2000},
	number = {TR-1},
	institution = {U.S. Census Bureau},
	author = {Singer, Eleanor},
	month = nov,
	year = {2003},
	keywords = {SDL, statistical disclosure limitation}
}

@article{woo_global_2009,
	title = {Global {Measures} of {Data} {Utility} for {Microdata} {Masked} for {Disclosure} {Limitation}},
	volume = {1},
	url = {http://repository.cmu.edu/cgi/viewcontent.cgi?article=1006&context=jpc},
	number = {1},
	journal = {Privacy and Confidentiality},
	author = {Woo, M. and Reiter, J. P. and Oganian, A. and Karr, A. F.},
	year = {2009},
	keywords = {SDL, statistical disclosure limitation, data confidentiality, and phrases, cluster, data u, data utility, nonparametric distribution function, propensity score},
	pages = {111--124}
}

@article{wendner_status_2008,
	title = {Status {Effects}, {Public} {Goods} {Provision}, and {Excess} {Burden}},
	volume = {92},
	issn = {0047-2727},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=eoh&AN=1017081&lang=ja&site=ehost-live$\backslash$nhttp://dx.doi.org/10.1016/j.jpubeco.2008.04.011$\backslash$nhttp://www.elsevier.com/locate/inca/505578/ DP - EBSCOhost DB - eoh},
	doi = {10.1016/j.jpubeco.2008.04.011},
	abstract = {Most studies of the optimal provision of public goods or the excess burden from taxation assume that individual utility is independent of other individuals' consumption. This paper investigates public good provision and excess burden in a model that allows for interdependence in consumption in the form of status (relative consumption) effects. In the presence of such effects, consumption and labor taxes no longer are pure distortionary taxes but have a corrective tax element that addresses an externality from consumption. As a result, the marginal excess burden of consumption taxes is lower than in the absence of status effects, and will be negative if the consumption tax rate is below the "Pigouvian" rate. Correspondingly, when consumption or labor tax rates are below the Pigouvian rate, the second-best level of public goods provision is above the first-best level, contrary to findings from models without status effects. For plausible functional forms and parameters relating to status effects, the marginal excess burden from existing U.S. labor taxes is substantially lower than in most prior studies, and is negative in some cases.},
	number = {10-11},
	journal = {Journal of Public Economics},
	author = {Wendner, Ronald and Goulder, Lawrence H},
	year = {2008},
	note = {Publisher: Elsevier B.V.},
	keywords = {includes inheritance and gift taxes H240, Personal Income and Other Nonbusiness Taxes and Su, Public Goods H410 L3 - http://www.elsevier.com/lo, Taxation and Subsidies: Incidence H220},
	pages = {1968--1985}
}

@article{wasserman_statistical_2010,
	title = {A {Statistical} {Framework} for {Differential} {Privacy}},
	volume = {105},
	issn = {0162-1459},
	doi = {10.1198/jasa.2009.tm08651},
	abstract = {One goal of statistical privacy research is to construct a data release mechanism that protects individual privacy while preserving information content. An example is a random mechanism that takes an input database X and outputs a random database Z according to a distribution Qn(*{\textbar}X). Differential privacy is a particular privacy requirement developed by computer scientists in which Qn(*{\textbar}X) is required to be insensitive to changes in one data point in X. This makes it difficult to infer from Z whether a given individual is in the original database X. We consider differential privacy from a statistical perspective. We consider several data-release mechanisms that satisfy the differential privacy requirement. We show that it is useful to compare these schemes by computing the rate of convergence of distributions and densities constructed from the released data. We study a general privacy method, called the exponential mechanism, introduced by McSherry and Talwar (2007). We show that the accuracy of this method is intimately linked to the rate at which the probability that the empirical distribution concentrates in a small ball around the true distribution.},
	number = {489},
	journal = {Journal of the American Statistical Association},
	author = {Wasserman, Larry and Zhou, Shuheng},
	year = {2010},
	note = {\_eprint: arXiv:0811.2501v2},
	keywords = {formal privacy, Privacy, disclosure limitation, privacy, Disclosure limitation, minimax estimation, Minimax estimation},
	pages = {375--389}
}

@article{wang_privacy_2015,
	title = {Privacy for {Free}: {Posterior} {Sampling} and {Stochastic} {Gradient} {Monte} {Carlo}},
	url = {http://proceedings.mlr.press/v37/wangg15.pdf},
	abstract = {We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to "differential privacy:, a cryptographic approach to protect individual-level privacy while permiting database-level utility. Specifically, we show that that under standard assumptions, getting one single sample from a posterior distribution is differentially private "for free". We will see that estimator is statistically consistent, near optimal and computationally tractable whenever the Bayesian model of interest is consistent, optimal and tractable. Similarly but separately, we show that a recent line of works that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an "anytime" algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets.},
	journal = {arXiv},
	author = {Wang, Yu-Xiang and Fienberg, Stephen E. and Smola, Alex},
	year = {2015},
	note = {\_eprint: 1502.07645},
	keywords = {formal privacy},
	pages = {1--27}
}

@inproceedings{varian_economic_1995,
	title = {Economic {Mechanism} {Design} for {Computerized} {Agents}},
	abstract = {The field of economic mechanism design has been an active area of research in economics for at least 20 years. This field uses the tools of economics and game theory to design rules of interaction? for economic transactions that will, in principle, yield some desired outcome. In this paper I provide an overview of this subject for an audience interested in applications to electronic commerce and discuss some special problems that arise in this context.},
	booktitle = {Proceedings of the 1st {Conference} on {USENIX} {Workshop} on {Electronic} {Commerce} - {Volume} 1},
	author = {Varian, Hal R},
	year = {1995},
	note = {Issue: May
Journal Abbreviation: Proceedings of the 1st Conference on USENIX Workshop on Electronic Commerce - Volume 1},
	keywords = {economics, mechanism design, electronic commerce},
	pages = {1--14}
}

@article{varian_how_1997,
	title = {How to build an economic model in your spare time},
	url = {http://web.cenet.org.cn/upfile/91315.pdf},
	number = {December 1994},
	journal = {American Economist-Tuscaloosa-},
	author = {Varian, Hal R},
	year = {1997},
	keywords = {address, and systems, berkeley, dean, edu, hal r, school of information mangement, sims, uc, varian, web page http, www}
}

@article{varian_economics_1999,
	title = {Economics and search},
	issn = {0163-5840},
	url = {http://people.ischool.berkeley.edu/ hal/Papers/sigir/sigir.pdf},
	doi = {10.1145/331403.331404},
	number = {August},
	journal = {SIGIR Forum},
	author = {Varian, HR},
	year = {1999},
	pages = {1--12}
}

@article{varian_buying_2003,
	title = {Buying, {Sharing} and {Renting} {Information} {Goods}},
	volume = {48},
	issn = {0022-1821},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-6451.00133},
	doi = {10.1111/1467-6451.00133},
	abstract = {Information goods such as books, journals, computer software, music and videos can be copied, shared, resold, or rented. When such opportunities for sharing are present, the content producer will generally sell a smaller amount at a higher price which may increase or decrease profits. I identify three circumstances where profits increase: (1) when the transactions cost of sharing is less than the marginal cost of production; (2) when content is viewed only a few times and transactions costs of sharing are low; and (3) when a sharing market provides a way to segment high-value and low-value users.},
	number = {4},
	journal = {The Journal of Industrial Economics},
	author = {Varian, Hal R.},
	year = {2003},
	keywords = {value of data, books, d4, information, jel classification numbers, l86, l96, libraries},
	pages = {473--488}
}

@incollection{varian_economic_2002,
	address = {Boston, MA},
	title = {Economic {Aspects} of {Personal} {Privacy}},
	isbn = {978-1-4757-3575-8},
	url = {https://doi.org/10.1007/978-1-4757-3575-8_9},
	abstract = {The advent of low-cost technology for manipulating and communicating information has raised significant concerns about personal privacy. Privacy is a complex issue that can be treated from many perspectives; this paper provides an overview of some of the economic issues surrounding it.1},
	booktitle = {Cyber {Policy} and {Economics} in an {Internet} {Age}},
	publisher = {Springer US},
	author = {Varian, Hal R.},
	editor = {Lehr, William H. and Pupillo, Lorenzo M.},
	year = {2002},
	doi = {10.1007/978-1-4757-3575-8_9},
	keywords = {primary},
	pages = {127--137}
}

@incollection{varian_market_2000,
	address = {Cambridge, MA},
	title = {Market structure in the network age},
	isbn = {978-0-262-52330-1},
	abstract = {E-commerce will undoubtedly change the way business is done. But as I have said elsewhere, technology changes, economic laws do not? Despite the changes introduced by e-commerce, many of the fundamental principles of competition will still be relevant. In this chapter I investigate three aspects of competition in ecommerce: marketing, interconnection, and price matching. In each case I will describe the phenomenon, illustrate its relevance for e-commerce, and describe some research issues raised. Book: The rapid growth of electronic commerce, along with changes in information, computing, and communications, is having a profound effect on the United States economy. President Clinton recently directed the National Economic Council, in consultation with executive branch agencies, to analyze the economic implications of the Internet and electronic commerce domestically and internationally, and to consider new types of data collection and research that could be undertaken by public and private organizations. This book contains work presented at a conference held by executive branch agencies in May 1999 at the Department of Commerce. The goals of the conference were to assess current research on the digital economy, to engage the private sector in developing the research that informs investment and policy decisions, and to promote better understanding of the growth and socioeconomic implications of information technology and electronic commerce. Aspects of the digital economy addressed include macroeconomic assessment, organizational change, small business, access, market structure and competition, and employment and the workforce.},
	booktitle = {Understanding the {Digital} {Economy}},
	publisher = {MIT Press},
	author = {Varian, H.R.},
	editor = {Brynjolfsson, Erik and Kahin, Brian},
	year = {2000},
	pages = {137--150}
}

@article{ullman_private_2014,
	title = {Private {Multiplicative} {Weights} {Beyond} {Linear} {Queries}},
	url = {https://dl.acm.org/citation.cfm?doid=2745754.2745755},
	doi = {10.1145/2745754.2745755},
	abstract = {A wide variety of fundamental data analyses in machine learning, such as linear and logistic regression, require minimizing a convex function defined by the data. Since the data may contain sensitive information about individuals, and these analyses can leak that sensitive information, it is important to be able to solve convex minimization in a privacy-preserving way. A series of recent results show how to accurately solve a single convex minimization problem in a differentially private manner. However, the same data is often analyzed repeatedly, and little is known about solving multiple convex minimization problems with differential privacy. For simpler data analyses, such as linear queries, there are remarkable differentially private algorithms such as the private multiplicative weights mechanism (Hardt and Rothblum, FOCS 2010) that accurately answer exponentially many distinct queries. In this work, we extend these results to the case of convex minimization and show how to give accurate and differentially private solutions to *exponentially many* convex minimization problems on a sensitive dataset.},
	journal = {arXiv},
	author = {Ullman, Jonathan},
	year = {2014},
	note = {\_eprint: arXiv:1407.1571v1},
	keywords = {formal privacy},
	pages = {1--17}
}

@article{thorburn_methods_1983,
	title = {On {Methods} for {Disclosure} {Control} in {Longitudinal} {Studies}},
	volume = {2},
	journal = {Statistik Tidskrift},
	author = {Thorburn, Daniel},
	year = {1983},
	keywords = {SDL, statistical disclosure limitation},
	pages = {93--101}
}

@article{suzumura_entry_1995,
	title = {Entry and {Cost} {Reduction}: {Comment}},
	volume = {7},
	issn = {0922-1425},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=eoh&AN=0410833&lang=ja&site=ehost-live$\backslash$nhttp://www.elsevier.com/wps/find/journaldescription.cws_home/505557/description#description},
	doi = {10.1016/0922-1425(95)00024-0},
	number = {4},
	journal = {Japan and the World Economy},
	author = {Suzumura, Kotaro},
	year = {1995},
	pmid = {410833},
	keywords = {Production, and Market Structure, Oligopoly and Other Imperfect Markets L130, Pricing, Size Distribution of Firms L110},
	pages = {411--418}
}

@techreport{stephens-davidowitz_hands-guide_2015,
	title = {A {Hands}-on {Guide} to {Google} {Data}},
	url = {http://people.ischool.berkeley.edu/ hal/Papers/2015/primer.pdf},
	institution = {Google, Inc.},
	author = {Stephens-Davidowitz, Seth and Varian, Hal},
	year = {2015},
	pages = {1--25}
}

@article{shokri_privacy-preserving_2015,
	title = {Privacy-preserving deep learning},
	url = {https://dl.acm.org/citation.cfm?doid=2810103.2813687},
	doi = {10.1145/2810103.2813687},
	journal = {CCS'15},
	author = {Shokri, Reza and Shmatikiv, Vitaly},
	year = {2015},
	keywords = {formal privacy}
}

@article{shen_adaptive_2002,
	title = {Adaptive {Model} {Selection}},
	volume = {97},
	issn = {0162-1459},
	url = {http://pubs.amstat.org/doi/abs/10.1198/016214502753479356},
	doi = {10.1198/016214502753479356},
	abstract = {Most model selection procedures use a fixed penalty penalizing an increase in the size of a model. These nonadaptive selection procedures perform well only in one type of situation. For instance, Bayesian information criterion (BIC) with a large penalty performs well for small models and poorly for large models, and Akaike's information criterion (AIC) does just the opposite. This article proposes an adaptive model selection procedure that uses a data-adaptive complexity penalty based on a concept of generalized degrees of freedom. The proposed procedure, combining the benefit of a class of nonadaptive procedures, approximates the best performance of this class of procedures across a variety of different situations. This class includes many well-known procedures, such as AIC, BIC, Mallows's Cp , and risk inflation criterion (RIC). The proposed procedure is applied to wavelet thresholding in nonparametric regression and variable selection in least squares regression. Simulation results and an asymptotic analysis support the effectiveness of the proposed procedure.},
	number = {457},
	journal = {Journal of the American Statistical Association},
	author = {Shen, Xiaotong and Ye, Jianming},
	year = {2002},
	keywords = {regression, adaptive penalty, false discovery rate, optimal predication, parametric and nonparametric, variable selec-},
	pages = {210--221}
}

@book{smith_general_2011,
	series = {National {Data} {Program} for the {Social} {Sciences} {Series}, no. 21},
	title = {General {Social} {Surveys}, 1972-2010: cumulative codebook},
	publisher = {Chicago: National Opinion Research Center},
	author = {Smith, Tom W. and Marsden, Peter and Hout, Michael and Kim, Jibum},
	year = {2011}
}

@article{sheffet_differentially_2015,
	title = {Differentially private least squares: estimation, confidence and rejecting the null hypothesis},
	volume = {abs/1507.02482},
	url = {http://webdocs.cs.ualberta.ca/ osheffet/OLS.html},
	journal = {CoRR},
	author = {Sheffet, Or},
	year = {2015},
	keywords = {formal privacy}
}

@article{shalev-shwartz_learnability_2010,
	title = {Learnability, {Stability} and {Uniform} {Convergence}},
	volume = {11},
	issn = {1532-4435},
	url = {http://eprints.pascal-network.org/archive/00008909/},
	abstract = {The problem of characterizing learnability is the most basic question of statistical learning theory. A fundamental and long-standing answer, at least for the case of supervised classification and regression, is that learnability is equivalent to uniform convergence of the empirical risk to the population risk, and that if a problem is learnable, it is learnable via empirical risk minimization. In this paper, we consider the general learning setting (introduced by vapnik), which includes most statistical learning problems as special cases. We show that in this setting, there are non-trivial learning problems where uniform convergence does not hold, empirical risk minimization fails, and yet they are learnable using alternative mechanisms. Instead of uniform convergence, we identify stability as the key necessary and sufficient condition for learnability. Moreover, we show that the conditions for learnability in the general setting are significantly more complex than in supervised classification and regression.},
	journal = {Jmlr},
	author = {Shalev-Shwartz, Shai and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
	year = {2010},
	keywords = {Theory \& Algorithms},
	pages = {2635--2670}
}

@article{shafaat_method_2007,
	title = {A method of adaptive coarsening for compressing scientific datasets},
	url = {http://www.springerlink.com/index/7188QU4233NW042R.pdf},
	journal = {Applied Parallel Computing},
	author = {Shafaat, T and Baden, S},
	year = {2007},
	pages = {774--780}
}

@article{schmutte_job_2015,
	title = {Job referral networks and the determination of earnings in local labor markets},
	volume = {33},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/677389},
	doi = {10.1086/677389},
	abstract = {Despite their documented importance in the labor market, little is known about how workers use social networks to find jobs and their resulting effect on earnings. I use geographically detailed U.S. employer-employee data to infer the role of social networks in connecting workers to jobs in high-paying firms. To identify social interactions in job search, I exploit variation in social network quality within small neighborhoods. Workers are more likely to change jobs, and more likely to move to a higher-paying firm, when their neighbors are employed in high-paying firms. Furthermore, local referral networks help match high-ability workers to high-paying firms.},
	number = {1},
	journal = {Journal of Labor Economics},
	author = {Schmutte, Ian M.},
	year = {2015},
	keywords = {Social Interactions},
	pages = {1--32}
}

@article{schmutte_differentially_2016,
	title = {Differentially {Private} {Release} of {Data} on {Wage} and {Job} {Mobility}},
	volume = {32},
	url = {https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji962},
	doi = {10.3233/SJI-160962},
	abstract = {Brazil, like many countries, is reluctant to publish business-level data, because of legitimate concerns about the establishments' confidentiality. A trusted data curator can increase the utility of data, while managing the risk to establishments, either by releasing synthetic data, or by infusing noise into published statistics. This paper evaluates the application of a differentially private mechanism to publish statistics on wages and job mobility computed from Brazilian employer-employee matched data. The publication mechanism can result in both the publication of specific statistics as well as the generation of synthetic data. I find that the tradeoff between the privacy guaranteed to individuals in the data, and the accuracy of published statistics, is potentially much better that the worst-case theoretical accuracy guarantee. However, the synthetic data fare quite poorly in analyses that are outside the set of queries to which it was trained. Note that this article only explores and characterizes the feasibility of these publication strategies, and will not directly result in the publication of any data.},
	number = {1},
	journal = {Statistical Journal of the IAOS},
	author = {Schmutte, Ian M.},
	year = {2016},
	keywords = {formal privacy},
	pages = {81--92}
}

@article{vilhuber_synthetic_2016,
	title = {Synthetic establishment microdata around the world},
	volume = {32},
	url = {https://ecommons.cornell.edu/handle/1813/42340},
	doi = {10.3233/SJI-160964},
	abstract = {In contrast to the many public-use microdata samples available for individual and household data from many statistical agencies around the world, there are virtually no establishment or firm microdata available. In large part, this difficulty in providing access to business micro data is due to the skewed and sparse distributions that characterize business data. Synthetic data are simulated data generated from statistical models. We organized sessions at the 2015 World Statistical Congress and the 2015 Joint Statistical Meetings, highlighting work on synthetic establishment microdata. This overview situates those papers, published in this issue, within the broader literature.},
	number = {1},
	journal = {Statistical Journal of the International Association for Official Statistics},
	author = {Vilhuber, Lars and Abowd, John M. and Reiter, Jerome P.},
	year = {2016},
	keywords = {SDL, statistical disclosure limitation},
	pages = {65--68}
}

@article{miranda_using_2016,
	title = {Using partially synthetic microdata to protect sensitive cells in business statistics},
	volume = {32},
	url = {https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji963},
	doi = {10.3233/SJI-160963},
	abstract = {We describe and analyze a method that blends records from both observed and synthetic microdata into public-use tabulations on establishment statistics. The resulting tables use synthetic data only in potentially sensitive cells. We describe different algorithms, and present preliminary results when applied to the Census Bureau's Business Dynamics Statistics and Synthetic Longitudinal Business Database, highlighting accuracy and protection afforded by the method when compared to existing public-use tabulations (with suppressions).},
	number = {1},
	journal = {Statistical Journal of the International Association for Official Statistics},
	author = {Miranda, Javier and Vilhuber, Lars},
	year = {2016},
	keywords = {SDL, statistical disclosure limitation},
	pages = {69--80}
}

@article{rutherford_applied_1999,
	title = {Applied {General} {Equilibrium} {Modeling} with {MPSGE} as a {GAMS} {Subsystem}: {An} {Overview} of the {Modeling} {Framework} and {Syntax}},
	volume = {14},
	doi = {10.1023/A:1008655831209},
	abstract = {his paper describes a programming environment for economic equilibrium analysis. The system introduces the Mathematical Programming System for General Equilibrium analysis (MPSGE, Rutherford 1987) within the Generalized Algebraic Modelling System (GAMS, Brooke, Kendrick and Meeraus (1988)). This arrangement exploits GAMS' set-oriented algebraic syntax for data manipulation and report writing. The system based on the tabular MPSGE input format provides a compact, non-algebraic representation of a model's nonlinear equations. This paper provides an overview of the modelling environment and three worked examples in tax policy analysis.},
	number = {1-2},
	journal = {Computational Economics},
	author = {Rutherford, Thomas},
	year = {1999},
	keywords = {applied general equilibrium},
	pages = {1--46}
}

@article{roth_what_2008,
	title = {What have we learned from market design?},
	volume = {118},
	issn = {0013-0133},
	doi = {10.1111/j.1468-0297.2007.02121.x},
	abstract = {This article discusses some things we have learned about markets, in the process of designing marketplaces to fix market failures. To work well, marketplaces have to provide thickness, i.e. they need to attract a large enough proportion of the potential participants in the market; they have to overcome the congestion that thickness can bring, by making it possible to consider enough alternative transactions to arrive at good ones; and they need to make it safe and sufficiently simple to participate in the market, as opposed to transacting outside of the market, or having to engage in costly and risky strategic behaviour. I will draw on recent examples of market design ranging from labour markets for doctors and new economists, to kidney exchange, and school choice in New York City and Boston.},
	number = {2006},
	journal = {Economic Journal},
	author = {Roth, Alvin E.},
	year = {2008},
	pages = {285--310}
}

@article{roth_interactive_2010,
	title = {Interactive privacy via the median mechanism},
	issn = {0737-8017},
	url = {http://portal.acm.org/citation.cfm?doid=1806689.1806794$\backslash$nhttp://dl.acm.org/citation.cfm?id=1806794},
	doi = {10.1145/1806689.1806794},
	abstract = {We define a new interactive differentially private mechanism – the median mechanism – for answering arbitrary predicate queries that arrive online. Relative to fixed accuracy and privacy constraints, this mechanism can answer exponentially more queries than the previously best known interactive privacy mechanism (the Laplace mechanism, which independently perturbs each query result). Our guarantee is almost the best possible, even for non-interactive privacy mechanisms. Conceptually, the median mechanism is the first privacy mechanism capable of identifying and exploiting correlations among queries in an interactive setting. We also give an efficient implementation of the median mechanism, with running time polynomial in the number of queries, the database size, and the domain size. This efficient implementation guarantees privacy for all input databases, and accurate query results for almost all input databases. The dependence of the privacy on the number of queries in this mechanism improves over that of the best previously known efficient mechanism by a super-polynomial factor, even in the non-interactive setting.},
	journal = {Proceedings of the 42nd ACM symposium on Theory of computing - STOC '10},
	author = {Roth, Aaron and Roughgarden, Tim},
	year = {2010},
	note = {ISBN: 9781450300506
\_eprint: 0911.1813},
	keywords = {formal privacy},
	pages = {765--774}
}

@article{roth_buying_2012,
	title = {Buying {Private} {Data} at {Auction} : {The} {Sensitive} {Surveyor}'s {Problem}},
	volume = {11},
	issn = {1551-9031},
	url = {http://doi.acm.org/10.1145/2325713.2325714},
	doi = {10.1145/2325713.2325714},
	number = {1},
	journal = {SIGecom Exch.},
	author = {Roth, Aaron},
	month = jun,
	year = {2012},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {economics of privacy},
	pages = {1--8}
}

@article{postlewaite_social_1998,
	title = {The {Social} {Basis} of {Interdependent} {Preferences}},
	volume = {42},
	issn = {0014-2921},
	doi = {10.1016/S0014-2921(97)00144-X},
	abstract = {Most economists are sympathetic to the idea that concerns for relative position are an important aspect of many economic problems. There has traditionally been a reluctance to include such concerns primarily because models that included them often allow such a broad range of behavior that there are few, if any, restrictions on equilibrium behavior and, hence, such models would have little or no predictive power. In this paper we discuss how reduced form models may naturally give rise to utility functions that depend, in part, on relative standing. There are several advantages of modelling concern for relative standing in reduced form utility functions even when there is no similar concern in the 'deep' preferences. It provides structure and constraints on the way that relative standing affects utility, and further, it can yield testable implications about the way that changes in the underlying environment affect the concern for relative standing. We discuss the advantages and disadvantages of modelling social concerns in this way and provide examples that illustrate how concerns for relative standing can affect savings, investment and labor choice decisions.},
	number = {3-5},
	journal = {European Economic Review},
	author = {Postlewaite, Andrew},
	month = may,
	year = {1998},
	keywords = {conspicuous consumption, group, interactions, interdependent preference, participation, relative consumption, social capital, Social status, status},
	pages = {779--800}
}

@article{reiter_estimating_2005,
	title = {Estimating risks of identification disclosure in microdata},
	volume = {100},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214505000000619},
	doi = {10.1198/016214505000000619},
	number = {472},
	journal = {Journal of the American Statistical Association},
	author = {Reiter, Jerome P},
	year = {2005},
	keywords = {SDL, statistical disclosure limitation, record linkage, confidentiality, public use data, survey},
	pages = {1103--1112}
}

@article{qardaji_understanding_2013,
	title = {Understanding hierarchical methods for differentially private histograms},
	volume = {6},
	url = {http://www.vldb.org/pvldb/vol6/p1954-qardaji.pdf},
	abstract = {In recent years, many approaches to differentially privately publish histograms have been proposed. Several approach- es rely on constructing tree structures in order to decrease the error when answer large range queries. In this paper, we examine the factors affecting the accuracy of hierarchical ap- proaches by studying the mean squared error (MSE) when answering range queries. We start with one-dimensional his- tograms, and analyze how the MSE changes with differen- t branching factors, after employing constrained inference, and with different methods to allocate the privacy budget among hierarchy levels. Our analysis and experimental re- sults show that combining the choice of a good branching factor with constrained inference outperform the current s- tate of the art. Finally, we extend our analysis to multi- dimensional histograms. We show that the benefits from employing hierarchical methods beyond a single dimension are significantly diminished, and when there are 3 or more dimensions, it is almost always better to use the Flat method instead of a hierarchy.},
	number = {14},
	journal = {39th International Conference on Very Large Data Bases VDBL 2013},
	author = {Qardaji, Wahbeh and Yang, Weining and Li, Ninghui},
	year = {2013},
	keywords = {formal privacy},
	pages = {1954--1965}
}

@article{proserpio_calibrating_2014,
	title = {Calibrating data to sensitivity in private data analysis: a platform for differentially-private analysis of weighted datasets},
	volume = {7},
	issn = {2150-8097},
	url = {http://dx.doi.org/10.14778/2732296.2732300},
	doi = {10.14778/2732296.2732300},
	number = {8},
	journal = {Proceedings of the VLDB Endowment},
	author = {Proserpio, Davide and Goldberg, Sharon and McSherry, Frank},
	month = apr,
	year = {2014},
	note = {Publisher: VLDB Endowment},
	keywords = {formal privacy},
	pages = {637--648}
}

@article{pollak_interdependent_1976,
	title = {Interdependent preferences},
	volume = {66},
	copyright = {Copyright 1976 American Economic Association},
	issn = {0002-8282},
	language = {English},
	number = {3},
	journal = {The American Economic Review},
	author = {Pollak, Robert A.},
	year = {1976},
	note = {Publisher: American Economic Association},
	pages = {309--320}
}

@techreport{park_variational_2016,
	title = {Variational bayes in private settings ({VIPS})},
	url = {https://arxiv.org/abs/1611.00340},
	abstract = {We provide a general framework for privacy-preserving variational Bayes (VB) for a large class of probabilistic models, called the conjugate exponential (CE) family. Our primary observation is that when models are in the CE family, we can privatise the variational posterior distributions simply by perturbing the expected sufficient statistics of the complete-data likelihood. For widely used non-CE models with binomial likelihoods, we exploit the Pólya-Gamma data augmentation scheme to bring such models into the CE family, such that inferences in the modified model resemble the private variational Bayes algorithm as closely as possible. The iterative nature of variational Bayes presents a further challenge since iterations increase the amount of noise needed. We overcome this by combining: (1) a relaxed notion of differential privacy, called concentrated differential privacy, which provides a tight bound on the privacy cost of multiple VB iterations and thus significantly decreases the amount of additive noise; and (2) the privacy amplification effect of subsampling mini-batches from large-scale data in stochastic learning. We empirically demonstrate the effectiveness of our method in CE and non-CE models including latent Dirichlet allocation, Bayesian logistic regression, and sigmoid belief networks, evaluated on real-world datasets.},
	institution = {arxiv.org},
	author = {Park, Mijung and Foulds, James and Chaudhuri, Kamalika and Welling, Max},
	year = {2016},
	keywords = {formal privacy}
}

@article{nissim_smooth_2007,
	title = {Smooth sensitivity and sampling in private data analysis},
	issn = {0737-8017},
	url = {http://portal.acm.org/citation.cfm?doid=1250790.1250803},
	doi = {10.1145/1250790.1250803},
	abstract = {We introduce a new, generic framework for private data analysis. The goal of private data analysis is to release aggregate information about a data set while protecting the privacy of the individuals whose information the data set contains. Our framework allows one to release functions f of the data with instance-based additive noise. That is, the noise magnitude is determined not only by the function we want to release, but also by the database itself. One of the challenges is to ensure that the noise magnitude does not leak information about the database. To address that, we calibrate the noise magnitude to the smooth sensitivity of f on the database x - a measure of variability of f in the neighborhood of the instance x. The new framework greatly expands the applicability of output perturbation, a technique for protecting individuals' privacy by adding a small amount of random noise to the released statistics. To our knowledge, this is the first formal analysis of the effect of instance-based noise in the context of data privacy. Our framework raises many interesting algorithmic questions. Narnely, to apply the framework one must compute or approximate the smooth sensitivity of f on x. We show how to do this efficiently for several different functions, including the median and the cost of the minimum spanning tree. We also give a generic procedure based on sampling that allows one to release f(x) accurately on many databases x. This procedure is applicable even when no efficient algorithm for approximating smooth sensitivity of f is known or when f is given as a black box. We illustrate the procedure by applying it to k-SED (k-means) Clustering and learning mixtures of Gaussians.},
	number = {x},
	journal = {Proceedings of the thirty-ninth annual ACM symposium on Theory of computing - STOC '07},
	author = {Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
	year = {2007},
	note = {ISBN: 9781595936318},
	keywords = {formal privacy, clustering, private data analysis, sensitivity, mining, output perturbation, privacy preserving data},
	pages = {75}
}

@article{matthew_estimating_2004,
	title = {Estimating the public value of conflicting information : the case of genetically modified foods},
	volume = {80},
	issn = {0023-7639},
	url = {http://www.jstor.org/stable/3147148},
	doi = {10.2307/3147148},
	abstract = {Environmental groups have become the chief antagonists toward agricultural biotechnology innovations. They demonstrate and disseminate private information with the objective of changing the behavior of consumers and producers. We use experimental auctions with adult U.S. consumers and show that this information reduces significantly the demand for genetically modified (GM)-food products and that it has significant public good value-an average of 3 cents per product purchased, or roughly \$2 billion annually. We also show that the dissemination of independent third-party information about agricultural biotechnology dissipates most of the public good value of negative GM-product information.},
	number = {1},
	journal = {Land Economics},
	author = {Matthew, C R and Huffman, Wallace E and Shogren, Jason F and Tegene, A},
	month = feb,
	year = {2004},
	keywords = {value of data},
	pages = {125--135}
}

@inproceedings{mir_dp-where_2013,
	title = {Dp-where: differentially private modeling of human mobility},
	doi = {10.1109/BigData.2013.6691626},
	abstract = {Models of human mobility have broad applicability in urban planning, ecology, epidemiology, and other fields. Starting with Call Detail Records (CDRs) from a cellular telephone network that have gone through a straightforward anonymization procedure, the prior WHERE modeling approach produces synthetic CDRs for a synthetic population. The accuracy of WHERE has been validated against billions of location samples for hundreds of thousands of cell phones in the New York and Los Angeles metropolitan areas. In this paper, we introduce DP-WHERE, which modifies WHERE by adding controlled noise to achieve differential privacy, a strict definition of privacy that makes no assumptions about the power or background knowledge of a potential adversary. We also present experiments showing that the accuracy of DP-WHERE remains close to that of WHERE and of real CDRs. With this work, we aim to enable the creation and possible release of synthetic models that capture the mobility patterns of real metropolitan populations while preserving privacy.},
	booktitle = {Conference on {Big} {Data}, 2013 {IEEE} {International}},
	author = {Mir, D.J. and Isaacman, S. and Caceres, R. and Martonosi, M. and Wright, R.N.},
	month = oct,
	year = {2013},
	keywords = {formal privacy, data privacy, Data privacy, differential privacy, Privacy, Databases, anonymization procedure, call detail records, CDR, cellular telephone network, demography, differentially private modeling, DP-WHERE approach, ecology, epidemiology, Histograms, human mobility models, Los Angeles, metropolitan populations, New York, Noise, Sensitivity, social sciences computing, synthetic population, urban planning, Vectors, WHERE modeling approach, work and home extracted regions},
	pages = {580--588}
}

@book{mas-colell_microeconomic_1995,
	series = {Oxford student edition},
	title = {Microeconomic theory},
	isbn = {978-0-19-507340-9},
	publisher = {Oxford University Press},
	author = {Mas-Colell, A. and Whinston, M.D. and Green, J.R.},
	year = {1995},
	lccn = {95018128}
}

@article{luttmer_neighbors_2005,
	title = {Neighbors as negatives: relative earnings and well-being},
	volume = {120},
	issn = {0033-5533},
	doi = {10.1162/003355305774268255},
	abstract = {This paper investigates whether individuals feel worse off when others around them earn more. In other words, do people care about relative position, and does lagging "behind the Joneses" diminish well-being? To answer this question, I match individual-level data containing various indicators of well-being to information about local average earnings. I find that, controlling for an individual's own income, higher earnings of neighbors are associated with lower levels of self-reported happiness. The data's panel nature and rich set of measures of well-being and behavior indicate that this association is not driven by selection or by changes in the way people define happiness. There is suggestive evidence that the negative effect of increases in neighbors' earnings on own well-being is most likely caused by interpersonal preferences, that is, people having utility functions that depend on relative consumption in addition to absolute consumption. 2005 MIT Press},
	number = {3},
	journal = {The Quarterly Journal of Economics},
	author = {Luttmer, Erzo F. P.},
	month = aug,
	year = {2005},
	pmid = {11490996},
	keywords = {utility, asset prices, interdependent preferences, comparison income, happiness, jealousy, joneses, satisfaction, taxation, unemployment},
	pages = {963--1002}
}

@article{linde_pricing_2009,
	title = {Pricing information goods},
	volume = {18},
	issn = {1061-0421},
	url = {http://amitre.synthasite.com/resources/varian_Hal_price-info-goods.pdf},
	doi = {10.1108/10610420910981864},
	abstract = {I describe some of the issues involved in pricing information goods such as computer software, databases, electronic journals and so on. In particular I discuss the incentives to engage in differential pricing and examine some of the forms such differential pricing may take. This paper was presented at the Research LibrariesGroup Symposium on "Scholarship in theNewInformation Environment" held at Harvard Law School,May 2-3, 1995 and will be published in the conference proceedings.},
	number = {5},
	journal = {Journal of Product \& Brand Management},
	author = {Linde, Frank},
	year = {2009},
	keywords = {value of data, information goods, price discrimination, pricing},
	pages = {379--384}
}

@article{lin_information_2013,
	title = {Information preservation in statistical privacy and bayesian estimation of unattributed histograms},
	issn = {0730-8078},
	url = {http://dl.acm.org/citation.cfm?doid=2463676.2463721},
	doi = {10.1145/2463676.2463721},
	journal = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
	author = {Lin, Bing-Rong and Kifer, Daniel},
	year = {2013},
	note = {ISBN: 9781450320375},
	keywords = {formal privacy, privacy, utility, decision theory, di ff erential privacy},
	pages = {677}
}

@article{machanavajjhala_data_2009,
	title = {Data {Publishing} against {Realistic} {Adversaries}},
	issn = {2150-8097},
	doi = {10.14778/1687627.1687717},
	abstract = {Privacy in data publishing has received much attention recently. The key to defining privacy is to model knowledge of the attacker – if the attacker is assumed to know too little, the published data can be easily attacked, if the attacker is assumed to know too much, the published data has little utility. Previous work considered either quite ignorant adversaries or nearly omniscient adversaries. In this paper, we introduce a new class of adversaries that we call realistic adversaries who live in the unexplored space in between. Realistic adversaries have knowledge from external sources with an associated stubbornness indicating the strength of their knowledge. We then introduce a novel privacy framework called epsilon-privacy that allows us to guard against realistic adversaries. We also show that prior privacy definitions are instantiations of our framework. In a thorough experimental study with real census data we show that e-privacy allows us to publish data with high utility while defending against strong adversaries.},
	journal = {Proceedings of the VLDB Endowment},
	author = {Machanavajjhala, Ashwin and Gehrke, Johannes and Götz, Michaela},
	year = {2009},
	keywords = {formal privacy},
	pages = {790--801}
}

@article{li_adaptive_2012,
	title = {An adaptive mechanism for accurate query answering under differential privacy},
	volume = {5},
	issn = {2150-8097},
	url = {http://dl.acm.org/citation.cfm?id=2168653},
	doi = {10.14778/2168651.2168653},
	abstract = {We propose a novel mechanism for answering sets of count- ing queries under differential privacy. Given a workload of counting queries, the mechanism automatically selects a different set of "strategy" queries to answer privately, using those answers to derive answers to the workload. The main algorithm proposed in this paper approximates the optimal strategy for any workload of linear counting queries. With no cost to the privacy guarantee, the mechanism improves significantly on prior approaches and achieves near-optimal error for many workloads, when applied under (epsilon, delta)-differential privacy. The result is an adaptive mechanism which can help users achieve good utility without requiring that they reason carefully about the best formulation of their task.},
	number = {6},
	journal = {Proceedings of the VLDB Endowment},
	author = {Li, Chao and Miklau, Gerome},
	month = feb,
	year = {2012},
	note = {\_eprint: arXiv:1202.3807v1},
	keywords = {formal privacy},
	pages = {514--525}
}

@article{li_optimizing_2009,
	title = {Optimizing {Histogram} {Queries} under {Differential} {Privacy}},
	url = {http://arxiv.org/abs/0912.4742},
	abstract = {Differential privacy is a robust privacy standard that has been successfully applied to a range of data analysis tasks. Despite much recent work, optimal strategies for answering a collection of correlated queries are not known. We study the problem of devising a set of strategy queries, to be submitted and answered privately, that will support the answers to a given workload of queries. We propose a general framework in which query strategies are formed from linear combinations of counting queries, and we describe an optimal method for deriving new query answers from the answers to the strategy queries. Using this framework we characterize the error of strategies geometrically, and we propose solutions to the problem of finding optimal strategies.},
	journal = {ArXiv},
	author = {Li, Chao and Hay, Michael and Rastogi, Vibhor and Miklau, Gerome and McGregor, Andrew},
	year = {2009},
	note = {ISBN: 9781450300339
\_eprint: 0912.4742},
	keywords = {formal privacy, private data analysis, output perturbation, diff-, erential privacy, semidefinite program},
	pages = {22}
}

@article{kifer_private_2012,
	title = {Private {Convex} {Empirical} {Risk} {Minimization} and {High}-dimensional {Regression}},
	volume = {23},
	journal = {Journal of Machine Learning Research: Workshop and Conference Proceedings},
	author = {Kifer, Daniel and Smith, Adam and Thakurta, Abhradeep},
	year = {2012},
	keywords = {formal privacy},
	pages = {25.1--25.40}
}

@inproceedings{kifer_no_2011,
	address = {New York, NY, USA},
	series = {{SIGMOD} '11},
	title = {No free lunch in data privacy},
	isbn = {978-1-4503-0661-4},
	url = {http://doi.acm.org/10.1145/1989323.1989345},
	doi = {10.1145/1989323.1989345},
	booktitle = {Proceedings of the 2011 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM Digital Library},
	author = {Kifer, Daniel and Machanavajjhala, Ashwin},
	year = {2011},
	note = {event-place: Athens, Greece},
	keywords = {formal privacy, differential privacy, privacy},
	pages = {193--204}
}

@article{kifer_rigorous_2012,
	title = {A rigorous and customizable framework for privacy},
	url = {http://dl.acm.org/citation.cfm?doid=2213556.2213571},
	doi = {10.1145/2213556.2213571},
	journal = {Proceedings of the 31st symposium on Principles of Database Systems - PODS '12},
	author = {Kifer, Daniel and Machanavajjhala, Ashwin},
	year = {2012},
	note = {ISBN: 9781450312486},
	keywords = {formal privacy, differential privacy, privacy},
	pages = {77}
}

@article{kearns_mechanism_2014,
	title = {Mechanism design in large games: {Incentives} and privacy},
	volume = {104},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.104.5.431},
	doi = {10.1257/aer.104.5.431},
	abstract = {We study the design of mechanisms satisfying two desiderata— incentive compatibility and privacy. The first, requires that each agent should be incentivized to report her private information truthfully. The second, privacy, requires the mechanism not reveal `much' about any agent's type to other agents. We propose a notion of privacy we call Joint Differential Privacy. It is a variant of Differential Privacy, a robust notion of privacy used in the Theoretical Computer Science literature. We show by construction that such mechanisms, i.e. ones which are both incentive compatible and jointly differentially private exist when the game is `large', i.e. there are a large number of players, and any player's action affects any other's payoff by at most a small amount. Our mechanism adds carefully selected noise to no-regret algorithms similar to those studied in Foster-Vohra and Hart-Mas-Colell. It therefore implements an approximate correlated equilibrium of the full information game induced by players' reports.},
	number = {5},
	journal = {American Economic Review},
	author = {Kearns, Michael and Pai, Mallesh M. and Roth, Aaron and Ullman, Jonathan},
	year = {2014},
	note = {ISBN: 9781450326988
\_eprint: 1207.4084},
	keywords = {economics of privacy},
	pages = {431--435}
}

@inproceedings{li_optimizing_2010,
	title = {Optimizing linear counting queries under differential privacy},
	url = {http://dx.doi.org/10.1145/1807085.1807104},
	doi = {10.1145/1807085.1807104},
	abstract = {Differential privacy is a robust privacy standard that has been successfully applied to a range of data analysis tasks. But despite much recent work, optimal strategies for answering a collection of related queries are not known. We propose the matrix mechanism, a new algorithm for answering a workload of predicate counting queries. Given a workload, the mechanism requests answers to a different set of queries, called a query strategy, which are answered using the standard Laplace mechanism. Noisy answers to the workload queries are then derived from the noisy answers to the strategy queries. This two stage process can result in a more complex correlated noise distribution that preserves differential privacy but increases accuracy. We provide a formal analysis of the error of query answers produced by the mechanism and investigate the problem of computing the optimal query strategy in support of a given workload. We show this problem can be formulated as a rank-constrained semidefinite program. Finally, we analyze two seemingly distinct techniques, whose similar behavior is explained by viewing them as instances of the matrix mechanism.},
	booktitle = {Proceedings of the twenty-ninth {ACM} {SIGMOD}-{SIGACT}-{SIGART} symposium on {Principles} of database systems of data - {PODS10}},
	publisher = {Association for Computing Machinery (ACM)},
	author = {Li, Chao and Hay, Michael and Rastogi, Vibhor and Miklau, Gerome and McGregor, Andrew},
	year = {2010},
	keywords = {formal privacy, differential privacy, private data analysis, output perturbation, semidefinite program},
	pages = {123--134}
}

@article{li_xarchive_2014,
	title = {Xarchive {A} {Data}- and {Workload}-{Aware} {Algorithm} for {Range} {Queries} {Under} {Differential} {Privacy}},
	volume = {7},
	issn = {2150-8097},
	url = {http://www.vldb.org/pvldb/vol7/p341-li.pdf},
	number = {5},
	journal = {Pvldb},
	author = {Li, Chao and Hay, Michael and Miklau, Gerome and Wang, Yue},
	year = {2014},
	note = {\_eprint: arXiv:1410.0265v1},
	keywords = {formal privacy},
	pages = {341--352}
}

@article{kronman_privacy_1980,
	title = {The {Privacy} {Exemption} to the {Freedom} of {Information} {Act}},
	volume = {9},
	url = {http://www.jstor.org/stable/724180},
	number = {4},
	journal = {The Journal of Legal Studies},
	author = {Kronman, Anthony T.},
	year = {1980},
	keywords = {economics of privacy},
	pages = {727--774}
}

@article{kleinberg_value_2001,
	title = {On the {Value} of {Private} {Information}},
	doi = {10.1111/j.1467-6451.2008.00337.x},
	abstract = {As individuals increasingly take advantage of on-line services, the value of the private information they possess emerges as a problem of fundamental concern. We believe that the principle underlying privacy should be simple: Individuals are entitled to control the dissemination of private information, disclosing it as part of a transaction only when they are fairly compensated. We show how this principle can be made precise in several diverse settings — in the use of marketing surveys by a vendor designing a product; and in the design of collaborative filtering and recommendation systems, where we seek to quantify the value of each user's participation. Our approach draws on the analysis of coalitional games, making use of the core and Shapley value of such games as fair allocation principles.},
	journal = {Conference on Theoretical Aspects of Rationality and Knowledge (TARK '01)},
	author = {Kleinberg, Jon M and Papadimitriou, Christos H and Raghavan, Prabhakar},
	year = {2001},
	note = {ISBN: 1-55860-791-9},
	keywords = {value of privacy},
	pages = {249--257}
}

@article{kapteyn_interdependent_1997,
	title = {Interdependent preferences: an econometric analysis},
	volume = {12},
	issn = {1099-1255},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1255%28199711/12%2912%3A6%3C665%3A%3AAID-JAE437%3E3.0.CO%3B2-U},
	doi = {10.1002/(SICI)1099-1255(199711/12)12:6<665::AID-JAE437>3.0.CO;2-U},
	abstract = {The theoretical model of Gaertner (1974) and Pollak (1976) for the interdependence of preferences in the Linear Expenditure System is estimated for a cross-section of households. The interdependence of consumption of different households has implications for the stochastic structure of the model and for the identifiability of its parameters. Both aspects are dealt with. The empirical results indicate a significant role played by the interdependence of preferences. One of its implications is that predictions of the effects of changes in a household's exogenous variables differ according to whether the exogenous variable only changes for this household or for all households jointly. 1997 John Wiley \& Sons, Ltd.},
	number = {6},
	journal = {Journal of Applied Econometrics},
	author = {Kapteyn, Arie and Van de Geer, Sara and Van De Stadt, Huib and Wansbeek, Tom},
	year = {1997},
	note = {Publisher: John Wiley \& Sons, Ltd.},
	keywords = {households, interdependence of preferences, Linear expenditure system},
	pages = {665--686}
}

@article{hyatt_job--job_2014,
	title = {Job-to-job (j2j) flows: new labor market statistics from linked employer-employee data},
	url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2523490},
	doi = {10.2139/ssrn.2523490},
	journal = {US Census Bureau Center for Economic Studies Paper CES-WP-14-34},
	author = {Hyatt, Henry R. and McEntarfer, Erika and McKinney, Kevin and Tibbets, Stephen and Walton, Doug},
	year = {2014}
}

@article{hundepool_statistical_2012,
	title = {Statistical disclosure control},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781118348239},
	doi = {10.1002/9781118348239},
	abstract = {"This handbook provides technical guidance on statistical disclosure control and on how to approach the problem of balancing the need to provide users with statistical outputs and the need to protect the confidentiality of respondents.Statistical disclosure control is combined with other tools such as administrative, legal and IT in order to define a proper data dissemination strategy based on a risk management approach. The key concepts of statistical disclosure control are presented, along with the methodology and software that can be used to apply various methods of statistical disclosure control.Examples will also be used to illustrate methods described in the book. The handbook is based upon material prepared by the leading National Institute of Statistics in Europe. The context is relevant globally, not just within the EU. "–},
	journal = {Wiley series in survey methodology},
	author = {Hundepool, Anco et al.},
	year = {2012},
	pmid = {17275773},
	note = {ISBN: 9781118348239},
	keywords = {SDL, statistical disclosure limitation, Confidential communications Statistical services., MATHEMATICS / Probability \& Statistics / General}
}

@article{holbrook_social_2010,
	title = {Social desirability bias in voter turnout reports: tests using the item count technique},
	volume = {74},
	url = {https://academic.oup.com/poq/article/74/1/37/1841959},
	doi = {10.1093/poq/nfp065},
	abstract = {Surveys usually yield rates of voting in elections that are higher than official turnout figures, a phenomenon often attributed to intentional misrepresentation by respondents who did not vote and would be embarrassed to admit that. The experiments reported here tested the social desirability response bias hypothesis directly by implementing a technique that allowed respondents to report secretly whether they voted: the "item count technique." The item count technique significantly reduced turnout reports in a national telephone survey relative to direct self-reports, suggesting that social desirability response bias influenced direct self-reports in that survey. But in eight national surveys of American adults conducted via the Internet, the item count technique did not significantly reduce turnout reports. This mode difference is consistent with other evidence that the Internet survey mode may be less susceptible to social desirability response bias because of self-administration.},
	number = {1},
	journal = {Public Opinion Quarterly},
	author = {Holbrook, Allyson L. and Krosnick, Jon A.},
	year = {2010},
	note = {\_eprint: http://poq.oxfordjournals.org/content/74/1/37.full.pdf+html},
	pages = {37--67}
}

@article{hui_economics_2006,
	title = {The {Economics} of {Privacy}},
	url = {https://papers.ssrn.com/soL3/papers.cfm?abstract_id=786846},
	abstract = {Privacy of personal information is an area of growing concern and importance in the digital age. Privacy as an issue rises when there is a conflict of interest between its commercial value and respect for an individual's right to privacy. This tends itself to the fact this trade off is of economic value and the issue of privacy is an economic problem and hence justifies the emergence of the economics of privacy as an important discipline which is a complex interplay of regulation, technology and people dynamics and the efficiency of doing business. In this survey paper we look into the work done by eminent people on the issue of privacy and its relationship with people, technology and regulation from an economic perspective and its increasing relevance today. Privacy affects each one of us in some way that we cannot afford to ignore it and it helps to be in cognizance of what is going on around us.},
	journal = {Handbooks in Information Systems, Economics and Information Systems},
	author = {Hui, Kai-Lung and Png, I P L and Camp, Thank Jean and Hahn, Robert and Jamal, Karim and Wathieu, Luc and Hendershott, Terry},
	year = {2006},
	keywords = {economics of privacy},
	pages = {471--493}
}

@article{hu_dirichlet_2015,
	title = {Dirichlet process mixture models for nested categorical data},
	url = {http://arxiv.org/abs/1412.2282v3},
	abstract = {We present a Bayesian model for estimating the joint distribution of multivariate categorical data when units are nested within groups. Such data arise frequently in social science settings, for example, people living in households. The model assumes that (i) each group is a member of a group-level latent class, and (ii) each unit is a member of a unit-level latent class nested within its group-level latent class. This structure allows the model to capture dependence among units in the same group. It also facilitates simultaneous modeling of variables at both group and unit levels. We develop a version of the model that assigns zero probability to groups and units with physically impossible combinations of variables. We apply the model to estimate multivariate relationships in a subset of the American Community Survey. Using the estimated model, we generate synthetic household data that could be disseminated as redacted public use files with high analytic validity and low disclosure risks. Supplementary materials for this article are available online.},
	journal = {ArXiv},
	author = {Hu, J. and Reiter, J.P. and Wang, Q.},
	year = {2015},
	keywords = {SDL, statistical disclosure limitation}
}

@article{hay_principled_2016,
	title = {Principled evaluation of differentially private algorithms using dpbench},
	url = {http://arxiv.org/pdf/1512.04817v1.pdf},
	doi = {10.1145/2882903.2882931},
	abstract = {Differential privacy has become the dominant standard in the research community for strong privacy protection. There has been a flood of research into query answering algorithms that meet this standard. Algorithms are becoming increasingly complex, and in particular, the performance of many emerging algorithms is {\textbackslash}em data dependent, meaning the distribution of the noise added to query answers may change depending on the input data. Theoretical analysis typically only considers the worst case, making empirical study of average case performance increasingly important. In this paper we propose a set of evaluation principles which we argue are essential for sound evaluation. Based on these principles we propose DPBench, a novel evaluation framework for standardized evaluation of privacy algorithms. We then apply our benchmark to evaluate algorithms for answering 1- and 2-dimensional range queries. The result is a thorough empirical study of 15 published algorithms on a total of 27 datasets that offers new insights into algorithm behavior—in particular the influence of dataset scale and shape—and a more complete characterization of the state of the art. Our methodology is able to resolve inconsistencies in prior empirical studies and place algorithm performance in context through comparison to simple baselines. Finally, we pose open research questions which we hope will guide future algorithm design.},
	journal = {SIGMOD},
	author = {Hay, Michael and Machanavajjhala, Ashwin and Miklau, Gerome and Chen, Yan and Zhang, Dan},
	year = {2016},
	keywords = {formal privacy}
}

@article{hardt_beyond_2013,
	title = {Beyond worst-case analysis in private singular vector computation},
	issn = {0737-8017},
	url = {http://dl.acm.org/citation.cfm?doid=2488608.2488650},
	doi = {10.1145/2488608.2488650},
	abstract = {We consider differentially private approximate singular vector computation. Known worst-case lower bounds show that the error of any differentially private algorithm must scale polynomially with the dimension of the singular vector. We are able to replace this dependence on the dimension by a natural parameter known as the coherence of the matrix that is often observed to be significantly smaller than the dimension both theoretically and empirically. We also prove a matching lower bound showing that our guarantee is nearly optimal for every setting of the coherence parameter. Notably, we achieve our bounds by giving a robust analysis of the well-known power iteration algorithm, which may be of independent interest. Our algorithm also leads to improvements in worst-case settings and to better low-rank approximations in the spectral norm.},
	journal = {Stoc},
	author = {Hardt, Moritz and Roth, Aaron},
	year = {2013},
	note = {ISBN: 9781450320290
\_eprint: 1211.0975},
	keywords = {formal privacy, differential privacy, singular value decomposition},
	pages = {331}
}

@inproceedings{hay_principled_2014,
	title = {Principled evaluation of differentially private algorithms [ {Experiments} and {Analysis} {Paper} ]},
	volume = {7},
	url = {https://dl.acm.org/citation.cfm?id=2882931},
	doi = {10.1145/2882903.2882931},
	booktitle = {Proceedings - {International} {Conference} on {Very} {Large} {Data} {Bases}},
	author = {Hay, Michael and Machanavajjhala, Ashwin and Miklau, Gerome and Chen, Yan and Zhang, Dan},
	year = {2014},
	note = {Issue: 5}
}

@article{hastie_elements_2009,
	title = {The {Elements} of {Statistical} {Learning}},
	volume = {1},
	issn = {0343-6993},
	url = {https://link.springer.com/book/10.1007%2F978-0-387-84858-7},
	doi = {10.1007/b94608},
	abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
	journal = {Elements},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	pmid = {15512507},
	note = {ISBN: 9780387848570},
	keywords = {reference},
	pages = {337--387}
}

@article{hardt_simple_2010,
	title = {A simple and practical algorithm for differentially private data release},
	volume = {abs/1012.4763},
	url = {http://papers.nips.cc/paper/4548-a-simple-and-practical-algorithm-for-differentially-private-data-release},
	journal = {CoRR},
	author = {Hardt, Moritz and Ligett, Katrina and McSherry, Frank},
	year = {2010}
}

@article{gupta_iterative_2012-1,
	title = {Iterative constructions and private data release},
	volume = {7194 LNCS},
	issn = {0302-9743},
	url = {https://link.springer.com/chapter/10.1007%2F978-3-642-28914-9_19},
	doi = {10.1007/978-3-642-28914-9_19},
	abstract = {In this paper we study the problem of approximately releasing the cut function of a graph while preserving differential privacy, and give new algorithms (and new analyses of existing algorithms) in both the interactive and non-interactive settings. Our algorithms in the interactive setting are achieved by revisiting the problem of releasing differentially private, approximate answers to a large number of queries on a database. We show that several algorithms for this problem fall into the same basic framework, and are based on the existence of objects which we call iterative database construction algorithms. We give a new generic framework in which new (efficient) IDC algorithms give rise to new (efficient) interactive private query release mechanisms. Our modular analysis simplifies and tightens the analysis of previous algorithms, leading to improved bounds. We then give a new IDC algorithm (and therefore a new private, interactive query release mechanism) based on the Frieze/Kannan low-rank matrix decomposition. This new release mechanism gives an improvement on prior work in a range of parameters where the size of the database is comparable to the size of the data universe (such as releasing all cut queries on dense graphs). We also give a non-interactive algorithm for efficiently releasing private synthetic data for graph cuts with error O({\textbar}V{\textbar}{\textasciicircum}\{1.5\}). Our algorithm is based on randomized response and a non-private implementation of the SDP-based, constant-factor approximation algorithm for cut-norm due to Alon and Naor. Finally, we give a reduction based on the IDC framework showing that an efficient, private algorithm for computing sufficiently accurate rank-1 matrix approximations would lead to an improved efficient algorithm for releasing private synthetic data for graph cuts. We leave finding such an algorithm as our main open problem.},
	journal = {Lecture Notes in Computer Science},
	author = {Gupta, Anupam and Roth, Aaron and Ullman, Jonathan},
	year = {2012},
	note = {ISBN: 9783642289132
\_eprint: 1107.3731},
	pages = {339--356}
}

@article{baumol_macroeconomics_1967,
	title = {Macroeconomics of {Unbalanced} {Growth}: {The} {Anatomy} of {Urban} {Crisis}},
	volume = {57},
	url = {http://www.jstor.org/stable/1812111},
	number = {3},
	journal = {American Economic Review},
	author = {Baumol, William J.},
	year = {1967},
	pages = {415--426}
}

@article{golle_anonymity_2009,
	title = {On the anonymity of home/work location pairs},
	volume = {5538 LNCS},
	issn = {0302-9743},
	url = {https://link.springer.com/chapter/10.1007%2F978-3-642-01516-8_26},
	doi = {10.1007/978-3-642-01516-8_26},
	abstract = {Many applications benefit from user location data, but location data raises privacy concerns. Anonymization can protect privacy, but identities can sometimes be inferred from supposedly anonymous data. This paper studies a new attack on the anonymity of location data. We show that if the approximate locations of an individual's home and workplace can both be deduced from a location trace, then the median size of the individual's anonymity set in the U.S. working population is 1, 21 and 34,980, for locations known at the granularity of a census block, census track and county respectively. The location data of people who live and work in different regions can be re-identified even more easily. Our results show that the threat of re-identification for location data is much greater when the individual's home and work locations can both be deduced from the data. To preserve anonymity, we offer guidance for obfuscating location traces before they are disclosed.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Golle, Philippe and Partridge, Kurt},
	year = {2009},
	note = {ISBN: 9783642015151},
	keywords = {formal privacy},
	pages = {390--397}
}

@article{goldwasser_probabilistic_1982,
	title = {Probabilistic encryption \& how to play mental poker keeping secret all partial information},
	url = {http://dl.acm.org/citation.cfm?id=802212},
	doi = {10.1145/800070.802212},
	abstract = {This paper proposes an Encryption Scheme that possess the following property : An adversary, who knows the encryption algorithm and is given the cyphertext, cannot obtain any information about the clear-text. Any implementation of a Public Key Cryptosystem, as proposed by Diffie and Hellman in 8, should possess this property. Our Encryption Scheme follows the ideas in the number theoretic implementations of a Public Key Cryptosystem due to Rivest, Shamir and Adleman 13, and Rabin 12.},
	journal = {STOC '82 Proceedings of the fourteenth annual ACM symposium on Theory of computing},
	author = {Goldwasser, Shaft and Micali, Silvio},
	year = {1982},
	note = {ISBN: 0897910672},
	keywords = {formal privacy},
	pages = {365--377}
}

@inproceedings{ghosh_selling_2011-1,
	address = {New York, NY, USA},
	series = {{EC} '11},
	title = {Selling privacy at auction},
	isbn = {978-1-4503-0261-6},
	url = {https://dl.acm.org/citation.cfm?doid=1993574.1993605},
	doi = {10.1145/1993574.1993605},
	booktitle = {Proceedings of the 12th {ACM} conference on {Electronic} commerce},
	publisher = {ACM},
	author = {Ghosh, Arpita and Roth, Aaron},
	year = {2011},
	note = {event-place: San Jose, California, USA},
	keywords = {differential privacy, economics of privacy, auctions},
	pages = {199--208}
}

@article{gelman_statistical_2014,
	title = {The statistical crisis in science},
	volume = {102},
	url = {https://www.americanscientist.org/article/the-statistical-crisis-in-science},
	doi = {DOI: 10.1511/2014.111.460},
	number = {6},
	journal = {American Scientist},
	author = {Gelman, Andrew and Loken, Eric},
	year = {2014},
	keywords = {misc},
	pages = {460--465}
}

@article{gould_privacy_1980,
	title = {Privacy and the {Economics} of {Information}},
	volume = {9},
	issn = {0047-2530},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/467668?journalCode=jls},
	doi = {10.1086/467668},
	abstract = {Focus on teh relationship of externalities and the production of information},
	number = {4},
	journal = {The Journal of Legal Studies},
	author = {Gould, John},
	year = {1980},
	keywords = {economics of privacy},
	pages = {827--842}
}

@article{goldwasser_probabilistic_1984,
	title = {Probabilistic encryption},
	volume = {28},
	issn = {0022-0000},
	url = {http://www.sciencedirect.com/science/article/pii/0022000084900709},
	doi = {10.1016/0022-0000(84)90070-9},
	abstract = {A new probabilistic model of data encryption is introduced. For this model, under suitable complexity assumptions, it is proved that extracting any information about the cleartext from the cyphertext is hard on the average for an adversary with polynomially bounded computational resources. The proof holds for any message space with any probability distribution. The first implementation of this model is presented. The security of this implementation is proved under the interactability assumptin of deciding Quadratic Residuosity modulo composite numbers whose factorization is unknown.},
	number = {2},
	journal = {Journal of Computer and System Sciences},
	author = {Goldwasser, Shafi and Micali, Silvio},
	year = {1984},
	keywords = {formal privacy},
	pages = {270--299}
}

@book{goldfarb_economic_2015,
	title = {Economic {Analysis} of the {Digital} {Economy}},
	isbn = {978-0-226-20684-4},
	url = {https://books.google.co.uk/books?id=6jPBBwAAQBAJ},
	author = {Goldfarb, A and Greenstein, S M and Tucker, C E},
	year = {2015},
	doi = {10.7208/chicago/9780226206981.001.0001},
	keywords = {economics of privacy}
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G?=F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster tomake careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed.We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
	number = {477},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E},
	year = {2007},
	keywords = {bayes factor, bregman divergence, brier score, coherent, continuous ranked probability score, cross-validation, distribution, entropy, kernel score, loss function, minimum contrast estimation, negative definite function, prediction interval, predictive, quantile forecast, scoring rule, skill score, strictly proper, utility function},
	pages = {359--378}
}

@book{nissenbaum_privacy_2009,
	address = {Stanford, CA, USA},
	title = {Privacy in {Context}: {Technology}, {Policy}, and the {Integrity} of {Social} {Life}},
	isbn = {0-8047-5237-0 978-0-8047-5237-4},
	publisher = {Stanford University Press},
	author = {Nissenbaum, Helen},
	year = {2009}
}

@techreport{neel_mitigating_2018,
	title = {Mitigating {Bias} in {Adaptive} {Data} {Gathering} via {Differential} {Privacy}},
	institution = {arXiv},
	author = {Neel, Seth and Roth, Aaron},
	year = {2018},
	keywords = {formal privacy, data unions}
}

@techreport{ligett_accuracy_2017,
	title = {Accuracy {First}: {Selecting} a {Differential} {Privacy} {Level} for {Accuracy}-{Constrained} {ERM}},
	number = {1705.10829v1},
	institution = {arXiv},
	author = {Ligett, Katrina and Neel, Seth and Roth, Aaron and Waggoner, Bo and Wu, Z. Steven},
	month = may,
	year = {2017}
}

@article{kamenica_bayesian_2011,
	title = {Bayesian {Persuasion}},
	volume = {101},
	doi = {10.1257/aer.101.6.2590},
	number = {6},
	journal = {American Economic Review},
	author = {Kamenica, Emir and Gentzkow, Matthew},
	month = oct,
	year = {2011},
	note = {Publisher: American Economic Association},
	keywords = {value of data, data unions},
	pages = {2590--2615}
}

@article{miller_privacy_2018,
	title = {Privacy {Protection}, {Personalized} {Medicine}, and {Genetic} {Testing}},
	volume = {64},
	doi = {10.1287/mnsc.2017.2858},
	number = {10},
	journal = {Management Science},
	author = {Miller, Amalia R. and Tucker, Catherine},
	month = oct,
	year = {2018},
	note = {Publisher: Institute for Operations Research and the Management Sciences (INFORMS)},
	keywords = {value of data},
	pages = {4648--4668}
}

@article{lanier_blueprint_2018,
	title = {A {Blueprint} for a {Better} {Digital} {Society}},
	journal = {Harvard Business Review},
	author = {Lanier, Jaron and Weyl, E. Glen},
	year = {2018},
	keywords = {data unions}
}

@techreport{kiefer_effective_2019,
	title = {{EFFECTIVE} {PRIVACY} {AFTER} {ADJUSTING} {FOR} {CONSTRAINTS}, {WITH} {APPLICATIONS} {TO} {THE} 2020 {CENSUS}},
	abstract = {Differential privacy is a mathematical tool for protecting the confidentiality of records belong- T ing to individuals. One of the key premises of differential privacy is that any measurement based on theU confidential data must be altered with carefully chosen random noise before publication. However, theBde- ployment of differentially private disclosure limitation technologies by official statistical agencies maIy not always occur under ideal conditions. For instance, internal decisions or external requirements (e.g.,Rlegal or contractual obligations) may stipulate that certain statistics must be published exactly. AdditioTnally, over- lapping datasets may have already been published. In this paper, we explain (1) the semanticsSof algorithms that satisfy differential privacy, (2) how the semantics are affected by release of exact statiIstics (computed directly from the confidential data), (3) how to attribute responsibility for any resulting inDformation leakage, (4) how to provide privacy semantics for the combined information leakage.},
	institution = {U.S. Census Bureau},
	author = {Kiefer, Daniel and Machanavajjhala, Ashwin and Leclerc, Philip and Sexton, William and Ashmead, Robert},
	year = {2019}
}

@techreport{frankel_quantifying_2018,
	title = {Quantifying information and uncertainty},
	institution = {University of Chicago},
	author = {Frankel, Alexander and Kamenica, Emir},
	year = {2018},
	keywords = {value of data, data unions, value of information, entropy, Bregman divergences}
}

@techreport{andrews_inference_2018,
	title = {Inference on winners},
	institution = {Institute for Fiscal Studies},
	author = {Andrews, Isaiah and Kitagawa, Toru and McCloskey, Adam},
	year = {2018}
}

@book{oecd_data-driven_2015,
	title = {Data-{Driven} {Innovation}},
	url = {https://www.oecd-ilibrary.org/content/publication/9789264229358-en},
	author = {{OECD}},
	year = {2015},
	doi = {10.1787/9789264229358-en},
	keywords = {value of data}
}

@article{gentzkow_rothschild-stiglitz_2016,
	title = {A {Rothschild}-{Stiglitz} {Approach} to {Bayesian} {Persuasion}},
	volume = {106},
	doi = {10.1257/aer.p20161049},
	number = {5},
	journal = {American Economic Review},
	author = {Gentzkow, Matthew and Kamenica, Emir},
	month = may,
	year = {2016},
	note = {Publisher: American Economic Association},
	keywords = {value of data, data unions},
	pages = {597--601}
}

@article{craft_value_1998,
	title = {The {Value} of {Weather} {Information} {Services} for {Nineteenth}-{Century} {Great} {Lakes} {Shipping}},
	volume = {88},
	url = {https://EconPapers.repec.org/RePEc:aea:aecrev:v:88:y:1998:i:5:p:1059-76},
	abstract = {The U.S. government established a national weather organization in 1870. Changes in Great Lakes cargo and hull losses, and shipping rates from Chicago to Buffalo, provide evidence of the value of storm warnings on the Great Lakes. Nearly half of the Great Lakes storm-warning stations were closed during the fall of 1883 because of appropriations reductions. This exogenous shock permits the econometric estimation of the value of storm-warning locations on the Great Lakes. The results indicate that the social rate of return for weather expenditures during the Weather Bureau's founding period was at least 60 percent. Copyright 1998 by American Economic Association.},
	number = {5},
	journal = {American Economic Review},
	author = {Craft, Erik D},
	year = {1998},
	keywords = {value of data},
	pages = {1059--76}
}

@techreport{bergemann_markets_2018,
	type = {Cowles {Foundation} {Discussion} {Paper}},
	title = {Markets for {Information}: {An} {Introduction}},
	number = {2142},
	institution = {Cowles Foundation},
	author = {Bergemann, Dick and Bonatti, Alessandro},
	month = aug,
	year = {2018},
	keywords = {value of data, data unions}
}

@article{kim_screening_2015,
	title = {Screening incentives and privacy protection in financial markets: a theoretical and empirical analysis},
	volume = {46},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1756-2171.12083},
	doi = {10.1111/1756-2171.12083},
	abstract = {We study a model in which firms offer financial products to individuals, post prices for their products, and screen consumers who apply to purchase them. Any information obtained in the screening process may be traded to another firm selling related products. We show that firms' ability to sell consumer information can lead to lower prices, higher screening intensities, and increased social welfare. By exploiting variations in the adoption of local financial-privacy ordinances in five California Bay Area counties, we are able to provide simple estimates of the effects of stricter financial-privacy laws on mortgage denial rates during 2001?2006. Consistent with the model's predictions, denial rates for home-purchase loans and refinancing loans decreased in counties where opt-in privacy ordinances were adopted. Moreover, estimated foreclosure start rates during the financial crisis of 2007?2008 were higher in counties where the privacy ordinance was adopted.},
	number = {1},
	journal = {The RAND Journal of Economics},
	author = {Kim, Jin-Hyuk and Wagman, Liad},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1756-2171.12083},
	keywords = {economics of privacy},
	pages = {1--22}
}

@article{brynjolfsson_rapid_2016,
	title = {The {Rapid} {Adoption} of {Data}-{Driven} {Decision}-{Making}},
	volume = {106},
	url = {http://www.aeaweb.org/articles?id=10.1257/aer.p20161016},
	doi = {10.1257/aer.p20161016},
	number = {5},
	journal = {American Economic Review},
	author = {Brynjolfsson, Erik and McElheran, Kristina},
	month = may,
	year = {2016},
	keywords = {value of data},
	pages = {133--39}
}

@techreport{brynjolfsson_data_2016,
	type = {Working {Papers}},
	title = {Data in {Action}: {Data}-{Driven} {Decision} {Making} in {U}.{S}. {Manufacturing}},
	url = {https://EconPapers.repec.org/RePEc:cen:wpaper:16-06},
	institution = {U.S. Census Bureau, Center for Economic Studies},
	author = {Brynjolfsson, Erik and McElheran, Kristina},
	year = {2016},
	doi = {10.2139/ssrn.2722502},
	keywords = {value of data}
}

@article{goldfarb_privacy_2011,
	title = {Privacy {Regulation} and {Online} {Advertising}},
	volume = {57},
	url = {https://EconPapers.repec.org/RePEc:inm:ormnsc:v:57:y:2011:i:1:p:57-71},
	abstract = {Advertisers use online customer data to target their marketing appeals. This has heightened consumers' privacy concerns, leading governments to pass laws designed to protect consumer privacy by restricting the use of data and by restricting online tracking techniques used by websites. We use the responses of 3.3 million survey takers who had been randomly exposed to 9,596 online display (banner) advertising campaigns to explore how privacy regulation in the European Union (EU) has influenced advertising effectiveness. This privacy regulation restricted advertisers' ability to collect data on Web users in order to target ad campaigns. We find that, on average, display advertising became far less effective at changing stated purchase intent after the EU laws were enacted, relative to display advertising in other countries. The loss in effectiveness was more pronounced for websites that had general content (such as news sites), where non-data-driven targeting is particularly hard to do. The loss of effectiveness was also more pronounced for ads with a smaller presence on the webpage and for ads that did not have additional interactive, video, or audio features. This paper was accepted by Pradeep Chintagunta, marketing.},
	number = {1},
	journal = {Management Science},
	author = {Goldfarb, Avi and Tucker, Catherine},
	year = {2011},
	keywords = {economics, economics of privacy, privacy, online advertising, targeting},
	pages = {57--71}
}

@inproceedings{ramachandran_exploring_2012,
	title = {Exploring re-identification risks in public domains},
	doi = {10.1109/PST.2012.6297917},
	abstract = {While re-identification of sensitive data has been studied extensively, with the emergence of online social networks and the popularity of digital communications, the ability to use public data for re-identification has increased. This work begins by presenting two different cases studies for sensitive data re-identification. We conclude that targeted re-identification using traditional variables is not only possible, but fairly straightforward given the large amount of public data available. However, our first case study also indicates that large-scale re-identification is less likely. We then consider methods for agencies such as the Census Bureau to identify variables that cause individuals to be vulnerable without testing all combinations of variables. We show the effectiveness of different strategies on a Census Bureau data set and on a synthetic data set.},
	booktitle = {2012 {Tenth} {Annual} {International} {Conference} on {Privacy}, {Security} and {Trust}},
	author = {Ramachandran, A. and Singh, L. and Porter, E. and Nagle, F.},
	year = {2012},
	keywords = {SDL, statistical disclosure limitation, Data privacy, Accuracy, Databases, census bureau data set, data reidentification risk, digital communication, Facebook, large-scale reidentification, online social network, public data, public domain, security of data, sensitive data reidentification, social networking (online), Sociology, Twitter},
	pages = {35--42}
}

@book{us_supreme_court_department_1999,
	title = {{DEPARTMENT} {OF} {COMMERCE} v. {UNITED} {STATES} {HOUSE} (98-404) {No}. 98—404, 11 {F}. {Supp}. 2d 76, appeal dismissed; {No}. 98—564, 19 {F}. {Supp}. 2d 543, affirmed.},
	url = {https://www.law.cornell.edu/supct/html/98-404.ZO.html},
	author = {{U.S.{\textbackslash} Supreme Court}},
	month = jan,
	year = {1999},
	keywords = {policy}
}

@techreport{us_census_bureau_census_2017,
	title = {Census {Scientific} {Advisory} {Committee}},
	url = {https://www.census.gov/about/cac/sac/meetings/2017-09-meeting.html},
	institution = {U.S. Commerce Department},
	author = {{U.S. Census Bureau}},
	month = sep,
	year = {2017},
	keywords = {policy}
}

@book{cormen_introduction_2009,
	edition = {3rd Edition},
	title = {Introduction to {Algorithms}},
	isbn = {978-0-262-03384-8},
	publisher = {The MIT Press},
	author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
	year = {2009}
}

@book{us_census_bureau_census_2002,
	title = {Census {Confidentiality} and {Privacy} 1790 to 2002},
	url = {https://www.census.gov/prod/2003pubs/conmono2.pdf},
	publisher = {Department of Commerce},
	author = {{U.S. Census Bureau}},
	year = {2002}
}

@book{office_of_management_and_budget_revisions_1997,
	title = {Revisions to the {Standards} for the {Classification} of {Federal} {Data} on {Race} and {Ethnicity}},
	url = {https://obamawhitehouse.archives.gov/omb/fedreg_1997standards},
	author = {{Office of Management and Budget}},
	month = oct,
	year = {1997}
}

@book{irs_statistics_of_income_soi_2018,
	title = {{SOI} {Products} and {Services}},
	url = {https://www.irs.gov/pub/irs-soi/12otproductswinbul.pdf},
	author = {{IRS Statistics of Income}},
	year = {2018}
}

@article{rivest_method_1978,
	title = {A {Method} for {Obtaining} {Digital} {Signatures} and {Public}-key {Cryptosystems}},
	volume = {21},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359340.359342},
	doi = {10.1145/359340.359342},
	number = {2},
	journal = {Commun. ACM},
	author = {Rivest, R. L. and Shamir, A. and Adleman, L.},
	month = feb,
	year = {1978},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {privacy, cryptography, security, authentication, digital signatures, electronic funds transfer, electronic mail, factorization, message-passing, prime number, public-key cryptosystems},
	pages = {120--126}
}

@book{us_supreme_court_utah_2002,
	title = {{UTAH} {V}. {EVANS} (01-714) 536 {U}.{S}. 452 182 {F}. {Supp}. 2d 1165, affirmed.},
	url = {https://www.law.cornell.edu/supct/html/01-714.ZS.html},
	author = {{U.S.{\textbackslash} Supreme Court}},
	month = jun,
	year = {2002},
	keywords = {policy}
}

@article{hoxby_comments_2015,
	title = {Comments and {Discussion}},
	volume = {2015},
	url = {https://www.jstor.org/stable/43684104?seq=1#metadata_info_tab_contents},
	doi = {10.1353/eca.2016.0006},
	number = {1},
	journal = {Brookings Papers on Economic Activity},
	author = {Hoxby, Caroline and Stevenson, Betsy},
	year = {2015},
	pages = {268--293}
}

@book{data_stewardship_executive_policy_committee_ds-22_2014,
	title = {{DS}-22 {Data} {Breach} {Policy} {Addendum}},
	url = {https://www2.census.gov/foia/ds_policies/ds022.pdf},
	author = {{Data Stewardship Executive Policy Committee}},
	month = feb,
	year = {2014},
	keywords = {policy}
}

@book{donovan_memorandum_2017,
	title = {Memorandum {M}-17-12 {Preparing} for and {Responding} to a {Breach} of {Personally} {Identifiable} {Information}},
	url = {https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2017/m-17-12_0.pdf},
	author = {Donovan, Shaun},
	month = jan,
	year = {2017},
	keywords = {policy}
}

@book{national_bureau_of_economic_research_us_2017,
	title = {U.{S}.{\textbackslash} {Individual} {Income} {Tax} {Public} {Use} {Sample} {Documentation}},
	url = {https://users.nber.org/ taxsim/gdb/},
	author = {{National Bureau of Economic Research}},
	month = jan,
	year = {2017}
}

@article{perlman_continuous_1951,
	title = {The {Continuous} {Work}-{History} {Sample}: {The} {First} 12 {Years}},
	volume = {14},
	number = {4},
	journal = {Social Security Bulletin},
	author = {Perlman, Jacob},
	month = apr,
	year = {1951},
	pages = {3--10}
}

@techreport{us_department_of_agriculture_food_and_nutrition_research_service_office_of_research_nutrition_and_analysis_school_2008,
	title = {School {Lunch} and {Breakfast} {Cost} {Study} {II}, {Final} {Report}},
	number = {CN-08-MCII},
	institution = {Special Nutition Programs},
	author = {{U.S. Department of Agriculture, Food and Nutrition Research Service, Office of Research, Nutrition and Analysis}},
	month = apr,
	year = {2008},
	keywords = {'}
}

@article{feenberg_introduction_1993,
	title = {An {Introduction} to the {TAXSIM} {Model}},
	volume = {12},
	url = {http://users.nber.org/ taxsim/feenberg-coutts.pdf},
	number = {1},
	journal = {Journal of Policy Analysis and Management},
	author = {Feenberg, Daniel and Coutts, Elisabeth},
	year = {1993},
	pages = {189--194}
}

@article{mandel_oasi_1950,
	title = {{OASI} {Earnings} {Statistics} and {Their} {Uses}},
	volume = {70},
	issn = {00981818, 19374658},
	url = {http://www.jstor.org/stable/41832028},
	number = {4},
	journal = {Monthly Labor Review},
	author = {Mandel, B. J.},
	year = {1950},
	note = {Publisher: Bureau of Labor Statistics, U.S. Department of Labor},
	pages = {421--425}
}

@article{buckler_commentary_1988,
	title = {Commentary: {Continuous} {Work} {History} {Sample}},
	volume = {51},
	number = {4},
	journal = {Social Security Bulletin},
	author = {Buckler, Warren},
	month = apr,
	year = {1988},
	pages = {12, 56}
}

@article{topel_job_1992,
	title = {Job {Mobility} and the {Careers} of {Young} {Men}},
	volume = {107},
	url = {http://dx.doi.org/10.2307/2118478},
	doi = {10.2307/2118478},
	number = {2},
	journal = {The Quarterly Journal of Economics},
	author = {Topel, Robert H. and Ward, Michael P.},
	year = {1992},
	note = {\_eprint: /oup/backfile/content\_public/journal/qje/107/2/10.2307/2118478/2/107-2-439.pdf},
	pages = {439--479}
}

@article{perlman_continuous_1944,
	title = {The {Continuous} {Work} {History} {Sample} {Under} {Old}-{Age} and {Survivors} {Insurance}},
	volume = {7},
	number = {2},
	journal = {Social Security Bulletin},
	author = {Perlman, Jacob and Mandel, Benjamin},
	month = feb,
	year = {1944},
	pages = {12--22}
}

@article{smith_social_1989,
	title = {The {Social} {Security} {Administration}'s {Continuous} {Work} {History} {Sample}},
	volume = {52},
	number = {10},
	journal = {Social Security Bulletin},
	author = {Smith, Chreston M.},
	month = oct,
	year = {1989},
	pages = {20--28}
}

@book{national_institutes_of_health_nih_2014,
	title = {{NIH} {Genomic} {Data} {Sharing} {Policy}},
	url = {https://grants.nih.gov/grants/guide/notice-files/NOT-OD-14-124.html},
	author = {{National Institutes of Health}},
	month = aug,
	year = {2014},
	keywords = {official statistics}
}

@techreport{us_census_bureau_2010_2012,
	title = {2010 {Census} {Summary} {File1}–{Technical} {Documentation}},
	url = {https://www.census.gov/prod/cen2010/doc/sf1.pdf},
	institution = {Department of Commerce, Economics and Statistics Administration},
	author = {{U.S. Census Bureau}},
	year = {2012}
}

@article{homer_resolving_2008,
	title = {Resolving {Individuals} {Contributing} {Trace} {Amounts} of {DNA} to {Highly} {Complex} {Mixtures} {Using} {High}-{Density} {SNP} {Genotyping} {Microarrays}},
	volume = {4},
	url = {https://doi.org/10.1371/journal.pgen.1000167},
	doi = {10.1371/journal.pgen.1000167},
	abstract = {Author Summary In this report we describe a framework for accurately and robustly resolving whether individuals are in a complex genomic DNA mixture using high-density single nucleotide polymorphism (SNP) genotyping microarrays. We develop a theoretical framework for detecting an individual's presence within a mixture, show its limits through simulation, and finally demonstrate experimentally the identification of the presence of genomic DNA of individuals within a series of highly complex genomic mixtures. Our approaches demonstrate straightforward identification of trace amounts ({\textless}1 pct) of DNA from an individual contributor within a complex mixture. We show how probe-intensity analysis of high-density SNP data can be used, even given the experimental noise of a microarray. We discuss the implications of these findings in two fields: forensics and genome-wide association (GWA) genetic studies. Within forensics, resolving whether an individual is contributing trace amounts of genomic DNA to a complex mixture is a tremendous challenge. Within GWA studies, there is a considerable push to make experimental data publicly available so that the data can be combined with other studies. Our findings show that such an approach does not completely conceal identity, since it is straightforward to assess the probability that a person or relative participated in a GWA study.},
	number = {8},
	journal = {PLOS Genetics},
	author = {Homer, Nils and Szelinger, Szabolcs and Redman, Margot and Duggan, David and Tembe, Waibhav and Muehling, Jill and Pearson, John V. and Stephan, Dietrich A. and Nelson, Stanley F. and Craig, David W.},
	year = {2008},
	note = {Publisher: Public Library of Science},
	pages = {1--9}
}

@book{agencies_principles_2013,
	title = {Principles {Governing} {International} {Statistical} {Activities}},
	url = {https://unstats.un.org/unsd/methods/statorg/principles_stat_activities/principles_stat_activities.pdf},
	author = {agencies, Chief Statisticians or Coordinators of statistical activities of United Nations},
	year = {2013},
	keywords = {policy}
}

@book{assembly_fundamental_2014,
	title = {Fundamental {Principles} of {Official} {Statistics}},
	url = {https://unstats.un.org/unsd/dnss/gp/FP-New-E.pdf},
	author = {Assembly, United Nations General},
	year = {2014},
	note = {Published: Resolution of the Assembly A/RES/68/261},
	keywords = {policy}
}

@book{national_academies_of_sciences_engineering_and_medicine_principles_2017,
	address = {Washington, DC},
	title = {Principles and {Practices} for a {Federal} {Statistical} {Agency}, {Sixth} {Edition}},
	url = {https://www.nap.edu/catalog/24810/principles-and-practices-for-a-federal-statistical-agency-sixth-edition},
	publisher = {The National Academies Press},
	author = {{National Academies of Sciences, Engineering, and Medicine}},
	year = {2017},
	doi = {10.17226/24810},
	keywords = {official statistics}
}

@inproceedings{gehrke_towards_2011,
	title = {Towards privacy for social networks: {A} zero-knowledge based definition of privacy},
	booktitle = {Theory of {Cryptography} {Conference}},
	publisher = {Springer},
	author = {Gehrke, Johannes and Lui, Edward and Pass, Rafael},
	year = {2011},
	keywords = {formal privacy},
	pages = {432--449}
}

@article{yu_scalable_2014,
	title = {Scalable privacy-preserving data sharing methodology for genome-wide association studies},
	volume = {50},
	issn = {1532-0464},
	url = {http://www.sciencedirect.com/science/article/pii/S1532046414000100},
	doi = {https://doi.org/10.1016/j.jbi.2014.01.008},
	journal = {Journal of Biomedical Informatics},
	author = {Yu, Fei and Fienberg, Stephen E. and Slavkovic, Aleksandra B. and Uhler, Caroline},
	year = {2014},
	keywords = {formal privacy, Differential privacy, Allelic test, Contingency table, Genome-wide association study (GWAS), Pearson -test, Single-nucleotide polymorphism (SNP)},
	pages = {133 -- 141}
}

@inproceedings{narayanan_robust_2008,
	address = {Washington, DC, USA},
	series = {{SP} '08},
	title = {Robust {De}-anonymization of {Large} {Sparse} {Datasets}},
	isbn = {978-0-7695-3168-7},
	url = {https://doi.org/10.1109/SP.2008.33},
	booktitle = {Proceedings of the 2008 {IEEE} {Symposium} on {Security} and {Privacy}},
	publisher = {IEEE Computer Society},
	author = {Narayanan, Arvind and Shmatikov, Vitaly},
	year = {2008},
	keywords = {formal privacy, Privacy, Anonymity, Attack},
	pages = {111--125}
}

@techreport{commission_on_evidence-based_policymaking_promise_2017,
	title = {The {Promise} of {Evidence}-{Based} {Policymaking}: {Report} of the {Commission} on {Evidence}-{Based} {Policymaking}},
	url = {https://www.cep.gov/content/dam/cep/report/cep-final-report.pdf},
	institution = {Government Printing Office},
	author = {{Commission on Evidence-Based Policymaking}},
	year = {2017},
	keywords = {policy}
}

@techreport{harrell_victims_2017,
	title = {Victims of {Identity} {Theft}, 2014 ({Revised} {November} 13, 2017)},
	url = {https://www.bjs.gov/index.cfm?ty=pbdetail&iid=5408},
	number = {NCJ 248991},
	institution = {Department of Justice},
	author = {Harrell, Erika},
	month = sep,
	year = {2017},
	keywords = {value of privacy}
}

@techreport{national_center_for_education_statistics_common_2016,
	type = {[{Computer} file]},
	title = {Common {Core} of {Data}},
	url = {N/A},
	number = {v.1a},
	institution = {U.S. Department of Education},
	author = {{National Center for Education Statistics}},
	month = aug,
	year = {2016},
	note = {Published: Computer file}
}

@techreport{sonnenberg_allocating_2016,
	title = {Allocating {Grants} for {Title} {I}},
	url = {https://nces.ed.gov/surveys/AnnualReports/pdf/titleI20160111.pdf},
	institution = {National Center for Education Statistics},
	author = {Sonnenberg, William},
	month = jan,
	year = {2016},
	keywords = {policy}
}

@inproceedings{cormode_differentially_2012,
	title = {Differentially {Private} {Spatial} {Decompositions}},
	doi = {10.1109/ICDE.2012.16},
	booktitle = {2012 {IEEE} 28th {International} {Conference} on {Data} {Engineering}},
	author = {Cormode, G. and Procopiuc, C. and Srivastava, D. and Shen, E. and Yu, T.},
	year = {2012},
	note = {ISSN: 1063-6382},
	keywords = {formal privacy},
	pages = {20--31}
}

@book{abowd_replication_2018,
	title = {Replication archive for: {An} {Economic} {Analysis} of {Privacy} {Protection} and {Statistical} {Accuracy} as {Social} {Choices}},
	url = {https://doi.org/10.5281/zenodo.1208758},
	publisher = {Zenodo},
	author = {Abowd, John M. and Schmutte, Ian M.},
	year = {2018},
	doi = {10.5281/zenodo.1208758}
}

@book{abowd_replication_2018-1,
	title = {Replication archive for: {Revisiting} the economics of privacy: {Population} statistics and confidentiality protection as public goods},
	url = {https://doi.org/10.5281/zenodo.345385},
	abstract = {Replication archive for http://digitalcommons.ilr.cornell.edu/ldi/22/},
	publisher = {Zenodo},
	author = {Abowd, John M and Schmutte, Ian M},
	year = {2018},
	doi = {10.5281/zenodo.345385}
}

@inproceedings{mcsherry_mechanism_2007,
	title = {Mechanism design via differential privacy},
	isbn = {0-7695-3010-9},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4389483},
	doi = {10.1109/FOCS.2007.66},
	abstract = {We study the role that privacy-preserving algorithms, which prevent the leakage of specific information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Specifically, we show that the recent notion of differential privacv, in addition to its own intrinsic virtue, can ensure that participants have limited effect on the outcome of the mechanism, and as a consequence have limited incentive to lie. More precisely, mechanisms with differential privacy are approximate dominant strategy under arbitrary player utility functions, are automatically resilient to coalitions, and easily allow repeatability. We study several special cases of the unlimited supply auction problem, providing new results for digital goods auctions, attribute auctions, and auctions with arbitrary structural constraints on the prices. As an important prelude to developing a privacy-preserving auction mechanism, we introduce and study a generalization of previous privacy work that accommodates the high sensitivity of the auction setting, where a single participant may dramatically alter the optimal fixed price, and a slight change in the offered price may take the revenue from optimal to zero.},
	booktitle = {48th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science} 2007 ({FOCS} '07)},
	author = {McSherry, Frank and Talwar, Kunal},
	month = oct,
	year = {2007},
	note = {ISSN: 0272-5428},
	keywords = {formal privacy, data privacy, Data privacy, differential privacy, Robustness, mechanism design, Computer science, Data analysis, Pricing, Algorithm design and analysis, approximate dominant strategy, arbitrary player utility functions, arbitrary structural constraints, attribute auctions, Concrete, digital goods auctions, optimal fixed price, privacy-preserving algorithms, Protection, Silicon, strategic agents, unlimited supply auction problem, Utility theory},
	pages = {94--103}
}

@article{trottini_modelling_2002,
	title = {Modelling {User} {Uncertainty} for {Disclosure} {Risk} and {Data} {Utility}},
	volume = {10},
	issn = {0218-4885},
	url = {http://dx.doi.org/10.1142/S0218488502001612},
	doi = {10.1142/S0218488502001612},
	number = {5},
	journal = {International Journal of Uncertainty and Fuzziness in Knowledge-Based Systems},
	author = {Trottini, Mario and Fienberg, Stephen E.},
	month = oct,
	year = {2002},
	note = {Place: River Edge, NJ, USA
Publisher: World Scientific Publishing Co., Inc.},
	keywords = {SDL, statistical disclosure limitation, disclosure limitation, Bayesian decision theory, data release, information theory, intruder uncertainty},
	pages = {511--527}
}

@incollection{mcfadden_measuring_1998,
	title = {Measuring {Willingness}-{To}-{Pay} {For} {Transportation} {Improvements}},
	booktitle = {Theoretical {Foundations} of {Travel} {Choice} {Modeling}},
	publisher = {Emerald},
	author = {Mcfadden, Daniel},
	editor = {Garling, Tommy and Laitila, Thomas and Westin, Kerstin},
	year = {1998}
}

@article{wang_privacy-utility_2017,
	title = {Privacy-{Utility} {Tradeoffs} under {Constrained} {Data} {Release} {Mechanisms}},
	volume = {abs/1710.09295},
	url = {http://arxiv.org/abs/1710.09295},
	journal = {CoRR},
	author = {Wang, Ye and Basciftci, Yuksel Ozan and Ishwar, Prakash},
	year = {2017},
	note = {\_eprint: 1710.09295},
	keywords = {formal privacy}
}

@article{gouweleeuw_post_1998,
	title = {Post randomisation for statistical disclosure control: {Theory} and implementation},
	volume = {14},
	number = {4},
	journal = {Journal of official Statistics},
	author = {Gouweleeuw, JM and Kooiman, Peter and De Wolf, P-P},
	year = {1998},
	note = {Publisher: Statistics Sweden (SCB)},
	keywords = {SDL, statistical disclosure limitation},
	pages = {463}
}

@techreport{alaggan_heterogeneous_2015,
	title = {Heterogeneous differential privacy},
	url = {http://arxiv.org/abs/1504.06998},
	number = {1504.06998},
	institution = {arXiv},
	author = {Alaggan, Mohammad and Gambs, Sébastien and Kermarrec, Anne-Marie},
	year = {2015},
	doi = {10.29012/jpc.v7i2.652},
	note = {Publication Title: arXiv},
	keywords = {Formal Privacy}
}

@inproceedings{bhaskara_unconditional_2012,
	address = {New York, NY, USA},
	series = {{STOC} '12},
	title = {Unconditional {Differentially} {Private} {Mechanisms} for {Linear} {Queries}},
	isbn = {978-1-4503-1245-5},
	url = {http://doi.acm.org/10.1145/2213977.2214089},
	doi = {10.1145/2213977.2214089},
	booktitle = {Proceedings of the {Forty}-fourth {Annual} {ACM} {Symposium} on {Theory} of {Computing}},
	publisher = {ACM},
	author = {Bhaskara, Aditya and Dadush, Daniel and Krishnaswamy, Ravishankar and Talwar, Kunal},
	year = {2012},
	note = {event-place: New York, New York, USA},
	keywords = {formal privacy, differential privacy, slicing conjecture},
	pages = {1269--1284}
}

@article{shlomo_privacy_2012,
	title = {Privacy protection from sampling and perturbation in survey microdata},
	volume = {4},
	number = {1},
	journal = {Journal of Privacy and Confidentiality},
	author = {Shlomo, Natalie and Skinner, Chris J},
	year = {2012},
	keywords = {formal privacy},
	pages = {7}
}

@article{lin_benefits_2013,
	title = {On the {Benefits} of {Sampling} in {Privacy} {Preserving} {Statistical} {Analysis} on {Distributed} {Databases}},
	volume = {abs/1304.4613},
	url = {http://arxiv.org/abs/1304.4613},
	journal = {CoRR},
	author = {Lin, Bing-Rong and Wang, Ye and Rane, Shantanu},
	year = {2013},
	note = {\_eprint: 1304.4613},
	keywords = {formal privacy}
}

@article{fienberg_disclosure_1998,
	title = {Disclosure limitation using perturbation and related methods for categorical data},
	volume = {14},
	number = {4},
	journal = {Journal of Official Statistics},
	author = {Fienberg, Stephen E and Steele, Russell J},
	year = {1998},
	note = {Publisher: Statistics Sweden (SCB)},
	keywords = {SDL, statistical disclosure limitation},
	pages = {485}
}

@article{loong_multiply-imputed_2017,
	title = {Multiply-{Imputed} {Synthetic} {Data}: {Advice} to the {Imputer}},
	volume = {33},
	issn = {0282-423X, 2001-7367},
	url = {https://content.sciendo.com/view/journals/jos/33/4/article-p1005.xml},
	doi = {10.1515/jos-2017-0047},
	abstract = {Several statistical agencies have started to use multiply-imputed synthetic microdata to create public-use data in major surveys. The purpose of doing this is to protect the confidentiality of respondents' identities and sensitive attributes, while allowing standard complete-data analyses of microdata. A key challenge, faced by advocates of synthetic data, is demonstrating that valid statistical inferences can be obtained from such synthetic data for non-confidential questions. Large discrepancies between observed-data and synthetic-data analytic results for such questions may arise because of uncongeniality; that is, differences in the types of inputs available to the imputer, who has access to the actual data, and to the analyst, who has access only to the synthetic data. Here, we discuss a simple, but possibly canonical, example of uncongeniality when using multiple imputation to create synthetic data, which specifically addresses the choices made by the imputer. An initial, unanticipated but not surprising, conclusion is that non-confidential design information used to impute synthetic data should be released with the confidential synthetic data to allow users of synthetic data to avoid possible grossly conservative inferences.},
	number = {4},
	journal = {Journal of Official Statistics},
	author = {Loong, Bronwyn and Rubin, Donald B},
	year = {2017},
	pages = {531}
}

@article{carter_social_2015,
	title = {The social licence for research: why care.data ran into trouble},
	volume = {41},
	issn = {0306-6800},
	url = {http://jme.bmj.com/content/41/5/404},
	doi = {10.1136/medethics-2014-102374},
	abstract = {In this article we draw on the concept of a social licence to explain public concern at the introduction of care.data, a recent English initiative designed to extract data from primary care medical records for commissioning and other purposes, including research. The concept of a social licence describes how the expectations of society regarding some activities may go beyond compliance with the requirements of formal regulation; those who do not fulfil the conditions for the social licence (even if formally compliant) may experience ongoing challenge and contestation. Previous work suggests that people’s cooperation with specific research studies depends on their perceptions that their participation is voluntary and is governed by values of reciprocity, non-exploitation and service of the public good. When these conditions are not seen to obtain, threats to the social licence for research may emerge. We propose that care.data failed to adequately secure a social licence because of: (i) defects in the warrants of trust provided for care.data, (ii) the implied rupture in the traditional role, expectations and duties of general practitioners, and (iii) uncertainty about the status of care.data as a public good. The concept of a social licence may be useful in explaining the specifics of care.data, and also in reinforcing the more general lesson for policy-makers that legal authority does not necessarily command social legitimacy.},
	number = {5},
	journal = {Journal of Medical Ethics},
	author = {Carter, Pam and Laurie, Graeme T and Dixon-Woods, Mary},
	year = {2015},
	note = {Publisher: Institute of Medical Ethics
\_eprint: http://jme.bmj.com/content/41/5/404.full.pdf},
	pages = {404--409}
}

@inproceedings{li_sampling_2012,
	title = {On sampling, anonymization, and differential privacy or, k-anonymization meets differential privacy},
	doi = {10.1145/2414456.2414474},
	booktitle = {Proceedings of the 7th {ACM} {Symposium} on {Information}, {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Li, Ninghui and Qardaji, Wahbeh and Su, Dong},
	year = {2012},
	keywords = {formal privacy},
	pages = {32--33}
}

@article{gehrke_crowd-blending_2012,
	title = {Crowd-blending privacy},
	doi = {10.1007/978-3-642-32009-5_28},
	journal = {Advances in Cryptology–CRYPTO 2012},
	author = {Gehrke, Johannes and Hay, Michael and Lui, Edward and Pass, Rafael},
	year = {2012},
	note = {Publisher: Springer},
	keywords = {SDL, statistical disclosure limitation},
	pages = {479--496}
}

@inproceedings{evfimievski_limiting_2003,
	title = {Limiting privacy breaches in privacy preserving data mining},
	doi = {10.1145/773153.773174},
	abstract = {There has been increasing interest in the problem of building accurate data mining models over aggregate data, while protecting privacy at the level of individual records. One approach for this problem is to randomize the values in individual records, and only disclose the randomized values. The model is then built over the randomized data, after first compensating for the randomization (at the aggregate level). This approach is potentially vulnerable to privacy breaches: based on the distribution of the data, one may be able to learn with high confidence that some of the randomized records satisfy a specified property, even though privacy is preserved on average.In this paper, we present a new formulation of privacy breaches, together with a methodology, "amplification", for limiting them. Unlike earlier approaches, amplification makes it is possible to guarantee limits on privacy breaches without any knowledge of the distribution of the original data. We instantiate this methodology for the problem of mining association rules, and modify the algorithm from [9] to limit privacy breaches without knowledge of the data distribution. Next, we address the problem that the amount of randomization required to avoid privacy breaches (when mining association rules) results in very long transactions. By using pseudorandom generators and carefully choosing seeds such that the desired items from the original transaction are present in the randomized transaction, we can send just the seed instead of the transaction, resulting in a dramatic drop in communication and storage cost. Finally, we define new information measures that take privacy breaches into account when quantifying the amount of privacy preserved by randomization.},
	booktitle = {{SIGMOD} {Principles} of {Database} {Systems} {PODS} '03},
	publisher = {ACM Digital Library},
	author = {Evfimievski, Alexandre and Gehrke, Johannes and Srikant, Ramakrishnan},
	year = {2003},
	note = {Journal Abbreviation: Pods},
	keywords = {formal privacy},
	pages = {211--222}
}

@article{ghosh_inferential_2016,
	title = {Inferential {Privacy} {Guarantees} for {Differentially} {Private} {Mechanisms}},
	volume = {abs/1603.01508},
	url = {http://arxiv.org/abs/1603.01508},
	journal = {CoRR},
	author = {Ghosh, Arpita and Kleinberg, Robert},
	year = {2016},
	keywords = {formal privacy}
}

@article{carson_contingent_2003,
	title = {Contingent {Valuation} and {Lost} {Passive} {Use}: {Damages} from the {Exxon} {Valdez} {Oil} {Spill}},
	volume = {25},
	issn = {1573-1502},
	url = {http://dx.doi.org/10.1023/A:1024486702104},
	doi = {10.1023/A:1024486702104},
	abstract = {We report on the results of a large-scale contingent valuation (CV) study conducted after the Exxon Valdez oil spill to assess the harm caused by it. Among the issues considered are the design features of the CV survey, its administration to a national sample of U.S. households, estimation of household willingness to pay to prevent another Exxon Valdez type oil spill, and issues related to reliability and validity of the estimates obtained. Events influenced by the study's release are also briefly discussed.},
	number = {3},
	journal = {Environmental and Resource Economics},
	author = {Carson, Richard T. and Mitchell, Robert C. and Hanemann, Michael and Kopp, Raymond J. and Presser, Stanley and Ruud, Paul A.},
	year = {2003},
	pages = {257--286}
}

@book{bean_independent_2016,
	title = {Independent review of {UK} economic statistics},
	url = {https://www.gov.uk/government/publications/independent-review-of-uk-economic-statistics-final-report},
	author = {Bean, Charles},
	year = {2016},
	note = {Published: Cabinet Office, HM Treasury, The Rt Hon Matt Hancock, and The Rr Hon George Osborne},
	keywords = {official statistics}
}

@article{shokri_membership_2016,
	title = {Membership {Inference} {Attacks} against {Machine} {Learning} {Models}},
	volume = {abs/1610.05820},
	url = {http://arxiv.org/abs/1610.05820},
	doi = {10.1109/sp.2017.41},
	journal = {CoRR},
	author = {Shokri, Reza and Stronati, Marco and Shmatikov, Vitaly},
	year = {2016}
}

@article{geng_optimal_2012,
	title = {Optimal {Noise}-{Adding} {Mechanism} in {Differential} {Privacy}},
	volume = {abs/1212.1186},
	url = {http://arxiv.org/abs/1212.1186},
	journal = {CoRR},
	author = {Geng, Quan and Viswanath, Pramod},
	year = {2012},
	keywords = {formal privacy}
}

@article{tourangeau_asking_1996,
	title = {{ASKING} {SENSITIVE} {QUESTIONS} {THE} {IMPACT} {OF} {DATA} {COLLECTION} {MODE}, {QUESTION} {FORMAT}, {AND} {QUESTION} {CONTEXT}},
	volume = {60},
	url = {+ http://dx.doi.org/10.1086/297751},
	doi = {10.1086/297751},
	number = {2},
	journal = {Public Opinion Quarterly},
	author = {TOURANGEAU, ROGER and SMITH, TOM W.},
	year = {1996},
	note = {\_eprint: /oup/backfile/content\_public/journal/poq/60/2/10.1086\_297751/3/60-2-275.pdf},
	keywords = {value of privacy},
	pages = {275}
}

@article{dwork_guilt-free_2017,
	title = {Guilt-free data reuse},
	volume = {60},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/3051088},
	doi = {10.1145/3051088},
	number = {4},
	journal = {Commun. ACM},
	author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
	year = {2017},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {value of privacy},
	pages = {86--93}
}

@article{ghosh_universally_2012,
	title = {Universally {Utility}-maximizing {Privacy} {Mechanisms}},
	volume = {41},
	url = {https://doi.org/10.1137/09076828X},
	doi = {10.1137/09076828X},
	number = {6},
	journal = {SIAM Journal on Computing},
	author = {Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
	year = {2012},
	note = {\_eprint: https://doi.org/10.1137/09076828X},
	keywords = {formal privacy},
	pages = {1673--1693}
}

@article{dwork_generalization_2015-1,
	title = {Generalization in {Adaptive} {Data} {Analysis} and {Holdout} {Reuse}},
	volume = {abs/1506.02629},
	url = {http://arxiv.org/abs/1506.02629},
	journal = {CoRR},
	author = {Dwork, Cynthia and Feldman, Vitaly and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Roth, Aaron},
	year = {2015},
	keywords = {value of privacy}
}

@article{bruine_de_bruin_public_2014,
	title = {Public perceptions of local flood risk and the role of climate change},
	volume = {34},
	issn = {2194-5411},
	url = {http://dx.doi.org/10.1007/s10669-014-9513-6},
	doi = {10.1007/s10669-014-9513-6},
	abstract = {The IPCC reports that climate change will pose increased risks of heatwaves and flooding. Although survey-based studies have examined links between public perceptions of hot weather and climate change beliefs, relatively little is known about people's perceptions of changes in flood risks, the extent to which climate change is perceived to contribute to changes in flood risks, or how such perceptions vary by political affiliation. We discuss findings from a survey of long-time residents of Pittsburgh, Pennsylvania, USA, a region that has experienced regular flooding. Our participants perceived local flood risks as having increased and expected further increase in the future; expected higher future flood risks if they believed more in the contribution of climate change; interpreted projections of future increases in flooding as evidence for climate change; and perceived similar increases in flood risks independent of their political affiliation despite disagreeing about climate change. Overall, these findings suggest that communications about climate change adaptation will be more effective if they focus more on protection against local flood risks, especially when targeting audiences of potential climate sceptics.},
	number = {4},
	journal = {Environment Systems and Decisions},
	author = {Bruine de Bruin, Wändi and Wong-Parodi, Gabrielle and Morgan, M. Granger},
	year = {2014},
	keywords = {value of data},
	pages = {591--599}
}

@article{bruin_measuring_2011,
	title = {Measuring consumer uncertainty about future inflation},
	volume = {26},
	issn = {08837252, 10991255},
	url = {http://www.jstor.org/stable/23017556},
	abstract = {We introduce a survey-based measure of uncertainty about future inflation, asking consumers for density forecasts across inflation outcomes. Consumers are willing and able to express uncertainty, showing high response rates and response patterns that are reliably related to qualitative measures of uncertainty. Heterogeneity in expressed uncertainty is associated with demographic characteristics and financial literacy, and measures of central tendency derived from density forecasts are strongly correlated with point forecasts. Furthermore, expressed uncertainty is positively related to point forecast levels and to larger revisions in point forecasts over time.},
	number = {3},
	journal = {Journal of Applied Econometrics},
	author = {Bruin, Wändi Bruine de and Manski, Charles F. and Topa, Giorgio and Klaauw, Wilbert van der},
	year = {2011},
	note = {Publisher: Wiley},
	keywords = {value of data},
	pages = {454--478}
}

@book{conrad_interviewing_2014,
	title = {Interviewing by texting: costs, efficiency, and data quality.},
	url = {N/A},
	author = {Conrad, Frederick G. and Schober, Michael F. and Antoun, Christopher and Hupp, Andrew L.},
	year = {2014},
	note = {Published: In 69th annual conference of the American Association for Public Opinion Research}
}

@inproceedings{ligett_take_2012,
	address = {Berlin, Heidelberg},
	series = {{WINE}'12},
	title = {Take {It} or {Leave} {It}: {Running} a {Survey} when {Privacy} {Comes} at a {Cost}},
	isbn = {978-3-642-35310-9},
	url = {http://dx.doi.org/10.1007/978-3-642-35311-6_28},
	doi = {10.1007/978-3-642-35311-6_28},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Internet} and {Network} {Economics}},
	publisher = {Springer-Verlag},
	author = {Ligett, Katrina and Roth, Aaron},
	year = {2012},
	note = {event-place: Liverpool, UK},
	keywords = {value of privacy},
	pages = {378--391}
}

@article{liu_statistical_2020,
	title = {A {Statistical} {Overview} on {Data} {Privacy}},
	url = {http://arxiv.org/abs/2007.00765},
	abstract = {The eruption of big data with the increasing collection and processing of vast volumes and variety of data have led to breakthrough discoveries and innovation in science, engineering, medicine, commerce, criminal justice, and national security that would not have been possible in the past. While there are many benefits to the collection and usage of big data, there are also growing concerns among the general public on what personal information is collected and how it is used. In addition to legal policies and regulations, technological tools and statistical strategies also exist to promote and safeguard individual privacy, while releasing and sharing useful population-level information. In this overview, I introduce some of these approaches, as well as the existing challenges and opportunities in statistical data privacy research and applications to better meet the practical needs of privacy protection and information sharing.},
	urldate = {2020-08-31},
	journal = {arXiv:2007.00765 [cs, stat]},
	author = {Liu, Fang},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.00765},
	keywords = {Statistics - Other Statistics, Computer Science - Cryptography and Security}
}

@article{buuren_mice_2011,
	title = {mice: {Multivariate} {Imputation} by {Chained} {Equations} in {R}},
	volume = {45},
	url = {https://www.jstatsoft.org/v45/i03/},
	number = {3},
	journal = {Journal of Statistical Software},
	author = {Buuren, Stef van and Groothuis-Oudshoorn, Karin},
	year = {2011},
	pages = {1--67}
}

@misc{innovations_for_poverty_action_povertyactionpii_detection_2020,
	title = {{PovertyAction}/{PII}\_detection},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/PovertyAction/PII_detection},
	abstract = {Application and python script to identify, remove, and/or recode personally identifiable information (PII) from field experiment datasets.},
	urldate = {2020-08-30},
	publisher = {Innovations for Poverty Action},
	author = {{Innovations for Poverty Action}},
	month = aug,
	year = {2020},
	note = {original-date: 2017-10-05T15:31:48Z},
	keywords = {deidentification, field-survey, natural-language-processing, pii}
}

@misc{j-pal_j-palstata_pii_scan_2020,
	title = {J-{PAL}/stata\_PII\_scan},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/J-PAL/stata_PII_scan},
	abstract = {Stata program to scan for personally identifiable information (PII)},
	urldate = {2020-08-30},
	publisher = {The Abdul Latif Jameel Poverty Action Lab},
	author = {{J-PAL}},
	month = jun,
	year = {2020},
	note = {original-date: 2018-01-22T22:06:58Z}
}

@misc{j-pal_j-palpii-scan_2020,
	title = {J-{PAL}/{PII}-{Scan}},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/J-PAL/PII-Scan},
	abstract = {R code to scan for obvious PII. Contribute to J-PAL/PII-Scan development by creating an account on GitHub.},
	urldate = {2020-08-30},
	publisher = {The Abdul Latif Jameel Poverty Action Lab},
	author = {{J-PAL}},
	month = mar,
	year = {2020},
	note = {original-date: 2017-03-06T20:46:27Z}
}

@article{reiter_verification_2009,
	title = {Verification servers: {Enabling} analysts to assess the quality of inferences from public use data},
	volume = {53},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947308004751},
	doi = {10.1016/j.csda.2008.10.006},
	abstract = {To protect confidentiality, statistical agencies typically alter data before releasing them to the public. Ideally, although generally not done, the agency also provides a way for secondary data analysts to assess the quality of inferences obtained with the released data. Quality measures can help secondary data analysts to identify inaccurate conclusions resulting from the disclosure limitation procedures, as well as have confidence in accurate conclusions. We propose a framework for an interactive, web-based system that analysts can query for measures of inferential quality. As we illustrate, agencies seeking to build such systems must consider the additional disclosure risks from releasing quality measures. We suggest some avenues of research on limiting these risks.},
	number = {4},
	journal = {Computational statistics \& data analysis},
	author = {Reiter, Jerome P and Oganian, Anna and Karr, Alan F},
	month = feb,
	year = {2009},
	pages = {1475--1482}
}

@article{snoke_general_2018,
	title = {General and specific utility measures for synthetic data},
	volume = {181},
	issn = {0964-1998, 1467-985X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12358},
	doi = {10.1111/rssa.12358},
	language = {en},
	number = {3},
	urldate = {2020-08-30},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Snoke, Joshua and Raab, Gillian M. and Nowok, Beata and Dibben, Chris and Slavkovic, Aleksandra},
	month = jun,
	year = {2018},
	pages = {663--688},
	file = {Snoke et al_2018_General and specific utility measures for synthetic data.pdf:/home/vilhuber/Zotero/storage/99JQCEC6/Snoke et al_2018_General and specific utility measures for synthetic data.pdf:application/pdf}
}

@article{snoke_general_2017,
	title = {General and specific utility measures for synthetic data},
	url = {http://arxiv.org/abs/1604.06651},
	abstract = {Data holders can produce synthetic versions of datasets when concerns about potential disclosure restrict the availability of the original records. This paper is concerned with methods to judge whether such synthetic data have a distribution that is comparable to that of the original data, what we will term general utility. We consider how general utility compares with specific utility, the similarity of results of analyses from the synthetic data and the original data. We adapt a previous general measure of data utility, the propensity score mean-squared-error (pMSE), to the specific case of synthetic data and derive its distribution for the case when the correct synthesis model is used to create the synthetic data. Our asymptotic results are confirmed by a simulation study. We also consider two specific utility measures, confidence interval overlap and standardized difference in summary statistics, which we compare with the general utility results. We present two examples examining this comparison of general and specific utility to real data syntheses and make recommendations for their use for evaluating synthetic data.},
	urldate = {2020-08-30},
	journal = {arXiv:1604.06651 [stat]},
	author = {Snoke, Joshua and Raab, Gillian and Nowok, Beata and Dibben, Chris and Slavkovic, Aleksandra},
	month = jun,
	year = {2017},
	note = {arXiv: 1604.06651},
	keywords = {Statistics - Applications},
	file = {arXiv.org Snapshot:/home/vilhuber/Zotero/storage/NUD3RSB3/1604.html:text/html;Snoke et al_2017_General and specific utility measures for synthetic data.pdf:/home/vilhuber/Zotero/storage/D52JTJVW/Snoke et al_2017_General and specific utility measures for synthetic data.pdf:application/pdf}
}

@misc{us_department_of_health__human_services_health_nodate,
	title = {Health {Information} {Privacy}},
	url = {https://www.hhs.gov/hipaa/index.html},
	urldate = {2020-06-23},
	author = {{U.S. Department of Health \& Human Services}}
}

@inproceedings{shlomo_integrating_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Integrating {Differential} {Privacy} in the {Statistical} {Disclosure} {Control} {Tool}-{Kit} for {Synthetic} {Data} {Production}},
	isbn = {978-3-030-57521-2},
	doi = {10.1007/978-3-030-57521-2_19},
	abstract = {A standard approach in the statistical disclosure control tool-kit for producing synthetic data is the procedure based on multivariate sequential chained-equation regression models where each successive regression includes variables from the preceding regressions. The models depend on conditional Bayesian posterior distributions and can handle continuous, binary and categorical variables. Synthetic data are generated by drawing random values from the corresponding predictive distributions. Multiple copies of the synthetic data are generated and inference carried out on each of the data sets with results combined for point and variance estimates under well-established combination rules. In this paper, we investigate whether algorithms and mechanisms found in the differential privacy literature can be added to the synthetic data production process to raise the privacy standards used at National Statistical Institutes. In particular, we focus on a differentially private functional mechanism of adding random noise to the estimating equations of the regression models. We also incorporate regularization in the OLS linear models (ridge regression) to compensate for noisy estimating equations and bound the global sensitivity. We evaluate the standard and modified multivariate sequential chained-equation regression approach for producing synthetic data in a small-scale simulation study.},
	language = {en},
	booktitle = {Privacy in {Statistical} {Databases}},
	publisher = {Springer International Publishing},
	author = {Shlomo, Natalie},
	editor = {Domingo-Ferrer, Josep and Muralidhar, Krishnamurty},
	year = {2020},
	keywords = {Functional mechanism, Ridge regression, Score functions, Sequential chained-equation regression models},
	pages = {271--280}
}

@inproceedings{kinney_advantages_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Advantages of {Imputation} vs. {Data} {Swapping} for {Statistical} {Disclosure} {Control}},
	isbn = {978-3-030-57521-2},
	doi = {10.1007/978-3-030-57521-2_20},
	abstract = {Data swapping is an approach long-used by public agencies to protect respondent confidentiality in which values of some variables are swapped with similar records for a small portion of respondents. Synthetic data is a newer method in which many if not all values are replaced with multiple imputations. Synthetic data can be difficult to implement for complex data; however, when the portion of data replaced is similar to data swapping, it becomes simple to implement using publicly available software. This paper describes how this simplification of synthetic data can be used to provide a better balance of data quality and disclosure protection compared to data swapping. This is illustrated via an empirical comparison using data from the Survey of Earned Doctorates.},
	language = {en},
	booktitle = {Privacy in {Statistical} {Databases}},
	publisher = {Springer International Publishing},
	author = {Kinney, Satkartar K. and Looby, Charlotte B. and Yu, Feng},
	editor = {Domingo-Ferrer, Josep and Muralidhar, Krishnamurty},
	year = {2020},
	keywords = {Applications, Methodology, Synthetic data},
	pages = {281--296}
}

@techreport{american_community_survey_office_american_2020,
	title = {American {Community} {Survey} 2014-2018 {ACS} 5-{Year} {PUMS} {Files} {Readme}},
	url = {https://www2.census.gov/programs-surveys/acs/tech_docs/pums/ACS2014_2018_PUMS_README.pdf},
	institution = {U.S. Census Bureau},
	author = {{American Community Survey Office}},
	month = jan,
	year = {2020}
}

@techreport{us_census_bureau_finalpublic_2011,
	title = {{FinalPublic} {Use} {Microdata} {Area} ({PUMA}) {Criteria} and {Guidelines} for the 2010 {Census} and the {American} {Community} {Survey}},
	url = {American Community Survey Office},
	author = {{U.S. Census Bureau}},
	year = {2011}
}

@techreport{desai_five_2016,
	title = {Five {Safes}: {Designing} data access for research},
	shorttitle = {Five {Safes}},
	url = {https://uwe-repository.worktribe.com/output/914745},
	abstract = {What is the best way of managing access to sensitive data? This is not a straightforward question, as it involves the interaction of legal, technical, statistical and, above all, human components to produce a solution. This paper introduces a modelling tool designed to simplify and structure such decision-making. The Five Safes model is a popular framework for designing, describing and evaluating access systems for data, used by data providers, data users, and regulators. The model integrates analysis of opportunities, constraints, costs and benefits of different approaches, taking account of the level of data anonymisation, the likely users, the scope for training, the environment through which data are accessed, and the statistical outputs derived from data use. Up to now this model has largely been described indirectly in other papers which have used it as a framing device. This paper focuses specifically on the framework, discusses usage, and demonstrates where it sits with other data and risk management tools. The aim is to provide a practical guide to the effective planning and management of access to research data.},
	language = {en},
	urldate = {2020-01-30},
	institution = {University of the West of England},
	author = {Desai, Tanvi and Ritchie, Felix and Welpton, Richard},
	month = jan,
	year = {2016}
}
