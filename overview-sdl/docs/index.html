<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Overview of disclosure avoidance methods</title>
  <meta name="description" content="Overview of disclosure avoidance methods" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Overview of disclosure avoidance methods" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="labordynamicsinstitute/overview-trad-disclosure-avoidance" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Overview of disclosure avoidance methods" />
  
  
  

<meta name="author" content="Ian M. Schmutte and Lars Vilhuber" />


<meta name="date" content="2020-07-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="0.0.1" data-path=""><a href="#purpose-of-statistical-disclosure-limitation-methods-definitions-and-context"><i class="fa fa-check"></i><b>0.0.1</b> Purpose of statistical disclosure limitation methods: Definitions and Context</a></li>
<li class="chapter" data-level="0.0.2" data-path=""><a href="#methods"><i class="fa fa-check"></i><b>0.0.2</b> Methods</a></li>
<li class="chapter" data-level="0.0.3" data-path=""><a href="#metrics"><i class="fa fa-check"></i><b>0.0.3</b> Metrics</a></li>
<li class="chapter" data-level="0.0.4" data-path=""><a href="#impact-on-analyses"><i class="fa fa-check"></i><b>0.0.4</b> Impact on analyses</a></li>
<li class="chapter" data-level="0.0.5" data-path=""><a href="#value-of-privacy-and-data-accuracy"><i class="fa fa-check"></i><b>0.0.5</b> Value of Privacy and Data Accuracy</a></li>
<li class="chapter" data-level="0.0.6" data-path=""><a href="#tools"><i class="fa fa-check"></i><b>0.0.6</b> Tools</a></li>
<li class="chapter" data-level="0.1" data-path=""><a href="#about-the-authors"><i class="fa fa-check"></i><b>0.1</b> About the Authors</a><ul>
<li class="chapter" data-level="0.1.1" data-path=""><a href="#acknowledgements"><i class="fa fa-check"></i><b>0.1.1</b> Acknowledgements</a></li>
<li class="chapter" data-level="0.1.2" data-path=""><a href="#disclaimer"><i class="fa fa-check"></i><b>0.1.2</b> Disclaimer</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path=""><a href="#references"><i class="fa fa-check"></i><b>0.2</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Overview of disclosure avoidance methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Overview of disclosure avoidance methods</h1>
<p class="author"><em>Ian M. Schmutte and Lars Vilhuber</em></p>
<p class="date"><em>2020-07-17</em></p>
</div>
<p>The overall purpose of this handbook is to provide guidance on how to enable broader access to data. As outlined in the introduction, one key concern is how to prevent unethical or illegal disclosure of data that should be kept confidential. The [chapter on physical protections] provides guidance on how to prevent disclosure - or release - of data or information by technical means. This chapter identifies the statistical means - through probabilistic or deterministic edits to data and outputs - by which data curators can limit the likelihood of a disclosure. These techniques are referred to as “statistical disclosure limitation” (SDL) in the literature, though one will sometimes find the use of “anonymization” or “de-identification.” We will define these terms, clarify what “limitation” means, why true anonymization is never possible, and why de-identification is very hard. We describe common traditional methods, deferring the most recent - and strict - method, differential privacy, to the more in-depth chapther on that topic.</p>
<p>Because any SDL will modify data, in a way that distorts the true, measured value, the quality of any inference using the modified data will be (negatively) affected. We will describe a few ways used to measure the outcomes of these methods, i.e., how a particular method solves the tradeoff between disclosure limitation and degradation in quality. We note right away that there is no “correct” or “right” level of tradeoff - it is a choice made by the data custodians and policy makers in ways that must take into accounts the uses made of the data.</p>
<p>We also discuss the impact various methods might have on data releases and econometric analyses of protected data. An often overlooked aspect of SDL methods is that they are not ignorable. However, an analogy is the care many econometric analyses take with addressing and correcting for measurement issues and biases. The distortion introduced through SDL methods is similar in impact, and often less in scale. This section draws heavily on <span class="citation">Abowd &amp; Schmutte (<a href="#ref-abowd_economic_2015" role="doc-biblioref">2015</a>)</span>.</p>
<p>Finally, SDL methods must be implemented and deployed, and we provide pointers to existing “off-the-rack” tools in a variety of platforms (Stata, R, and Python).</p>
<div id="purpose-of-statistical-disclosure-limitation-methods-definitions-and-context" class="section level3">
<h3><span class="header-section-number">0.0.1</span> Purpose of statistical disclosure limitation methods: Definitions and Context</h3>
<blockquote>
<p>Discuss legal and ethical requirements. Define terms, with reference to external sources (de-identification, anonymization, pseudonymization, European, US, and Indian legislation). Link to “safe data” and “safe outputs”. Reference glossaries where available.</p>
</blockquote>
<p>(1-1.5 pages)</p>
<p>The key concepts in disclosure avoidance are privacy and confidentiality. <em>Privacy</em> in the context of information can be viewed as the right to restrict (prevent) others’ gaining access to information a person holds, whether through query or through observation (see <span class="citation">Hirshleifer (<a href="#ref-hirshleifer_privacy_1980" role="doc-biblioref">1980</a>)</span>). <em>Confidentiality</em> pertains to the information gained once privacy has been pierced (or breached), and applies to data that others hold about entities such as individuals or firms.</p>
<blockquote>
<p>Confidential should mean that the dissemination of data in a manner that would allow public identification of the respondent or would in any way be harmful to him is prohibited and that the data are immune from legal process. (<span class="citation">Duncan, Jabine, &amp; Wolf (<a href="#ref-duncan_private_1993" role="doc-biblioref">1993</a>)</span>, p. 24.)</p>
</blockquote>
<p>In the United States, a majority of individuals are aware and possibly resigned that government and private companies collect data on them (about 62%, <span class="citation">Auxier et al. (<a href="#ref-auxier_americans_2019" role="doc-biblioref">2019</a>)</span>), and seem to believe that there is little benefit to them of such collection: 81% think so when companies do the data collection, and 66% when the government does so <span class="citation">(Auxier et al., <a href="#ref-auxier_americans_2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>Protection of the confidentiality of the underlying micro-data:
- Avoiding identity disclosure: who (or what entity) is in the confidential micro-data
- Avoiding attribute disclosure: value of a characteristic for that entity or individual
- Avoiding inferential disclosure: improvement of the posterior odds of a particular event (identity or attribute)</p>
<p>Within national statistical agencies, the primary approach to protecting respondent privacy has been <em>statistical disclosure limitation</em> or SDL. <span class="citation">Fellegi (<a href="#ref-fellegi_question_1972" role="doc-biblioref">1972</a>)</span> initiated the statistical analysis of data confidentiality. <span class="citation">Dalenius (<a href="#ref-dalenius_towards_1977" role="doc-biblioref">1977</a>)</span> recognized that statistical agencies would need to do more than just protect against direct disclosures, and thus warned against what he called inferential disclosure. His idea was formalized by <span class="citation">Duncan &amp; Lambert (<a href="#ref-duncan_disclosure-limited_1986" role="doc-biblioref">1986</a>)</span>, and provides the ultimate rationale for formal privacy in national statistics.
<span class="citation">Harris-Kojetin et al. (<a href="#ref-harris-kojetin_statistical_2005" role="doc-biblioref">2005</a>)</span> provides the most comprehensive review of SDL methods currently in use across the U.S. statistical system.
See also <span class="citation">Dupriez &amp; Boyko (<a href="#ref-dupriez_dissemination_2010" role="doc-biblioref">2010</a>)</span> for an overview from a multinational NSO perspective.
<span class="citation">Anderson &amp; Seltzer (<a href="#ref-anderson_challenges_2007" role="doc-biblioref">2007</a>)</span> describes the history of threats to confidentiality in the U.S. statistical system prior to 1965.</p>
<p>The interested reader is also pointed at a large and robust literature on (the value of) privacy in economics. That literature is generally focused on the value to individuals of being able to conceal private information, like a health condition, from a firm or prospective employer.
The challenge to the firm is to design mechanisms, like pricing strategies, that encourage people to disclose private information. For an overview of ideas in this literature, we recommend reading <span class="citation">Stigler (<a href="#ref-stigler_introduction_1980" role="doc-biblioref">1980</a>)</span>, <span class="citation">Posner (<a href="#ref-posner_economics_1981" role="doc-biblioref">1981</a>)</span>, and <span class="citation">Hirshleifer (<a href="#ref-hirshleifer_privacy_1980" role="doc-biblioref">1980</a>)</span>. <span class="citation">Varian (<a href="#ref-varian_economic_2002" role="doc-biblioref">2002</a>)</span> and <span class="citation">Acquisti, Taylor, &amp; Wagman (<a href="#ref-acquisti_economics_2016" role="doc-biblioref">2016</a>)</span> both provide comprehensive surveys at different points in the development of this literature.</p>
</div>
<div id="methods" class="section level3">
<h3><span class="header-section-number">0.0.2</span> Methods</h3>
<blockquote>
<p>Define the methods used for disclosure avoidance. (removal, coarsening of various kinds, swapping, data synthesis, formal privacy). Should reference WP 22, <strong>accessible</strong> guidelines by various entities including J-PAL, FCSM. Note: WP-22 is being revised, and will be released AFTER the handbook is released - so needs to have some forward looking elements. Reference glossaries where available.</p>
</blockquote>
<p><span class="citation">Harris-Kojetin et al. (<a href="#ref-harris-kojetin_statistical_2005" role="doc-biblioref">2005</a>)</span> provides the most comprehensive review of SDL methods currently in use across the U.S. statistical system.
See also <span class="citation">Dupriez &amp; Boyko (<a href="#ref-dupriez_dissemination_2010" role="doc-biblioref">2010</a>)</span> for an overview from a multinational NSO perspective.
<span class="citation">Garfinkel (<a href="#ref-garfinkel_-identification_2015" role="doc-biblioref">2015</a>)</span> discusses techniques for de-identifying data and the many ways in which modern computing tools and a data-rich environment may render effective de-identification impossible.</p>
<p>We briefly outline the most common methods here.</p>
<p>(pull from Ian slides)</p>
<p>Traditional methods
- Suppression
- Coarsening
- Adding noise via swapping
- Adding noise via sampling</p>
<p>Newer methods
- Explicit noise infusion
- Synthetic data
- Formal privacy (not handled here, refer to DP chapter)</p>
<div id="suppression" class="section level4">
<h4><span class="header-section-number">0.0.2.1</span> Suppression</h4>
<blockquote>
<p>Also mention rules that point to “suppress regression coefficients when derived from less than x% of sample, or the p-percent rule” as they are applied to “safe output” rules in RDC and MOU scenarios.</p>
</blockquote>
<p>This is by far the most common technique.
- Model the sensitivity of a particular data item or observation (“disclosure risk”)
- Do not allow the release of data items that have excessive disclosure risk (primary suppression)
- Do not allow the release of other data from which the sensitive item can be calculated (complementary suppression)</p>
<blockquote>
<p>Explicitly mention rules that point to “suppress regression coefficients when derived from less than x% of sample, or the p-percent rule” as they are applied to “safe output” rules in RDC and MOU scenarios. Can provide examples from HRS or PSID rules (less than x people in a cell)</p>
</blockquote>
</div>
<div id="coarsening" class="section level4">
<h4><span class="header-section-number">0.0.2.2</span> Coarsening</h4>
<blockquote>
<p>(describe coarsening in output rules, such as rounding of regression coefficients to x significant digits)</p>
</blockquote>
<p>Coarsening is the creation of a smaller number of categories from the variable in order to increase the number of cases in each cell
Computer scientists call this “generalizing”
Geographic coarsening: block-block group-tract-minor civil division-county-state-region
Top coding of income is a form of coarsening
All continuous variables in a micro-data file can be considered coarsened to the level of precision (significant digits) released
This method is often applied to model-based data releases by restricting the number of significant digits that can be released</p>
<p>(bring example of top-coding from IAN slides)</p>
<p>Coarsen: variables with heavy tails (earnings, payroll), residuals (truncate range, suppress labels of range)</p>
<p>Smooth: density estimation and quantiles, use a kernel density estimator to produce quantiles</p>
</div>
<div id="swapping" class="section level4">
<h4><span class="header-section-number">0.0.2.3</span> Swapping</h4>
<p>Estimate the disclosure risk of certain attributes or individuals
If the risk is too great, attributes of one data record are (randomly) swapped with the same attributes of another record
If geographic attributes are swapped this has the effect of placing the risky attributes in a different location from the truth
Commonly used in household censuses and surveys
Rarely used with establishment data</p>
</div>
<div id="sampling" class="section level4">
<h4><span class="header-section-number">0.0.2.4</span> Sampling</h4>
<p>Sampling is the original SDL technique
By only selecting certain entities from the population on which to collect additional data (data not on the frame), uncertainty about which entity was sampled provides some protection
In modern, detailed surveys, sampling is of limited use for SDL</p>
</div>
<div id="noise-infusion" class="section level4">
<h4><span class="header-section-number">0.0.2.5</span> Noise infusion</h4>
<p>Adding noise to the published item or to the underlying micro data to disguise the true value
Example: QWIs and work place data in OTM
Original method developed by <span class="citation">Evans, Zayatz, &amp; Slanta (<a href="#ref-evans_using_1998" role="doc-biblioref">1998</a>)</span>
QWI method: <span class="citation">Abowd et al. (<a href="#ref-abowd_lehd_2009" role="doc-biblioref">2009</a>)</span> , <span class="citation">Abowd et al. (<a href="#ref-abowd_dynamically_2012" role="doc-biblioref">2012</a>)</span></p>
</div>
<div id="synthetic-data" class="section level4">
<h4><span class="header-section-number">0.0.2.6</span> Synthetic data</h4>
<p>Synthetic data are created by estimating the posterior predictive distribution (PPD) of the release data given the confidential data; then sampling release data from the PPD conditioning on the actual confidential values
The PPD is a parameter-free forecasting model for new values of the complete data matrix that conditions on all values of the underlying confidential data</p>
<p>Needs references to SSB, SynLBD.</p>
<p>(2-3 pages)</p>
</div>
</div>
<div id="metrics" class="section level3">
<h3><span class="header-section-number">0.0.3</span> Metrics</h3>
<blockquote>
<p>How do you measure risk, and the reduction in risk achieved by applying above methods? Mention uniqueness criteria, k-anonymity, l-diversity, matching metrics, etc.</p>
</blockquote>
<ul>
<li>Count of suppressed cells</li>
<li>k-anonymity: <span class="citation">(Sweeney, <a href="#ref-sweeney_achieving_2002" role="doc-biblioref">2002</a>)</span></li>
<li>l-diversity: <span class="citation">(Machanavajjhala, Kifer, Gehrke, &amp; Venkitasubramaniam, <a href="#ref-machanavajjhala_l-diversity_2007" role="doc-biblioref">2007</a>)</span></li>
</ul>
<p>Also measure the value</p>
<p>(2-3 pages)</p>
</div>
<div id="impact-on-analyses" class="section level3">
<h3><span class="header-section-number">0.0.4</span> Impact on analyses</h3>
<blockquote>
<p>What is the impact on analyses when using protected data (reprise Abowd-Schmutte, BPEA), but also Chetty + Friedman (AEA P&amp;P, JPC) and Green-McKinney-Abowd-Vilhuber (increased variance) as well as the various papers on MOE/ACS. Consider Dwork on alignment of DP methods and safe inference.</p>
</blockquote>
<blockquote>
<ul>
<li>Reference standard methods that are related</li>
<li>Moulton correction (data aggregated - for whatever reason)</li>
<li>Using ACS MOE as an example of incorporating uncertainty (regardless of source)</li>
<li>Parts of Abowd-Schmutte, BPEA</li>
</ul>
</blockquote>
<p><span class="citation">Abowd &amp; Schmutte (<a href="#ref-abowd_economic_2015" role="doc-biblioref">2015</a>)</span> review the SDL methods currently in use and discuss their application to economic data. They argue that the analysis of SDL-laden data is inherently compromised because the details of the SDL protections cannot be disclosed. If they cannot be disclosed, their consequences for inference are unknowable, and, as they show, potentially large.</p>
<p>Measuring both is difficult, except in very particular cases. In this section, we outline metrics used to assess both the protection provided through SDL, as well as the reduction in “data quality”.</p>
<p>(expand using your slides)</p>
<div id="suppression-1" class="section level4">
<h4><span class="header-section-number">0.0.4.1</span> Suppression</h4>
</div>
<div id="coarsening-1" class="section level4">
<h4><span class="header-section-number">0.0.4.2</span> Coarsening</h4>
<p>Also reference the reduction in inference precision when regression coefficients are rounded (with probably little cost)</p>
</div>
<div id="adding-noise-via-swapping" class="section level4">
<h4><span class="header-section-number">0.0.4.3</span> Adding noise via swapping</h4>
</div>
<div id="adding-noise-via-sampling" class="section level4">
<h4><span class="header-section-number">0.0.4.4</span> Adding noise via sampling</h4>
</div>
<div id="noise-infusion-1" class="section level4">
<h4><span class="header-section-number">0.0.4.5</span> Noise infusion</h4>
<p>(LARS: can reference McKinney et al on QWI noise)</p>
</div>
<div id="synthetic-data-1" class="section level4">
<h4><span class="header-section-number">0.0.4.6</span> Synthetic data</h4>
<p>(LARS: can reference our work on SynLBD/SSB analysis)</p>
<p>(1-2 pages)</p>
</div>
</div>
<div id="value-of-privacy-and-data-accuracy" class="section level3">
<h3><span class="header-section-number">0.0.5</span> Value of Privacy and Data Accuracy</h3>
<p>Any researcher or data provider needs to evaluate the benefits from reducing the protection afforded through SDL techniques and the gain from the additional accuracy. One key challenge for implementing privacy systems lies in choosing the amount, or type, of privacy to provide. Answering this question requires some way to understand the individual and social value of privacy. <span class="citation">J. Abowd &amp; Schmutte (<a href="#ref-abowd_economic_2019" role="doc-biblioref">2019</a>)</span> discuss the question of optimal privacy protection (see also <span class="citation">Hsu et al. (<a href="#ref-hsu_differential_2014" role="doc-biblioref">2014</a>)</span> in the specific context of differential privacy).</p>
<p>Part of the social value of privacy arises from its relationship to scientific integrity. While the law of information recovery suggests that improved privacy must come at the cost of increased error in published statistics, these effects might be mitigated through two distinct channels.</p>
<p>First, people are more truthful in surveys if they believe their data is not at risk, as <span class="citation">Couper, Singer, Conrad, &amp; Groves (<a href="#ref-couper_risk_2008" role="doc-biblioref">2008</a>)</span> illustrate. Second, work in computer science <span class="citation">(Dwork et al., <a href="#ref-dwork_generalization_2015" role="doc-biblioref">2015</a>, p. @dwork_fienberg_2018)</span> and statistics <span class="citation">(Cummings, Ligett, Nissim, Roth, &amp; Wu, <a href="#ref-cummings_adaptive_2016" role="doc-biblioref">2016</a>)</span> suggests a somewhat surprising benefit of differential privacy: protection against overfitting.</p>
<p>It is equally necessary to develop a more robust understanding of why data is valuable in the first place, the overall social cost of increasing error in public statistics. This seems to be an area in which very little comprehensive theoretical or empirical research has been done. We nevertheless recommend what seem to be good starting points.</p>
<p><span class="citation">Spencer (<a href="#ref-spencer_optimal_1985" role="doc-biblioref">1985</a>)</span>, who developed a decision-theoretic framework for modeling optimal data quality.</p>
<p>On the empirical side, a handful of interesting use cases suggest techniques for uncovering the value of data. For example, <span class="citation">Card, Mas, Moretti, &amp; Saez (<a href="#ref-card_inequality_2012" role="doc-biblioref">2012</a>)</span> and <span class="citation">Perez-Truglia (<a href="#ref-perez-truglia_effects_2016" role="doc-biblioref">2016</a>)</span> show how workers respond to pay transparency policies, which give them new information about co-worker salaries. <span class="citation">Spencer &amp; Seeskin (<a href="#ref-spencer_effects_2015" role="doc-biblioref">2015</a>)</span> use a calibration exercise to study the costs, measured in misallocated congressional seats, of reduced accuracy in population census data. These examples might be of interest to various (government) data providers, as well as researchers interested in implementing surveys linked to administrative data.</p>
</div>
<div id="tools" class="section level3">
<h3><span class="header-section-number">0.0.6</span> Tools</h3>
<p>A sketch with lots of links to Stata and R packages that implement disclosure avoidance methods. Some simple methods to compute metrics as well (usually integrated).</p>
<ul>
<li>Summary of methods/packages in Stata</li>
<li>Summary of methods/packages in R</li>
</ul>
<p>(1-2 pages)</p>
</div>
<div id="about-the-authors" class="section level2">
<h2><span class="header-section-number">0.1</span> About the Authors</h2>
<p>Ian M. Schmutte</p>
<p>Lars Vilhuber</p>
<div id="acknowledgements" class="section level3">
<h3><span class="header-section-number">0.1.1</span> Acknowledgements</h3>
<p>This chapter draws on <span class="citation">John M. Abowd et al. (<a href="#ref-abowd_introductory_2019" role="doc-biblioref">2019</a>)</span> and the INFO7470 class at Cornell University <span class="citation">Abowd &amp; Vilhuber (<a href="#ref-abowd_session_2016" role="doc-biblioref">2016</a>)</span> . We gratefully acknowledge the support of Alfred P. <a href="https://sloan.org/grant-detail/6845">Sloan Foundation Grant G-2015-13903</a> and <a href="http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=1131848">NSF Grant SES-1131848</a>.</p>
</div>
<div id="disclaimer" class="section level3">
<h3><span class="header-section-number">0.1.2</span> Disclaimer</h3>
<p>The views expressed in this paper are those of the authors and not those of the U.S. Census Bureau or other sponsors.</p>
</div>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">0.2</span> References</h2>
<!-- # References -->
<!-- If you need PDF output, uncomment bookdown::pdf_book above in YAML. You will need a LaTeX installation, e.g., https://yihui.name/tinytex/ -->

<div id="refs" class="references">
<div>
<p>Abowd, J. M., Gittings, R. K. K., McKinney, K. L., Stephens, B., Vilhuber, L., &amp; Woodcock, S. D. (2012). <em>Dynamically Consistent Noise Infusion and Partially Synthetic Data as Confidentiality Protection Measures for Related Time Series</em> (No. 12-13). <a href="https://doi.org/10.2139/ssrn.2159800">https://doi.org/10.2139/ssrn.2159800</a></p>
</div>
<div>
<p>Abowd, J. M., Schmutte, I., Sexton, W., &amp; Vilhuber, L. (2019). <em>Introductory Readings in Formal Privacy for Economists</em> (Document No. 2662639). <a href="https://doi.org/10.5281/zenodo.2662639">https://doi.org/10.5281/zenodo.2662639</a></p>
</div>
<div>
<p>Abowd, J. M., Stephens, B. E., Vilhuber, L., Andersson, F., McKinney, K. L., Roemer, M., &amp; Woodcock, S. D. (2009). The LEHD Infrastructure Files and the Creation of the Quarterly Workforce Indicators. In T. Dunne and J B Jensen and M J Roberts (Ed.), <em>Producer Dynamics: New Evidence from Micro Data</em>. University of Chicago Press.</p>
</div>
<div>
<p>Abowd, J. M., &amp; Vilhuber, L. (2016). <em>Session 12: Statistical Tools: Methods of Confidentiality Protection</em> (Presentation No. 45060). Retrieved from Labor Dynamics Institute, Cornell University website: <a href="https://hdl.handle.net/1813/45060">https://hdl.handle.net/1813/45060</a></p>
</div>
<div>
<p>Abowd, J., &amp; Schmutte, I. (2019). An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices. <em>American Economic Review</em>, <em>109</em>(1), 171–202. <a href="https://doi.org/10.1257/aer.20170627">https://doi.org/10.1257/aer.20170627</a></p>
</div>
<div>
<p>Abowd, J., &amp; Schmutte, I. M. (2015). Economic analysis and statistical disclosure limitation. <em>Brookings Papers on Economic Activity</em>, 221–267. <a href="https://doi.org/10.1353/eca.2016.0004">https://doi.org/10.1353/eca.2016.0004</a></p>
</div>
<div>
<p>Acquisti, A., Taylor, C., &amp; Wagman, L. (2016). The Economics of Privacy. <em>Journal of Economic Literature</em>, <em>54</em>(2), 442–492. <a href="https://doi.org/10.1257/jel.54.2.442">https://doi.org/10.1257/jel.54.2.442</a></p>
</div>
<div>
<p>Anderson, M., &amp; Seltzer, W. (2007). Challenges to the confidentiality of US federal statistics, 1910-1965. <em>Journal of Official Statistics</em>, <em>23</em>(1), 1. Retrieved from <a href="https://www.scb.se/contentassets/ff271eeeca694f47ae99b942de61df83/challenges-to-the-confidentiality-of-u.s.-federal-statistics-1910-1965.pdf">https://www.scb.se/contentassets/ff271eeeca694f47ae99b942de61df83/challenges-to-the-confidentiality-of-u.s.-federal-statistics-1910-1965.pdf</a></p>
</div>
<div>
<p>Auxier, B., Rainie, L., Anderson, M., Perrin, A., Kumar, M., &amp; Turner, E. (2019). <em>Americans and Privacy: Concerned, Confused and Feeling Lack of Control Over Their Personal Information</em>. Retrieved from Pew Research Center website: <a href="https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/">https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/</a></p>
</div>
<div>
<p>Card, D., Mas, A., Moretti, E., &amp; Saez, E. (2012). Inequality at work: The effect of peer salaries on job satisfaction. <em>American Economic Review</em>, <em>102</em>(6), 2981–3003. <a href="https://doi.org/10.1257/aer.102.6.2981">https://doi.org/10.1257/aer.102.6.2981</a></p>
</div>
<div>
<p>Couper, M. P., Singer, E., Conrad, F. G., &amp; Groves, R. M. (2008). Risk of disclosure, perceptions of risk, and concerns about privacy and confidentiality as factors in survey participation. <em>Journal of Official Statistics</em>, <em>24</em>(2), 255. Retrieved from <a href="http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/risk-of-disclosure-perceptions-of-risk-and-concerns-about-privacy-and-confidentiality-as-factors-in-survey-participation.pdf">http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/risk-of-disclosure-perceptions-of-risk-and-concerns-about-privacy-and-confidentiality-as-factors-in-survey-participation.pdf</a></p>
</div>
<div>
<p>Cummings, R., Ligett, K., Nissim, K., Roth, A., &amp; Wu, Z. S. (2016). Adaptive Learning with Robust Generalization Guarantees. <em>CoRR</em>, <em>abs/1602.07726</em>. Retrieved from <a href="http://arxiv.org/abs/1602.07726">http://arxiv.org/abs/1602.07726</a></p>
</div>
<div>
<p>Dalenius, T. (1977). Towards a methodology for statistical disclosure control. <em>Statistik Tidskrift</em>, <em>15</em>, 429–444. <a href="https://doi.org/10.1145/320613.320616">https://doi.org/10.1145/320613.320616</a></p>
</div>
<div>
<p>Duncan, G., &amp; Lambert, D. (1986). Disclosure-limited data dissemination. <em>Journal of the American Statistical Association</em>, <em>81</em>(393), 10–18. <a href="https://doi.org/10.1080/01621459.1986.10478229">https://doi.org/10.1080/01621459.1986.10478229</a></p>
</div>
<div>
<p>Duncan, G. T., Jabine, T. B., &amp; Wolf, V. A. de (Eds.). (1993). <em>Private Lives and Public Policies: Confidentiality and Accessibility of Government Statistics</em>. <a href="https://doi.org/10.17226/2122">https://doi.org/10.17226/2122</a></p>
</div>
<div>
<p>Dupriez, O., &amp; Boyko, E. (2010). <em>Dissemination of Microdata Files - Principles, Procedures and Practices</em> (Working Paper No. 005). Retrieved from The World Bank website: <a href="http://ihsn.org/dissemination-of-microdata-files">http://ihsn.org/dissemination-of-microdata-files</a></p>
</div>
<div>
<p>Dwork, C., Feldman, V., Hardt, M., Pitassi, T., Reingold, O., &amp; Roth, A. (2015). Generalization in Adaptive Data Analysis and Holdout Reuse. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, &amp; R. Garnett (Eds.), <em>Advances in Neural Information Processing Systems 28</em> (pp. 2341–2349). Retrieved from <a href="http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf">http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf</a></p>
</div>
<div>
<p>Dwork, C., &amp; Ullman, J. (2018). The Fienberg Problem: How to Allow Human Interactive Data Analysis in the Age of Differential Privacy. <em>Journal of Privacy and Confidentiality</em>, <em>8</em>(1). <a href="https://doi.org/10.29012/jpc.687">https://doi.org/10.29012/jpc.687</a></p>
</div>
<div>
<p>Evans, T., Zayatz, L., &amp; Slanta, J. (1998). Using Noise for Disclosure Limitation of Establishment Tabular Data. <em>Journal of Official Statistics</em>, <em>14</em>(4), 537–551.</p>
</div>
<div>
<p>Fellegi, I. P. (1972). On the Question of Statistical Confidentiality. <em>Journal of the American Statistical Association</em>, <em>67</em>(337), 7–18. <a href="https://doi.org/10.2307/2284695">https://doi.org/10.2307/2284695</a></p>
</div>
<div>
<p>Garfinkel, S. (2015). <em>De-Identification of Personal Information</em> (Internal Report No. 8053). <a href="https://doi.org/10.6028/nist.ir.8053">https://doi.org/10.6028/nist.ir.8053</a></p>
</div>
<div>
<p>Harris-Kojetin, B. A., Alvey, W. L., Carlson, L., Cohen, S. B., Cohen, S. H., Cox, L. H., … Groves, R. (2005). <em>Statistical Policy Working Paper 22: Report on Statistical Disclosure Limitation Methodology</em> [Research Report]. U.S. Federal Committee on Statistical Methodology.</p>
</div>
<div>
<p>Hirshleifer, J. (1980). Privacy: Its origin, function, and future. <em>The Journal of Legal Studies</em>, <em>9</em>(4), 649–664. <a href="https://doi.org/10.1086/467659">https://doi.org/10.1086/467659</a></p>
</div>
<div>
<p>Hsu, J., Gaboardi, M., Haeberlen, A., Khanna, S., Narayan, A., Pierce, B. C., &amp; Roth, A. (2014). Differential Privacy: An Economic Method for Choosing Epsilon. <em>2014 IEEE 27th Computer Security Foundations Symposium</em>, 398–410. <a href="https://doi.org/10.1109/CSF.2014.35">https://doi.org/10.1109/CSF.2014.35</a></p>
</div>
<div>
<p>Machanavajjhala, A., Kifer, D., Gehrke, J., &amp; Venkitasubramaniam, M. (2007). L-diversity: Privacy beyond k-anonymity. <em>ACM Transactions on Knowledge Discovery from Data</em>, <em>1</em>(1). <a href="https://doi.org/10.1145/1217299.1217302">https://doi.org/10.1145/1217299.1217302</a></p>
</div>
<div>
<p>Perez-Truglia, R. (2016). The effects of income transparency on well-being: Evidence from a natural experiment. <em>SSRN</em>. <a href="https://doi.org/10.2139/ssrn.2657808">https://doi.org/10.2139/ssrn.2657808</a></p>
</div>
<div>
<p>Posner, R. A. (1981). The Economics of Privacy. <em>The American Economic Review</em>, <em>71</em>(2), 405–409. Retrieved from <a href="https://www.jstor.org/stable/1815754">https://www.jstor.org/stable/1815754</a></p>
</div>
<div>
<p>Spencer, B. D. (1985). Optimal Data Quality. <em>Journal of the American Statistical Association</em>, <em>80</em>(391), 564–573. <a href="https://doi.org/10.1080/01621459.1985.10478155">https://doi.org/10.1080/01621459.1985.10478155</a></p>
</div>
<div>
<p>Spencer, B. D., &amp; Seeskin, Z. H. (2015). Effects of Census Accuracy on Apportionment of Congress and Allocations of Federal Funds. <em>JSM Proceedings, Government Statistics Section</em>, 3061–3075. Retrieved from <a href="https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html">https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html</a></p>
</div>
<div>
<p>Stigler, G. J. (1980). An Introduction to Privacy in Economics and Politics. <em>Journal of Legal Studies</em>, <em>9</em>(4), 623–644. <a href="https://doi.org/10.2307/724174">https://doi.org/10.2307/724174</a></p>
</div>
<div>
<p>Sweeney, L. (2002). Achieving k-anonymity privacy protection using generalization and suppression. <em>International Journal on Uncertainty, Fuzziness and Knowledge-Based Systems</em>, <em>10</em>(5), 571–588. <a href="https://doi.org/10.1142/s021848850200165x">https://doi.org/10.1142/s021848850200165x</a></p>
</div>
<div>
<p>Varian, H. R. (2002). Economic Aspects of Personal Privacy. In W. H. Lehr &amp; L. M. Pupillo (Eds.), <em>Cyber Policy and Economics in an Internet Age</em> (pp. 127–137). <a href="https://doi.org/10.1007/978-1-4757-3575-8_9">https://doi.org/10.1007/978-1-4757-3575-8_9</a></p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-abowd_dynamically_2012">
<p>Abowd, J. M., Gittings, R. K. K., McKinney, K. L., Stephens, B., Vilhuber, L., &amp; Woodcock, S. D. (2012). <em>Dynamically Consistent Noise Infusion and Partially Synthetic Data as Confidentiality Protection Measures for Related Time Series</em> (No. 12-13). <a href="https://doi.org/10.2139/ssrn.2159800">https://doi.org/10.2139/ssrn.2159800</a></p>
</div>
<div id="ref-abowd_introductory_2019">
<p>Abowd, J. M., Schmutte, I., Sexton, W., &amp; Vilhuber, L. (2019). <em>Introductory Readings in Formal Privacy for Economists</em> (Document No. 2662639). <a href="https://doi.org/10.5281/zenodo.2662639">https://doi.org/10.5281/zenodo.2662639</a></p>
</div>
<div id="ref-abowd_lehd_2009">
<p>Abowd, J. M., Stephens, B. E., Vilhuber, L., Andersson, F., McKinney, K. L., Roemer, M., &amp; Woodcock, S. D. (2009). The LEHD Infrastructure Files and the Creation of the Quarterly Workforce Indicators. In T. Dunne and J B Jensen and M J Roberts (Ed.), <em>Producer Dynamics: New Evidence from Micro Data</em>. University of Chicago Press.</p>
</div>
<div id="ref-abowd_session_2016">
<p>Abowd, J. M., &amp; Vilhuber, L. (2016). <em>Session 12: Statistical Tools: Methods of Confidentiality Protection</em> (Presentation No. 45060). Retrieved from Labor Dynamics Institute, Cornell University website: <a href="https://hdl.handle.net/1813/45060">https://hdl.handle.net/1813/45060</a></p>
</div>
<div id="ref-abowd_economic_2019">
<p>Abowd, J., &amp; Schmutte, I. (2019). An Economic Analysis of Privacy Protection and Statistical Accuracy as Social Choices. <em>American Economic Review</em>, <em>109</em>(1), 171–202. <a href="https://doi.org/10.1257/aer.20170627">https://doi.org/10.1257/aer.20170627</a></p>
</div>
<div id="ref-abowd_economic_2015">
<p>Abowd, J., &amp; Schmutte, I. M. (2015). Economic analysis and statistical disclosure limitation. <em>Brookings Papers on Economic Activity</em>, 221–267. <a href="https://doi.org/10.1353/eca.2016.0004">https://doi.org/10.1353/eca.2016.0004</a></p>
</div>
<div id="ref-acquisti_economics_2016">
<p>Acquisti, A., Taylor, C., &amp; Wagman, L. (2016). The Economics of Privacy. <em>Journal of Economic Literature</em>, <em>54</em>(2), 442–492. <a href="https://doi.org/10.1257/jel.54.2.442">https://doi.org/10.1257/jel.54.2.442</a></p>
</div>
<div id="ref-anderson_challenges_2007">
<p>Anderson, M., &amp; Seltzer, W. (2007). Challenges to the confidentiality of US federal statistics, 1910-1965. <em>Journal of Official Statistics</em>, <em>23</em>(1), 1. Retrieved from <a href="https://www.scb.se/contentassets/ff271eeeca694f47ae99b942de61df83/challenges-to-the-confidentiality-of-u.s.-federal-statistics-1910-1965.pdf">https://www.scb.se/contentassets/ff271eeeca694f47ae99b942de61df83/challenges-to-the-confidentiality-of-u.s.-federal-statistics-1910-1965.pdf</a></p>
</div>
<div id="ref-auxier_americans_2019">
<p>Auxier, B., Rainie, L., Anderson, M., Perrin, A., Kumar, M., &amp; Turner, E. (2019). <em>Americans and Privacy: Concerned, Confused and Feeling Lack of Control Over Their Personal Information</em>. Retrieved from Pew Research Center website: <a href="https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/">https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/</a></p>
</div>
<div id="ref-card_inequality_2012">
<p>Card, D., Mas, A., Moretti, E., &amp; Saez, E. (2012). Inequality at work: The effect of peer salaries on job satisfaction. <em>American Economic Review</em>, <em>102</em>(6), 2981–3003. <a href="https://doi.org/10.1257/aer.102.6.2981">https://doi.org/10.1257/aer.102.6.2981</a></p>
</div>
<div id="ref-couper_risk_2008">
<p>Couper, M. P., Singer, E., Conrad, F. G., &amp; Groves, R. M. (2008). Risk of disclosure, perceptions of risk, and concerns about privacy and confidentiality as factors in survey participation. <em>Journal of Official Statistics</em>, <em>24</em>(2), 255. Retrieved from <a href="http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/risk-of-disclosure-perceptions-of-risk-and-concerns-about-privacy-and-confidentiality-as-factors-in-survey-participation.pdf">http://www.scb.se/contentassets/ca21efb41fee47d293bbee5bf7be7fb3/risk-of-disclosure-perceptions-of-risk-and-concerns-about-privacy-and-confidentiality-as-factors-in-survey-participation.pdf</a></p>
</div>
<div id="ref-cummings_adaptive_2016">
<p>Cummings, R., Ligett, K., Nissim, K., Roth, A., &amp; Wu, Z. S. (2016). Adaptive Learning with Robust Generalization Guarantees. <em>CoRR</em>, <em>abs/1602.07726</em>. Retrieved from <a href="http://arxiv.org/abs/1602.07726">http://arxiv.org/abs/1602.07726</a></p>
</div>
<div id="ref-dalenius_towards_1977">
<p>Dalenius, T. (1977). Towards a methodology for statistical disclosure control. <em>Statistik Tidskrift</em>, <em>15</em>, 429–444. <a href="https://doi.org/10.1145/320613.320616">https://doi.org/10.1145/320613.320616</a></p>
</div>
<div id="ref-duncan_disclosure-limited_1986">
<p>Duncan, G., &amp; Lambert, D. (1986). Disclosure-limited data dissemination. <em>Journal of the American Statistical Association</em>, <em>81</em>(393), 10–18. <a href="https://doi.org/10.1080/01621459.1986.10478229">https://doi.org/10.1080/01621459.1986.10478229</a></p>
</div>
<div id="ref-duncan_private_1993">
<p>Duncan, G. T., Jabine, T. B., &amp; Wolf, V. A. de (Eds.). (1993). <em>Private Lives and Public Policies: Confidentiality and Accessibility of Government Statistics</em>. <a href="https://doi.org/10.17226/2122">https://doi.org/10.17226/2122</a></p>
</div>
<div id="ref-dupriez_dissemination_2010">
<p>Dupriez, O., &amp; Boyko, E. (2010). <em>Dissemination of Microdata Files - Principles, Procedures and Practices</em> (Working Paper No. 005). Retrieved from The World Bank website: <a href="http://ihsn.org/dissemination-of-microdata-files">http://ihsn.org/dissemination-of-microdata-files</a></p>
</div>
<div id="ref-dwork_generalization_2015">
<p>Dwork, C., Feldman, V., Hardt, M., Pitassi, T., Reingold, O., &amp; Roth, A. (2015). Generalization in Adaptive Data Analysis and Holdout Reuse. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, &amp; R. Garnett (Eds.), <em>Advances in Neural Information Processing Systems 28</em> (pp. 2341–2349). Retrieved from <a href="http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf">http://papers.nips.cc/paper/5993-generalization-in-adaptive-data-analysis-and-holdout-reuse.pdf</a></p>
</div>
<div id="ref-evans_using_1998">
<p>Evans, T., Zayatz, L., &amp; Slanta, J. (1998). Using Noise for Disclosure Limitation of Establishment Tabular Data. <em>Journal of Official Statistics</em>, <em>14</em>(4), 537–551.</p>
</div>
<div id="ref-fellegi_question_1972">
<p>Fellegi, I. P. (1972). On the Question of Statistical Confidentiality. <em>Journal of the American Statistical Association</em>, <em>67</em>(337), 7–18. <a href="https://doi.org/10.2307/2284695">https://doi.org/10.2307/2284695</a></p>
</div>
<div id="ref-garfinkel_-identification_2015">
<p>Garfinkel, S. (2015). <em>De-Identification of Personal Information</em> (Internal Report No. 8053). <a href="https://doi.org/10.6028/nist.ir.8053">https://doi.org/10.6028/nist.ir.8053</a></p>
</div>
<div id="ref-harris-kojetin_statistical_2005">
<p>Harris-Kojetin, B. A., Alvey, W. L., Carlson, L., Cohen, S. B., Cohen, S. H., Cox, L. H., … Groves, R. (2005). <em>Statistical Policy Working Paper 22: Report on Statistical Disclosure Limitation Methodology</em> [Research Report]. U.S. Federal Committee on Statistical Methodology.</p>
</div>
<div id="ref-hirshleifer_privacy_1980">
<p>Hirshleifer, J. (1980). Privacy: Its origin, function, and future. <em>The Journal of Legal Studies</em>, <em>9</em>(4), 649–664. <a href="https://doi.org/10.1086/467659">https://doi.org/10.1086/467659</a></p>
</div>
<div id="ref-hsu_differential_2014">
<p>Hsu, J., Gaboardi, M., Haeberlen, A., Khanna, S., Narayan, A., Pierce, B. C., &amp; Roth, A. (2014). Differential Privacy: An Economic Method for Choosing Epsilon. <em>2014 IEEE 27th Computer Security Foundations Symposium</em>, 398–410. <a href="https://doi.org/10.1109/CSF.2014.35">https://doi.org/10.1109/CSF.2014.35</a></p>
</div>
<div id="ref-machanavajjhala_l-diversity_2007">
<p>Machanavajjhala, A., Kifer, D., Gehrke, J., &amp; Venkitasubramaniam, M. (2007). L-diversity: Privacy beyond k-anonymity. <em>ACM Transactions on Knowledge Discovery from Data</em>, <em>1</em>(1). <a href="https://doi.org/10.1145/1217299.1217302">https://doi.org/10.1145/1217299.1217302</a></p>
</div>
<div id="ref-perez-truglia_effects_2016">
<p>Perez-Truglia, R. (2016). The effects of income transparency on well-being: Evidence from a natural experiment. <em>SSRN</em>. <a href="https://doi.org/10.2139/ssrn.2657808">https://doi.org/10.2139/ssrn.2657808</a></p>
</div>
<div id="ref-posner_economics_1981">
<p>Posner, R. A. (1981). The Economics of Privacy. <em>The American Economic Review</em>, <em>71</em>(2), 405–409. Retrieved from <a href="https://www.jstor.org/stable/1815754">https://www.jstor.org/stable/1815754</a></p>
</div>
<div id="ref-spencer_optimal_1985">
<p>Spencer, B. D. (1985). Optimal Data Quality. <em>Journal of the American Statistical Association</em>, <em>80</em>(391), 564–573. <a href="https://doi.org/10.1080/01621459.1985.10478155">https://doi.org/10.1080/01621459.1985.10478155</a></p>
</div>
<div id="ref-spencer_effects_2015">
<p>Spencer, B. D., &amp; Seeskin, Z. H. (2015). Effects of Census Accuracy on Apportionment of Congress and Allocations of Federal Funds. <em>JSM Proceedings, Government Statistics Section</em>, 3061–3075. Retrieved from <a href="https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html">https://www.ipr.northwestern.edu/publications/papers/2015/ipr-wp-15-05.html</a></p>
</div>
<div id="ref-stigler_introduction_1980">
<p>Stigler, G. J. (1980). An Introduction to Privacy in Economics and Politics. <em>Journal of Legal Studies</em>, <em>9</em>(4), 623–644. <a href="https://doi.org/10.2307/724174">https://doi.org/10.2307/724174</a></p>
</div>
<div id="ref-sweeney_achieving_2002">
<p>Sweeney, L. (2002). Achieving k-anonymity privacy protection using generalization and suppression. <em>International Journal on Uncertainty, Fuzziness and Knowledge-Based Systems</em>, <em>10</em>(5), 571–588. <a href="https://doi.org/10.1142/s021848850200165x">https://doi.org/10.1142/s021848850200165x</a></p>
</div>
<div id="ref-varian_economic_2002">
<p>Varian, H. R. (2002). Economic Aspects of Personal Privacy. In W. H. Lehr &amp; L. M. Pupillo (Eds.), <em>Cyber Policy and Economics in an Internet Age</em> (pp. 127–137). <a href="https://doi.org/10.1007/978-1-4757-3575-8_9">https://doi.org/10.1007/978-1-4757-3575-8_9</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
